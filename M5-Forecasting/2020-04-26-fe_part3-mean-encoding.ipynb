{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:02:28.525755Z",
     "start_time": "2020-04-27T10:02:26.766812Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit,StratifiedKFold,TimeSeriesSplit,KFold,GroupKFold,train_test_split,GroupShuffleSplit,StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error,log_loss,confusion_matrix\n",
    "import sqlite3\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "import gc\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "#from bayes_opt import BayesianOptimization\n",
    "import re\n",
    "from string import punctuation\n",
    "from scipy.spatial import Voronoi\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.spatial import Delaunay\n",
    "from tqdm.notebook import tqdm\n",
    "from numba import jit\n",
    "from collections import Counter\n",
    "import json\n",
    "import joblib\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:02:28.633457Z",
     "start_time": "2020-04-27T10:02:28.530022Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int32', 'int64', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:02:42.541978Z",
     "start_time": "2020-04-27T10:02:28.641563Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "sell_prices = pd.read_csv('../data/sell_prices.csv')\n",
    "sales_train = pd.read_csv('../data/sales_train_validation.csv')\n",
    "calendar = pd.read_csv('../data/calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:02:42.611620Z",
     "start_time": "2020-04-27T10:02:42.547260Z"
    }
   },
   "outputs": [],
   "source": [
    "####扩展sales_train df方便后续\n",
    "#sales_train = pd.read_csv('../data/sales_train_validation.csv')\n",
    "for _ in [f'd_{i}' for i in range(1914,1970)]:\n",
    "    sales_train[_] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:03:03.844652Z",
     "start_time": "2020-04-27T10:02:42.614148Z"
    }
   },
   "outputs": [],
   "source": [
    "sales_train_long_format = pd.melt(sales_train,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],var_name = 'day_num',value_name='sale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:04:38.550815Z",
     "start_time": "2020-04-27T10:03:03.848379Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform_day_to_num(str1):\n",
    "    return int(str1[2:])\n",
    "sales_train_long_format['day_num'] = sales_train_long_format['day_num'].map(transform_day_to_num)\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "calendar['day_num'] = calendar['d'].map(transform_day_to_num)\n",
    "map_day_date = calendar[['date','day_num']].set_index('day_num')['date']\n",
    "sales_train_long_format['date'] = sales_train_long_format['day_num'].map(map_day_date)\n",
    "list1 = ['wm_yr_wk','event_name_1', 'event_type_1', 'event_name_2', 'event_type_2','snap_CA', 'snap_TX', 'snap_WI','day_num']\n",
    "sales_train_long_format = sales_train_long_format.merge(calendar[list1],on='day_num',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:06:16.723547Z",
     "start_time": "2020-04-27T10:04:38.554744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 6526.92 Mb (25.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "sales_train_long_format = sales_train_long_format.merge(sell_prices,how='left',on = ['store_id','item_id','wm_yr_wk'])\n",
    "###把没卖的变成nan\n",
    "sales_train_long_format.loc[pd.isna(sales_train_long_format.sell_price),'sale'] = np.nan\n",
    "sales_train_long_format = reduce_mem_usage(sales_train_long_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part3 or  part4\n",
    "\n",
    "- mean encoding part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:06:26.302154Z",
     "start_time": "2020-04-27T10:06:16.726900Z"
    }
   },
   "outputs": [],
   "source": [
    "sales_train = pd.read_csv('../data/sales_train_validation.csv')\n",
    "for _ in [f'd_{i}' for i in range(1914,1970)]:\n",
    "    sales_train[_] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:06:26.318959Z",
     "start_time": "2020-04-27T10:06:26.305434Z"
    }
   },
   "outputs": [],
   "source": [
    "def group_by_key_on_value(df,key,windows,agg_func = [np.mean,np.std,np.median,np.max,np.min],feature_name = 'No name'):\n",
    "    save_dict = {}\n",
    "    d_start_columns = list(df.columns[df.columns.str.startswith('d_')])\n",
    "    for key_value in tqdm(df[key].unique()):\n",
    "        get_key_df = df[df[key] == key_value].copy()\n",
    "        rolling_df = \\\n",
    "            get_key_df[d_start_columns].sum(axis=0,skipna=True).shift(1).rolling(windows,int(windows/2)).\\\n",
    "            agg(agg_func)\n",
    "        #rolling_df = rolling_df.loc[f'd_{day_min}':f'd_{day_max}']\n",
    "        rolling_df.index = [key_value+'_'+_ for _ in rolling_df.index]\n",
    "        rolling_df_dict = rolling_df.to_dict(orient='index')\n",
    "        save_dict.update(rolling_df_dict)\n",
    "    dict_mean,dict_std,dict_median,dict_max,dict_min = {},{},{},{},{}\n",
    "    for key,value in save_dict.items():\n",
    "        dict_mean[key] = value['mean']\n",
    "        dict_std[key] = value['std']\n",
    "        dict_median[key] = value['median']\n",
    "        dict_max[key] = values['amax']\n",
    "        dict_min[key] = values['amin']\n",
    "    return dict_mean,dict_std,dict_median,dict_max,dict_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:06:26.386208Z",
     "start_time": "2020-04-27T10:06:26.324632Z"
    }
   },
   "outputs": [],
   "source": [
    "def group_by_two_key_on_value(df,key1,key2,windows,agg_func,feature_name):\n",
    "    df['key'] = df[key1].astype(str) + '_' + df[key2].astype(str)\n",
    "    key = 'key'\n",
    "    save_dict = {}\n",
    "    d_start_columns = list(df.columns[df.columns.str.startswith('d_')])\n",
    "    for key_value in tqdm(df[key].unique()):\n",
    "        get_key_df = df[df[key] == key_value].copy()\n",
    "        rolling_df = \\\n",
    "            get_key_df[d_start_columns].sum(axis=0,skipna=True).shift(1).rolling(windows,int(windows/2)).\\\n",
    "            agg(agg_func)\n",
    "        #rolling_df = rolling_df.loc[f'd_{day_min}':f'd_{day_max}']\n",
    "        rolling_df.index = [key_value+'_'+_ for _ in rolling_df.index]\n",
    "        rolling_df_dict = rolling_df.to_dict(orient='index')\n",
    "        save_dict.update(rolling_df_dict)\n",
    "    dict_mean,dict_std,dict_median = {},{},{}\n",
    "    for key_temp,value in save_dict.items():\n",
    "        dict_mean[key_temp] = value['mean']\n",
    "        dict_std[key_temp] = value['std']\n",
    "        dict_median[key_temp] = value['median']\n",
    "    return dict_mean,dict_std,dict_median       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineer(df,num_core,date1):\n",
    "    \"\"\"\n",
    "    df format:sales_train_long_format\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    #### group by item_id\n",
    "    for key_single in ['state_id','store_id','cat_id','dept_id','item_id']:\n",
    "        df[f'{key_single}_day_num'] = df[key_single].astype(str) + '_d_' + df.day_num.astype(str)\n",
    "        for day_interval in [7,14,28]:\n",
    "            dict_mean,dict_std,dict_median,dict_max,dict_min = \\\n",
    "            group_by_key_on_value(sales_train,key_single,day_interval,[np.mean,np.std,np.median,np.max,np.min],\\\n",
    "                                  f'{key_single}_rolling_{day_interval}_sale')\n",
    "            df[f'{key_single}_rolling_{day_interval}_sale_mean'] = df[f'{key_single}_day_num'].map(dict_mean)\n",
    "            df[f'{key_single}_rolling_{day_interval}_sale_std'] = df[f'{key_single}_day_num'].map(dict_std)\n",
    "            df[f'{key_single}_rolling_{day_interval}_sale_median'] = df[f'{key_single}_day_num'].map(dict_median)\n",
    "            df[f'{key_single}_rolling_{day_interval}_sale_max'] = df[f'{key_single}_day_num'].map(dict_max)\n",
    "            df[f'{key_single}_rolling_{day_interval}_sale_min'] = df[f'{key_single}_day_num'].map(dict_min)\n",
    "\n",
    "            print(f'{key_single}_rolling_{day_interval}_sale','over')\n",
    "\n",
    "    df = reduce_mem_usage(df,False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)\n",
    "train1 = feature_engineer(sales_train_long_format,12,None)\n",
    "train1.to_pickle('data_part4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:10:32.193448Z",
     "start_time": "2020-04-27T10:10:32.181146Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineer(df,num_core,date1):\n",
    "    \"\"\"\n",
    "    df format:sales_train_long_format\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    for double_key1,double_key2 in [\n",
    "        ('state_id','cat_id'),\n",
    "        ('state_id','dept_id'),\n",
    "        ('state_id','item_id'),\n",
    "        ('store_id','cat_id'),\n",
    "        ('store_id','dept_id')]:\n",
    "        df[f'{double_key1}_{double_key2}_day_num'] = df[double_key1].astype(str)+'_'+df[double_key2].astype(str) + '_d_' + df.day_num.astype(str)\n",
    "        for day_interval in [7,14,28]:\n",
    "            dict_mean,dict_std,dict_median = \\\n",
    "            group_by_two_key_on_value(sales_train,double_key1,double_key2,day_interval,['mean','std','median'],\\\n",
    "                                  f'{double_key1}_{double_key2}_rolling_{day_interval}_sale')\n",
    "            df[f'{double_key1}_{double_key2}_rolling_{day_interval}_sale_mean'] = df[f'{double_key1}_{double_key2}_day_num'].map(dict_mean)\n",
    "            df[f'{double_key1}_{double_key2}_rolling_{day_interval}_sale_std'] = df[f'{double_key1}_{double_key2}_day_num'].map(dict_std)\n",
    "            df[f'{double_key1}_{double_key2}_rolling_{day_interval}_sale_median'] = df[f'{double_key1}_{double_key2}_day_num'].map(dict_median)\n",
    "            print(f'{double_key1}_{double_key2}_rolling_{day_interval}_sale','over')\n",
    "\n",
    "    df = reduce_mem_usage(df,False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T10:13:15.781789Z",
     "start_time": "2020-04-27T10:10:32.887865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3eec29dbf394b539812791f1a5f6439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "state_id_cat_id_rolling_7_sale over\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0193a59bbf43feb38abff4b20b5268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cac59c3baafc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_engineer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales_train_long_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-7dc07a2897f3>\u001b[0m in \u001b[0;36mfeature_engineer\u001b[0;34m(df, num_core, date1)\u001b[0m\n\u001b[1;32m     17\u001b[0m                                   f'{double_key1}_{double_key2}_rolling_{day_interval}_sale')\n\u001b[1;32m     18\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{double_key1}_{double_key2}_rolling_{day_interval}_sale_mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{double_key1}_{double_key2}_day_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{double_key1}_{double_key2}_rolling_{day_interval}_sale_std'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{double_key1}_{double_key2}_day_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{double_key1}_{double_key2}_rolling_{day_interval}_sale_median'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{double_key1}_{double_key2}_day_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_median\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{double_key1}_{double_key2}_rolling_{day_interval}_sale'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'over'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   3380\u001b[0m         \"\"\"\n\u001b[1;32m   3381\u001b[0m         new_values = super(Series, self)._map_values(\n\u001b[0;32m-> 3382\u001b[0;31m             arg, na_action=na_action)\n\u001b[0m\u001b[1;32m   3383\u001b[0m         return self._constructor(new_values,\n\u001b[1;32m   3384\u001b[0m                                  index=self.index).__finalize__(self)\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2753\u001b[0m                                  'backfill or nearest reindexing')\n\u001b[1;32m   2754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2755\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2757\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.lookup\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \"\"\"Convert the input to an array.\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(1)\n",
    "train1 = feature_engineer(sales_train_long_format,12,None)\n",
    "train1.to_pickle('data_part5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
