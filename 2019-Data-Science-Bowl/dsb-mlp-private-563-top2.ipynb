{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/media-sequence/media_sequence.csv\n",
      "/kaggle/input/dsb-media-sequence/media_sequence.csv\n",
      "/kaggle/input/data-science-bowl-2019/train.csv\n",
      "/kaggle/input/data-science-bowl-2019/train_labels.csv\n",
      "/kaggle/input/data-science-bowl-2019/specs.csv\n",
      "/kaggle/input/data-science-bowl-2019/test.csv\n",
      "/kaggle/input/data-science-bowl-2019/sample_submission.csv\n",
      "/kaggle/input/null-importance/2020_2_2_null_importance.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top 700 + add test label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit,StratifiedKFold,TimeSeriesSplit,KFold,GroupKFold,train_test_split,GroupShuffleSplit,StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error,log_loss,confusion_matrix\n",
    "import sqlite3\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "import gc\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from bayes_opt import BayesianOptimization\n",
    "import re\n",
    "from string import punctuation\n",
    "from scipy.spatial import Voronoi\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.spatial import Delaunay\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_accuracy_group(accuracy):\n",
    "    if accuracy ==0:\n",
    "        return 0\n",
    "    elif accuracy ==1:\n",
    "        return 3\n",
    "    elif accuracy ==0.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "@jit\n",
    "def qwk(a1, a2):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n",
    "\n",
    "    :param a1:\n",
    "    :param a2:\n",
    "    :param max_rat:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_rat = 3\n",
    "    a1 = np.asarray(a1, dtype=int)\n",
    "    a2 = np.asarray(a2, dtype=int)\n",
    "\n",
    "    hist1 = np.zeros((max_rat + 1, ))\n",
    "    hist2 = np.zeros((max_rat + 1, ))\n",
    "\n",
    "    o = 0\n",
    "    for k in range(a1.shape[0]):\n",
    "        i, j = a1[k], a2[k]\n",
    "        hist1[i] += 1\n",
    "        hist2[j] += 1\n",
    "        o +=  (i - j) * (i - j)\n",
    "\n",
    "    e = 0\n",
    "    for i in range(max_rat + 1):\n",
    "        for j in range(max_rat + 1):\n",
    "            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n",
    "\n",
    "    e = e / a1.shape[0]\n",
    "\n",
    "    return 1 - o / e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kappa(y_pred,y_true,coefficients):\n",
    "    preds = y_pred.copy()\n",
    "    preds[y_pred <= coefficients[0]] = 0\n",
    "    preds[np.where(np.logical_and(y_pred > coefficients[0], y_pred <= coefficients[1]))] = 1\n",
    "    preds[np.where(np.logical_and(y_pred > coefficients[1], y_pred <= coefficients[2]))] = 2\n",
    "    preds[y_pred > coefficients[2]] = 3\n",
    "    return qwk(y_true,preds)\n",
    "\n",
    "def get_pred(y_pred,coefficients):\n",
    "    preds = y_pred.copy()\n",
    "    preds[y_pred <= coefficients[0]] = 0\n",
    "    preds[np.where(np.logical_and(y_pred > coefficients[0], y_pred <= coefficients[1]))] = 1\n",
    "    preds[np.where(np.logical_and(y_pred > coefficients[1], y_pred <= coefficients[2]))] = 2\n",
    "    preds[y_pred > coefficients[2]] = 3\n",
    "    return preds\n",
    "\n",
    "def opt_more_coeff(oof_predict,y_train,coef):\n",
    "    score1 = 0\n",
    "    k = 0\n",
    "    for a in np.arange(-0.1,0.1,0.01):\n",
    "        for b in np.arange(-0.1,0.1,0.01):\n",
    "            for c in np.arange(-0.1,0.1,0.01):\n",
    "                coefficients = [coef[0]+a, coef[1]+b, coef[2]+c]\n",
    "                preds = oof_predict.copy()\n",
    "                preds[oof_predict <= coefficients[0]] = 0\n",
    "                preds[np.where(np.logical_and(oof_predict > coefficients[0], oof_predict <= coefficients[1]))] = 1\n",
    "                preds[np.where(np.logical_and(oof_predict > coefficients[1], oof_predict <= coefficients[2]))] = 2\n",
    "                preds[oof_predict > coefficients[2]] = 3\n",
    "                kappa_1 = qwk(y_train, preds)\n",
    "                k+=1\n",
    "                if kappa_1>score1:\n",
    "                    temp_save = [coef[0]+a, coef[1]+b, coef[2]+c]\n",
    "                    #print(np.round(kappa_1,8),'Per:',str(round((k/64000)*100,2))+'%',k,temp_save)\n",
    "                    score1 = kappa_1\n",
    "    coef = temp_save.copy()\n",
    "    ### second \n",
    "    k=0\n",
    "    for a in np.arange(-0.04,0.04,0.004):\n",
    "        for b in np.arange(-0.04,0.04,0.004):\n",
    "            for c in np.arange(-0.04,0.04,0.004):\n",
    "                coefficients = [coef[0]+a, coef[1]+b, coef[2]+c]\n",
    "                preds = oof_predict.copy()\n",
    "                preds[oof_predict <= coefficients[0]] = 0\n",
    "                preds[np.where(np.logical_and(oof_predict > coefficients[0], oof_predict <= coefficients[1]))] = 1\n",
    "                preds[np.where(np.logical_and(oof_predict > coefficients[1], oof_predict <= coefficients[2]))] = 2\n",
    "                preds[oof_predict > coefficients[2]] = 3\n",
    "                kappa_1 = qwk(y_train, preds)\n",
    "                k+=1\n",
    "                if kappa_1>score1:\n",
    "                    temp_save = [coef[0]+a, coef[1]+b, coef[2]+c]\n",
    "                    #print(np.round(kappa_1,8),'Per:',str(round((k/64000)*100,2))+'%',k,temp_save)\n",
    "                    score1 = kappa_1\n",
    "    return temp_save,score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\n",
    "specs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\n",
    "test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n",
    "train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\n",
    "train['timestamp'] = pd.to_datetime(train.timestamp)\n",
    "test['timestamp'] = pd.to_datetime(test.timestamp)\n",
    "null_importance = pd.read_csv('/kaggle/input/null-importance/2020_2_2_null_importance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = null_importance.iloc[:,0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title_event_code'] = train['title'].astype(str) + '_' + train['event_code'].astype(str)\n",
    "test['title_event_code'] = test['title'].astype(str) + '_' + test['event_code'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_event_code = set(train.event_code).union(set(test.event_code))\n",
    "list_of_event_id = set(train.event_id).union(set(test.event_id))\n",
    "list_title = set(train.title).union(set(test.title))\n",
    "list_title_event_code = set(train.title_event_code).union(set(test.title_event_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting(test_sample):\n",
    "    pred = [] \n",
    "    for i in range(test_sample.shape[1]):\n",
    "        result = test_sample[:,i]\n",
    "        value_counts = pd.Series(result).value_counts()\n",
    "        pred_value = np.random.permutation(list(value_counts.index[value_counts==value_counts.iloc[0]]))[0]\n",
    "        pred.append(pred_value)\n",
    "    return np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_decay(index_):\n",
    "    if index_ < 20:\n",
    "        return 0.0003\n",
    "    elif  index_ < 40:\n",
    "        if  index_ % 2 ==0:\n",
    "            return 0.00008\n",
    "        else:\n",
    "            return 0.0002                    \n",
    "    elif  index_ < 60:\n",
    "        if  index_ % 2 ==0:\n",
    "            return 0.00008\n",
    "        else:\n",
    "            return 0.00003          \n",
    "    else:\n",
    "        return 0.00003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dropout, Input, Dense, concatenate,Flatten, BatchNormalization, Softmax, Add,LeakyReLU\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras import optimizers\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from  keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import keras\n",
    "\n",
    "\n",
    "def NN_model():\n",
    "    Input_main = Input(shape=((X_train.shape[1],)), name=\"main\")\n",
    "    main_input = Dense(256)(Input_main)\n",
    "    main_input = LeakyReLU(alpha=0.3)(main_input)\n",
    "    main_input = BatchNormalization()(main_input)\n",
    "    main_input = Dropout(0.3)(main_input) \n",
    "    \n",
    "    main_input = Dense(256)(main_input)\n",
    "    main_input = LeakyReLU(alpha=0.3)(main_input)\n",
    "    main_input = BatchNormalization()(main_input)   \n",
    "    main_input = Dropout(0.3)(main_input)    \n",
    "\n",
    "    main_input = Dense(256)(main_input)    \n",
    "    main_input = LeakyReLU(alpha=0.3)(main_input)\n",
    "    main_input = BatchNormalization()(main_input)\n",
    "    main_input = Dropout(0.3)(main_input)   \n",
    "    \n",
    "    main_input = Dense(128)(main_input)    \n",
    "    main_input = LeakyReLU(alpha=0.3)(main_input)\n",
    "    main_input = BatchNormalization()(main_input)\n",
    "    main_input = Dropout(0.3)(main_input) \n",
    "\n",
    "\n",
    "    output = Dense(1)(main_input)\n",
    "    output2 = Dense(1)(main_input)\n",
    "    adam = optimizers.Adam(lr=0.0003, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    model = Model(inputs=[Input_main], outputs=[output])\n",
    "    model.compile(optimizer=adam, loss=['mean_squared_error'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_nn(X_train,y_train,ins_id,X_test):\n",
    "    coefficients = [1.051, 1.682, 2.231]\n",
    "    gkf = GroupKFold(n_splits=4)\n",
    "    impor1 = 0\n",
    "    score = 0\n",
    "    score_kappa = 0\n",
    "    models = []\n",
    "    oof_predict = np.zeros((y_train.shape[0]))\n",
    "    pred_test1 = 0\n",
    "    for train_index, test_index in gkf.split(X_train, y_train,groups=ins_id):\n",
    "        X_train2= X_train.iloc[train_index,:]\n",
    "        y_train2= y_train.iloc[train_index]\n",
    "        X_test2= X_train.iloc[test_index,:]\n",
    "        y_test2= y_train.iloc[test_index]\n",
    "        clf = NN_model()\n",
    "        es = EarlyStopping(monitor='val_loss', patience=30, verbose=2,restore_best_weights=True)\n",
    "        lr = keras.callbacks.LearningRateScheduler(lr_decay)\n",
    "        clf.fit(X_train2, y_train2,validation_data=(X_test2,y_test2),callbacks=[es,lr],batch_size=128,epochs=300,verbose=2)\n",
    "        models.append(clf)\n",
    "        temp_predict = clf.predict(X_test2).flatten()\n",
    "        pred_test1 +=  clf.predict(X_test).flatten()/gkf.n_splits\n",
    "        oof_predict[test_index] = temp_predict\n",
    "        rse_1 = np.sqrt(mean_squared_error(y_test2,temp_predict))\n",
    "        print('rse:',rse_1)\n",
    "        preds = temp_predict.copy()\n",
    "        preds[preds <= coefficients[0]] = 0\n",
    "        preds[np.where(np.logical_and(preds > coefficients[0], preds <= coefficients[1]))] = 1\n",
    "        preds[np.where(np.logical_and(preds > coefficients[1], preds <= coefficients[2]))] = 2\n",
    "        preds[preds > coefficients[2]] = 3\n",
    "        kappa_1 = qwk(y_test2, preds)\n",
    "        score += rse_1/gkf.n_splits\n",
    "        score_kappa += kappa_1/gkf.n_splits\n",
    "        gc.collect()\n",
    "    print('mean rse:',score)\n",
    "    print('mean kappa:',score_kappa)\n",
    "    preds = oof_predict.copy()\n",
    "    preds[preds <= coefficients[0]] = 0\n",
    "    preds[np.where(np.logical_and(preds > coefficients[0], preds <= coefficients[1]))] = 1\n",
    "    preds[np.where(np.logical_and(preds > coefficients[1], preds <= coefficients[2]))] = 2\n",
    "    preds[preds > coefficients[2]] = 3\n",
    "    print('oof kappa:',qwk(y_train, preds))\n",
    "    return oof_predict,preds,pred_test1,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_nn(X_train,y_train,ins_id,X_test):\n",
    "    cappa_list = []\n",
    "    oof_class_list = []\n",
    "    rmse_list = []\n",
    "    pred_class_list = []\n",
    "    oof_num_mean = 0\n",
    "    pred_num_pred = 0\n",
    "    temp_score_overall = []\n",
    "    \n",
    "    seed_list = [7,8,9,10,11]\n",
    "    for kth,seed1 in enumerate(seed_list):#[32,42,47,1103,128,22,45][11,22,33,43,45,56,67]\n",
    "        print(str(kth+1),'th seed begins----------------------' )\n",
    "        oof_num,oof_class,pred_num,rmse = normal_nn(X_train,y_train,ins_id,X_test)\n",
    "        pred_num_pred += pred_num/len(seed_list)\n",
    "        coefficients = [1.051, 1.682, 2.231]\n",
    "        temp_inter = 0\n",
    "        temp_score = 0 \n",
    "        \n",
    "        for i in range(400):###100可以继续往上加\n",
    "            t,score = opt_more_coeff(oof_num[list(truncated_groups[:,i*2+seed1])],y_train.loc[list(truncated_groups[:,i*2+seed1])],[1.051, 1.682, 2.231])\n",
    "\n",
    "            temp_inter +=np.array(t)/400\n",
    "            temp_score +=score/400\n",
    "        print(temp_inter)\n",
    "        print('mean cappa',temp_score)\n",
    "        temp_score_overall.append(temp_score)\n",
    "        \n",
    "        coefficients2 = list(temp_inter)\n",
    "        print('New threshold',coefficients2)\n",
    "        y_pred_class = get_pred(pred_num,coefficients2)\n",
    "        print(pd.Series(y_pred_class).value_counts())\n",
    "        cappa1 = qwk(y_train,get_pred(oof_num,coefficients2))\n",
    "        cappa_list.append(cappa1)\n",
    "        oof_class = get_pred(oof_num,coefficients2)\n",
    "        oof_class_list.append(oof_class)\n",
    "        oof_num_mean += oof_num/len(seed_list)\n",
    "        rmse_list.append(rmse)\n",
    "        pred_class_list.append(y_pred_class)\n",
    "    print('Overall situation-----------------------')\n",
    "    print('Mean rmse {}'.format(round(np.mean(rmse_list),5)))\n",
    "    print('Mean cappa {}'.format(round(np.mean(temp_score_overall),5)))\n",
    "    impor2 = 0\n",
    "\n",
    "    return voting(np.vstack(tuple(pred_class_list))),impor2,voting(np.vstack(tuple(oof_class_list))),oof_num_mean,pred_num_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_time = pd.read_csv('/kaggle/input/dsb-media-sequence/media_sequence.csv')\n",
    "clip_time = clip_time[clip_time.type == 'Clip']\n",
    "clip_time= clip_time[['title','duration']].set_index('title')['duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_list = ['Cart Balancer (Assessment)',\n",
    " 'Cauldron Filler (Assessment)',\n",
    " 'Mushroom Sorter (Assessment)',\n",
    " 'Chest Sorter (Assessment)',\n",
    " 'Bird Measurer (Assessment)']\n",
    "\n",
    "world_list = ['CRYSTALCAVES','MAGMAPEAK','TREETOPCITY']\n",
    "\n",
    "\n",
    "duration_event_id = ['90efca10', '4ef8cdd3', '9ee1c98c', 'e694a35b', '08fd73f3', '2dc29e21',\n",
    "       '499edb7c', 'e9c52111', 'd185d3ea', 'd3f1e122', 'cdd22e43', 'fcfdffb6',\n",
    "       '84538528', 'c58186bf', 'de26c3a6', '5c2f29ca', '598f4598', '804ee27f',\n",
    "       '56817e2b', '37c53127', '4a4c3d21', '363c86c9', 'e7561dd2', '022b4259',\n",
    "       '5a848010', '562cec5f', '71e712d8', 'd02b7a8e', '30614231', '3323d7e9',\n",
    "       '5f0eb72c', '0db6d71d', '4a09ace1', 'ca11f653', '1c178d24', '46cd75b4',\n",
    "       '00c73085', 'bc8f2793', '36fa3ebe', '16dffff1', '8fee50e2', '392e14df',\n",
    "       '9d4e7b25', 'd06f75b5', '895865f3', 'c1cac9a2', '28520915', 'd51b1749',\n",
    "       'b012cd7f', 'f5b8c21a', '3d0b9317', '9ce586dd', '3d63345e', 'c7128948',\n",
    "       '5348fd84', '83c6c409', '99abe2bb', 'c189aaf2', '99ea62f3', 'b74258a0',\n",
    "       'f6947f54', '6c930e6e', '6088b756', '9ed8f6da', '3edf6747', '53c6e11a',\n",
    "       'a1192f43', '4d6737eb', 'd2659ab4', 'd38c2fd7', '3bb91ced', 'd88ca108',\n",
    "       'a76029ee', '38074c54', '86ba578b', '0d18d96c']\n",
    "\n",
    "misses_id = ['08fd73f3', '56817e2b', '37c53127', '3323d7e9', 'ca11f653', '1c178d24',\n",
    "       '00c73085', '36fa3ebe', '16dffff1', '895865f3', '28520915', 'b012cd7f',\n",
    "       'f5b8c21a', 'b74258a0', 'f6947f54', '6c930e6e', '38074c54']\n",
    "\n",
    "activity_list = ['Bottle Filler (Activity)', 'Sandcastle Builder (Activity)',\n",
    "       'Chicken Balancer (Activity)', 'Fireworks (Activity)',\n",
    "       'Flower Waterer (Activity)', 'Bug Measurer (Activity)',\n",
    "       'Egg Dropper (Activity)', 'Watering Hole (Activity)']\n",
    "\n",
    "list_4020_4030 = {'Bottle Filler (Activity)':[4020,4030],\n",
    "                 'Bug Measurer (Activity)':[4030],\n",
    "                 'Chicken Balancer (Activity)':[4020,4030],\n",
    "                 'Egg Dropper (Activity)':[4020],\n",
    "                 'Fireworks (Activity)':[4020,4030],\n",
    "                 'Flower Waterer (Activity)':[4020,4030],\n",
    "                 'Sandcastle Builder (Activity)':[4020,4030],\n",
    "                 'Watering Hole (Activity)':[4020]}\n",
    "\n",
    "game_list = ['Chow Time', 'Scrub-A-Dub', 'All Star Sorting', 'Dino Drink',\n",
    "       'Bubble Bath', 'Crystals Rule', 'Dino Dive', 'Pan Balance',\n",
    "       'Happy Camel', 'Air Show', 'Leaf Leader']\n",
    "\n",
    "def get_data(user_sample,test_set = False):\n",
    "    \n",
    "\n",
    "    duration_id_list = {eve:0 for eve in duration_event_id}\n",
    "    duration_id_count = {eve:0 for eve in duration_event_id}\n",
    "    clip_abandon = 0\n",
    "    \n",
    "    activity_abandon_dict = {eve:0 for eve in activity_list}\n",
    "    activity_abandon_cnt = {eve:0 for eve in activity_list}\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #### round\n",
    "    num_round_list = []\n",
    "    num_round_max_list = []\n",
    "\n",
    "    round_title_max_dict = {'round_Scrub-A-Dub_max':[], \n",
    "                         'round_Dino Drink_max':[], \n",
    "                         'round_All Star Sorting_max':[], \n",
    "                         'round_Air Show_max':[],\n",
    "                        'round_Crystals Rule_max':[],\n",
    "                         'round_Bubble Bath_max':[], \n",
    "                         'round_Bottle Filler (Activity)_max':[],\n",
    "                        'round_Dino Dive_max':[], \n",
    "                         'round_Chow Time_max':[], \n",
    "                         'round_Pan Balance_max':[], \n",
    "                         'round_Happy Camel_max':[],\n",
    "                        'round_Leaf Leader_max':[]}    \n",
    "    \n",
    "    #### misss\n",
    "    num_miss = []\n",
    "    miss_id_list = {eve:[] for eve in misses_id}\n",
    "    miss_37c53127_dict = {'123':[],'456':[],'789':[],'other_level':[]}\n",
    "    level_37c53127_list = []\n",
    "    level_37c53127_list_max = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###加时间\n",
    "    count_game_diff_assessment = 0\n",
    "    count_assessment_diff_assessment = 0 \n",
    "    count_activity_diff_assessment = 0 \n",
    "    count_clip_diff_assessment = 0\n",
    "    \n",
    "    last_world = -1\n",
    "    ###1是计算是不是有直接开始assessment\n",
    "    shangyici_world_time1 = {'syc_MAGMAPEAK':[],'syc_TREETOPCITY':[],'syc_CRYSTALCAVES':[]}\n",
    "    shangyici_world_time2 = {'syc_MAGMAPEAK':[],'syc_TREETOPCITY':[],'syc_CRYSTALCAVES':[]}\n",
    "    shangyici_test_time = {'syc_Mushroom Sorter (Assessment)':[],'syc_Chest Sorter (Assessment)':[],'syc_Bird Measurer (Assessment)':[],\n",
    "                           'syc_Cauldron Filler (Assessment)':[],'syc_Cart Balancer (Assessment)':[]}\n",
    "    #accumulated_actions = 0\n",
    "    time_in_session = -1\n",
    "    durations = []\n",
    "    all_times = 0\n",
    "    count_type_dict = {'count_Game':0,'count_Assessment':0,'count_Activity':0,'count_Clip':0}\n",
    "    count_world_dict = {'count_MAGMAPEAK':0,'count_TREETOPCITY':0,'count_CRYSTALCAVES':0}\n",
    "    time_type_dict = {'time_Game':0,'time_Assessment':0,'time_Activity':0,'time_Clip':0}\n",
    "    time_world_dict = {'time_MAGMAPEAK':0,'time_TREETOPCITY':0,'time_CRYSTALCAVES':0}\n",
    "    count_session = 0\n",
    "    num_th_assess = 0\n",
    "    all_features = []\n",
    "    child_id = user_sample.installation_id.values[0]\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    abandon_times = 0\n",
    "    game_abandon = 0\n",
    "    games_all = 0##game_all 会统一统计 可以删去\n",
    "    num_game_correct = 0\n",
    "    num_game_false = 0\n",
    "    accum_avg_acc=[]\n",
    "    accum_avg_group = []\n",
    "    times_game_no_success = 0\n",
    "    times_game_success = 0\n",
    "    game_correct_list = []##acc_list\n",
    "    num_enter_game = 0\n",
    "    enter_game_acc_list = []\n",
    "    enter_game_num_corr = 0\n",
    "    enter_game_num_false = 0\n",
    "    grp_assess_list = {'grp_Bird Measurer (Assessment)':[],'grp_Chest Sorter (Assessment)':[],\\\n",
    "                              'grp_Cauldron Filler (Assessment)':[],'grp_Cart Balancer (Assessment)':[],\\\n",
    "                              'grp_Mushroom Sorter (Assessment)':[]}\n",
    "    acc_assess_list = {'acc_Bird Measurer (Assessment)':[],'acc_Chest Sorter (Assessment)':[],\\\n",
    "                              'acc_Cauldron Filler (Assessment)':[],'acc_Cart Balancer (Assessment)':[],\\\n",
    "                              'acc_Mushroom Sorter (Assessment)':[]}\n",
    "    curr_world_type_time={'time_Game_curr_world':0,'time_Assessment_curr_world':0,'time_Activity_curr_world':0,'time_Clip_curr_world':0}\n",
    "    curr_world_type_cnt = {'count_Game_curr_world':0,'count_Assessment_curr_world':0,'count_Activity_curr_world':0,'count_Clip_curr_world':0}\n",
    "    curr_world_type_time_all = 0\n",
    "    curr_world_type_count_all = 0\n",
    "    event_code_count = {ev: 0 for ev in list_of_event_code}\n",
    "    event_id_count = {eve: 0 for eve in list_of_event_id}\n",
    "    title_count = {eve: 0 for eve in list_title}\n",
    "    title_event_code_count = {t_eve: 0 for t_eve in list_title_event_code}\n",
    "\n",
    "    \n",
    "    for i,session in user_sample.groupby('game_session',sort=False):\n",
    "        session_type = session.type.values[0]\n",
    "        session_title = session.title.values[0]\n",
    "        session_world = session.world.values[0]\n",
    "        session_time_stamp_min = session.timestamp.min()\n",
    "        session_time_stamp_max = session.timestamp.max()\n",
    "        \n",
    "        if session_title == 'Welcome to Lost Lagoon!':\n",
    "            num_enter_game +=1\n",
    "            enter_game_acc_list = []\n",
    "            enter_game_num_corr = 0\n",
    "            enter_game_num_false = 0\n",
    "        \n",
    "        if session_type == 'Game':\n",
    "            games_all +=1\n",
    "            game_assess_df = session[session.event_data.str.contains('\"correct\":')].copy()\n",
    "            if game_assess_df.shape[0] >0:\n",
    "                num_corr = np.sum(session.event_data.str.contains('\"correct\":true').astype(int))\n",
    "                num_false = np.sum(session.event_data.str.contains('\"correct\":false').astype(int))\n",
    "                num_game_correct += num_corr\n",
    "                num_game_false += num_false\n",
    "                enter_game_num_corr += num_corr\n",
    "                enter_game_num_false +=num_false\n",
    "                game_correct_list.append(num_corr/(num_corr + num_false))\n",
    "                enter_game_acc_list.append(num_corr/(num_corr + num_false))\n",
    "                if num_false>0 and num_corr==0:\n",
    "                    times_game_no_success +=1\n",
    "                if num_corr >0:\n",
    "                    times_game_success +=1\n",
    "            else:\n",
    "                game_abandon +=1\n",
    "             \n",
    "        \n",
    "        if session_type == 'Assessment':\n",
    "            session_attempt = session[((session.event_code==4100)&(session.title != 'Bird Measurer (Assessment)'))\\\n",
    "              |((session.event_code==4110)&(session.title == 'Bird Measurer (Assessment)'))]\n",
    "            mark = (test_set & (len(session)==1) & (session.event_code.values[0]==2000))\n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "            if (session_attempt.shape[0]>0)|mark:\n",
    "                shangyici_test_time['syc_'+session_title].append(session_time_stamp_min)\n",
    "                shangyici_world_time1['syc_'+session_world].append(session_time_stamp_min)\n",
    "                features = dict()\n",
    "                ####miss\n",
    "                features['sum_num_miss'] = np.sum(num_miss) if len(num_miss)!=0 else -1  \n",
    "                features['mean_num_miss'] = np.mean(num_miss) if len(num_miss)!=0 else -1\n",
    "                temp_dict = {'mean_num_miss'+key:np.mean(values) if len(values)!=0 else -1 for key,values in miss_id_list.items()}\n",
    "                features.update(temp_dict.copy())\n",
    "                temp_dict = {'sum_num_miss'+key:np.sum(values) if len(values)!=0 else -1 for key,values in miss_id_list.items()}\n",
    "                features.update(temp_dict.copy())\n",
    "                temp_dict = {'last_5_sum_num_miss'+key:np.sum(values[-5:]) if len(values)!=0 else -1 for key,values in miss_id_list.items()}\n",
    "                features.update(temp_dict.copy())\n",
    "#                 temp_dict = {'mean_num_miss_level_37c53127'+key:np.mean(values) if len(values)!=0 else -1 for key,values in miss_37c53127_dict.items()}\n",
    "#                 features.update(temp_dict)\n",
    "#                 temp_dict = {'sum_num_miss_level_37c53127'+key:np.sum(values) if len(values)!=0 else -1 for key,values in miss_37c53127_dict.items()}\n",
    "#                 features.update(temp_dict)\n",
    "#                 temp_dict = {'length_num_miss_level_37c53127'+key:len(values) for key,values in miss_37c53127_dict.items()}\n",
    "#                 features.update(temp_dict)\n",
    "                features['mean_level_37c53127'] = np.mean(level_37c53127_list) if len(level_37c53127_list)!=0 else -1\n",
    "                features['mean_level_37c53127_max'] = np.mean(level_37c53127_list_max) if len(level_37c53127_list_max)!=0 else -1\n",
    "#                 features['sum_level_37c53127_max'] = np.sum(level_37c53127_list_max) if len(level_37c53127_list_max)!=0 else -1\n",
    "                \n",
    "                #####\n",
    "\n",
    "                temp_dict = {'overall_mean_'+key: values/duration_id_count[key] if duration_id_count[key]!=0 else -1 for key,values in duration_id_list.items()}\n",
    "                features.update(temp_dict.copy())\n",
    "                temp_dict = {'overall_sum_'+key:values for key,values in duration_id_list.items()}\n",
    "                features.update(temp_dict.copy())\n",
    "\n",
    "                \n",
    "                \n",
    "                features['num_round_list'] = np.mean(num_round_list) if len(num_round_list)!=0 else -1\n",
    "                features['num_round_max_list'] = np.mean(num_round_max_list) if len(num_round_max_list)!=0 else -1\n",
    "                features['num_round_max_sum'] = np.sum(num_round_max_list) if len(num_round_max_list)!=0 else -1\n",
    "                features['num_round_max_std'] = np.std(num_round_max_list) if len(num_round_max_list)!=0 else -1\n",
    "\n",
    "\n",
    "                temp_round_max_title = {'mean1_'+key:np.mean(value) if len(value)!=0 else -1 for key,value in round_title_max_dict.items()}\n",
    "                features.update(temp_round_max_title.copy())\n",
    "                temp_round_max_title = {'sum1_'+key:np.sum(value) if len(value)!=0 else -1 for key,value in round_title_max_dict.items()}\n",
    "                features.update(temp_round_max_title.copy())\n",
    "                \n",
    "                #features['accumulated_actions'] = accumulated_actions\n",
    "                features['last_session_time'] = time_in_session\n",
    "                #features['all_times']= all_times\n",
    "                features['duration_mean'] = np.mean(durations) if len(durations)!=0 else -1\n",
    "                features['duration_std'] = np.std(durations) if len(durations)!=0 else -1\n",
    "                features['mean_game_acc'] = np.mean(game_correct_list) if len(game_correct_list)!=0 else -1\n",
    "                features['std_game_acc'] = np.std(game_correct_list) if len(game_correct_list)!=0 else -1\n",
    "                features['mean_enter_game_acc'] = np.mean(enter_game_acc_list) if len(enter_game_acc_list)!=0 else -1\n",
    "                features['std_enter_game_acc'] = np.std(enter_game_acc_list) if len(enter_game_acc_list)!=0 else -1\n",
    "                #features['last_5_mean_game_acc'] = np.mean(game_correct_list[-5:]) if len(game_correct_list)!=0 else -1\n",
    "                features['last_1_mean_game_acc'] = game_correct_list[-1] if len(game_correct_list)!=0 else -1\n",
    "                features['count_game_acc'] = len(game_correct_list)\n",
    "                features['num_enter_game'] = num_enter_game\n",
    "                features.update(event_code_count.copy())\n",
    "                features.update(event_id_count.copy())\n",
    "                features.update(title_count.copy())\n",
    "                features.update(title_event_code_count.copy())\n",
    "                features.update(count_type_dict.copy())\n",
    "                features.update(count_world_dict.copy())\n",
    "                features['clip_abandon'] = clip_abandon\n",
    "                features['clip_abandon_ratio'] = clip_abandon/features['count_Clip'] if features['count_Clip']!=0 else -1\n",
    "\n",
    "                \n",
    "\n",
    "                \n",
    "                temp_dict = {'abandon_ratio_'+eve:values/activity_abandon_cnt[eve] if activity_abandon_cnt[eve]!=0 else -1 \\\n",
    "                             for eve,values in activity_abandon_dict.items()}\n",
    "                features.update(temp_dict.copy())\n",
    "                \n",
    "                temp_dict = {'abandon_cnt_'+eve:values for eve,values in activity_abandon_dict.items()}\n",
    "                features.update(temp_dict.copy())\n",
    "                \n",
    "                \n",
    "                if session_world!='NONE':\n",
    "                    features['curr_world_time'] = time_world_dict['time_'+session_world]\n",
    "                    #features['curr_world_time_per'] = time_world_dict['time_'+session_world]/all_times if all_times!=0 else -1\n",
    "                features['count_session'] = count_session\n",
    "                features.update(time_type_dict.copy())\n",
    "                features.update(time_world_dict.copy())\n",
    "                \n",
    "                temp_acc_assess_list = {key: np.mean(values) if len(values)!=0 else -1 for key,values in acc_assess_list.items()}\n",
    "                features.update(temp_acc_assess_list.copy())\n",
    "\n",
    "\n",
    "                #features['times_game_no_success'] = times_game_no_success\n",
    "                #features['times_game_success'] = times_game_success\n",
    "                features['ratio_time_game_success'] = times_game_success/(times_game_success + times_game_no_success) if (times_game_success + times_game_no_success)!=0 else -1\n",
    "                features.update(accuracy_groups.copy())\n",
    "                temp_all = accuracy_groups[0] + accuracy_groups[1] + accuracy_groups[2] + accuracy_groups[3]\n",
    "                if temp_all==0:\n",
    "                    features['0_ratio'] = 0\n",
    "                    features['1_ratio'] = 0\n",
    "                    features['2_ratio'] = 0\n",
    "                    features['3_ratio'] = 0\n",
    "                else:\n",
    "                    features['0_ratio'] = accuracy_groups[0]/temp_all\n",
    "                    features['1_ratio'] = accuracy_groups[1]/temp_all\n",
    "                    features['2_ratio'] = accuracy_groups[2]/temp_all\n",
    "                    features['3_ratio'] = accuracy_groups[3] /temp_all  \n",
    "                features['installation_id'] = child_id\n",
    "                features['game_session'] = i\n",
    "                features['title'] = session_title\n",
    "                features['world'] = session_world\n",
    "                features['num_th_assess'] = num_th_assess\n",
    "                features['abandon_times'] = abandon_times\n",
    "                num_th_assess += 1\n",
    "                features['accum_avg_acc'] = np.mean(accum_avg_acc) if len(accum_avg_acc)!=0 else -1\n",
    "                features['accum_avg_group'] = np.mean(accum_avg_group) if len(accum_avg_group)!=0 else -1\n",
    "                features['accum_std_acc'] = np.std(accum_avg_acc) if len(accum_avg_acc)!=0 else -1\n",
    "                features['accum_std_group'] = np.std(accum_avg_group) if len(accum_avg_group)!=0 else -1\n",
    "\n",
    "                features['last_5_accum_avg_acc'] = np.mean(accum_avg_acc[-5:]) if len(accum_avg_acc)!=0 else -1\n",
    "                #features['last_5_accum_avg_group'] = np.mean(accum_avg_group[-5:]) if len(accum_avg_group)!=0 else -1\n",
    "                features['last_5_accum_std_acc'] = np.std(accum_avg_acc[-5:]) if len(accum_avg_acc)!=0 else -1\n",
    "                features['last_5_accum_std_group'] = np.std(accum_avg_group[-5:]) if len(accum_avg_group)!=0 else -1\n",
    "                #features['last_1_accum_avg_acc'] = accum_avg_acc[-1] if len(accum_avg_acc)!=0 else -1\n",
    "                features['last_1_accum_avg_group'] = accum_avg_group[-1] if len(accum_avg_group)!=0 else -1\n",
    "                ###加这两个的count\n",
    "                features['overall_game_corr_ratio'] = num_game_correct/(num_game_correct + num_game_false) if (num_game_correct + num_game_false)!=0 else -1\n",
    "                features['enter_game_overall_game_corr_ratio'] = enter_game_num_corr/(enter_game_num_corr + enter_game_num_false) if (enter_game_num_corr + enter_game_num_false) !=0 else -1\n",
    "\n",
    "                \n",
    "                features['game_abandon'] = game_abandon\n",
    "                features['game_abandon_ratio'] = game_abandon/games_all if games_all!=0 else -1\n",
    "                features['mean_same_assess_grp'] = np.mean(grp_assess_list['grp_'+session_title]) if len(grp_assess_list['grp_'+session_title])!=0 else -1\n",
    "                features['mean_same_assess_acc'] = np.mean(acc_assess_list['acc_'+session_title]) if len(acc_assess_list['acc_'+session_title])!=0 else -1\n",
    "                features['std_same_assess_grp'] = np.std(grp_assess_list['grp_'+session_title]) if len(grp_assess_list['grp_'+session_title])!=0 else -1\n",
    "                features['std_same_assess_acc'] = np.std(acc_assess_list['acc_'+session_title]) if len(acc_assess_list['acc_'+session_title])!=0 else -1\n",
    "                features['count_same_assess_grp'] = len(grp_assess_list['grp_'+session_title])\n",
    "\n",
    "                features['last_3_mean_same_assess_grp'] = np.mean(grp_assess_list['grp_'+session_title][-3:]) if len(grp_assess_list['grp_'+session_title])!=0 else -1\n",
    "                features['last_3_mean_same_assess_acc'] = np.mean(acc_assess_list['acc_'+session_title][-3:]) if len(acc_assess_list['acc_'+session_title])!=0 else -1\n",
    "                \n",
    "                features['last_1_mean_same_assess_grp'] = grp_assess_list['grp_'+session_title][-1] if len(grp_assess_list['grp_'+session_title])!=0 else -1\n",
    "                features['last_1_mean_same_assess_acc'] = acc_assess_list['acc_'+session_title][-1] if len(acc_assess_list['acc_'+session_title])!=0 else -1\n",
    "                \n",
    "                features['last_test_to_now_time'] = (shangyici_test_time['syc_'+session_title][-1] \\\n",
    "                                                     - shangyici_test_time['syc_'+session_title][-2]).total_seconds() if len(shangyici_test_time['syc_'+session_title])>=2 else -1\n",
    "                features['last_world_to_now_time1'] =  (shangyici_world_time1['syc_'+session_world][-1]\\\n",
    "                                                        - shangyici_world_time1['syc_'+session_world][-2]).total_seconds() if len(shangyici_world_time1['syc_'+session_world])>=2 else -1\n",
    "                features['last_world_to_now_time2'] =  (shangyici_world_time2['syc_'+session_world][-1]\\\n",
    "                                                        - shangyici_world_time2['syc_'+session_world][-2]).total_seconds() if len(shangyici_world_time2['syc_'+session_world])>=2 else -1\n",
    "                features['count_game_diff_assessment'] = count_game_diff_assessment\n",
    "                features['count_assessment_diff_assessment'] = count_assessment_diff_assessment\n",
    "                features['count_activity_diff_assessment'] = count_activity_diff_assessment\n",
    "                features['count_clip_diff_assessment'] = count_clip_diff_assessment\n",
    "                features.update(curr_world_type_time.copy())\n",
    "                features.update(curr_world_type_cnt.copy())\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "#                 features['curr_world_type_time_all'] = curr_world_type_time_all\n",
    "#                 features['curr_world_type_count_all'] = curr_world_type_count_all\n",
    "                if not mark:\n",
    "                    true_attempt = np.sum(session_attempt.event_data.str.contains('\"correct\":true').astype(int))\n",
    "                    false_attempt = np.sum(session_attempt.event_data.str.contains('\"correct\":false').astype(int))\n",
    "                    features['accuracy'] = true_attempt/(true_attempt + false_attempt) if (true_attempt + false_attempt)!=0 else 0\n",
    "                    features['accuracy_group'] = to_accuracy_group(features['accuracy'])\n",
    "                    accum_avg_acc.append(features['accuracy'])\n",
    "                    accum_avg_group.append(features['accuracy_group'])\n",
    "                    accuracy_groups[features['accuracy_group']] += 1\n",
    "                    grp_assess_list['grp_'+session_title].append(features['accuracy_group'])\n",
    "                    acc_assess_list['acc_'+session_title].append(features['accuracy'])\n",
    "                all_features.append(features)\n",
    "                count_game_diff_assessment = 0\n",
    "                count_assessment_diff_assessment = 0\n",
    "                count_activity_diff_assessment = 0\n",
    "                count_clip_diff_assessment = 0\n",
    "            else:\n",
    "                abandon_times +=1\n",
    "            \n",
    "        def update_counters(counter, col):\n",
    "            num_of_session_count = Counter(session[col])\n",
    "            for k in num_of_session_count.keys():\n",
    "                x = k\n",
    "                counter[x] += num_of_session_count[k]\n",
    "            return counter\n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count,'title_event_code')\n",
    "        count_session +=1\n",
    "        count_type_dict['count_'+session_type] +=1\n",
    "        if session_type != 'Clip':\n",
    "            time_in_session = (session_time_stamp_max - session_time_stamp_min).total_seconds()\n",
    "        else:\n",
    "            try:\n",
    "                temp_time = session.timestamp.min()\n",
    "                temp_index = session.index[0]+1\n",
    "                time_in_session = ((user_sample.loc[temp_index,'timestamp']) - temp_time).total_seconds()\n",
    "                if time_in_session >clip_time[session_title]:\n",
    "                    time_in_session = clip_time[session_title]\n",
    "            except:\n",
    "                time_in_session = clip_time[session_title]\n",
    "            if time_in_session < 0.5*clip_time[session_title]:\n",
    "                clip_abandon +=1\n",
    "        time_type_dict['time_'+session_type] += time_in_session\n",
    "        durations.append(time_in_session)\n",
    "        all_times +=time_in_session\n",
    "        if session_world!='NONE':\n",
    "            count_world_dict['count_'+session_world] +=1\n",
    "            time_world_dict['time_'+session_world] += time_in_session\n",
    "        #accumulated_actions += len(session)\n",
    "        \n",
    "        if session_world!=last_world:\n",
    "            curr_world_type_time={'time_Game_curr_world':0,'time_Assessment_curr_world':0,'time_Activity_curr_world':0,'time_Clip_curr_world':0}\n",
    "            curr_world_type_cnt = {'count_Game_curr_world':0,'count_Assessment_curr_world':0,'count_Activity_curr_world':0,'count_Clip_curr_world':0}\n",
    "#             curr_world_type_time_all = 0\n",
    "#             curr_world_type_count_all = 0\n",
    "            if session_world != 'NONE':\n",
    "                shangyici_world_time2['syc_'+session_world].append(session_time_stamp_min)\n",
    "            last_world = session_world\n",
    "        if session_world != 'NONE':\n",
    "#             curr_world_type_time_all +=time_in_session\n",
    "#             curr_world_type_count_all +=1\n",
    "            curr_world_type_time['time_'+session_type+'_curr_world'] +=time_in_session\n",
    "            curr_world_type_cnt['count_'+session_type+'_curr_world'] +=1\n",
    "        #####1230 count4070系列\n",
    "        \n",
    "        if session_type == 'Game':\n",
    "            count_game_diff_assessment +=1\n",
    "        if session_type == 'Activity':\n",
    "            count_activity_diff_assessment+=1\n",
    "        if session_type == 'Assessment':\n",
    "            count_assessment_diff_assessment+=1\n",
    "        if session_type =='Clip':\n",
    "            count_clip_diff_assessment +=1\n",
    "        session_miss = session[session.event_data.str.contains('\"misses\":')].copy()\n",
    "        if session_miss.shape[0]>0:\n",
    "            session_miss['num_miss'] = session_miss.event_data.map(lambda x:json.loads(x)['misses'])\n",
    "            for id1,miss in zip(session_miss['event_id'],session_miss['num_miss']):\n",
    "                num_miss.append(miss)\n",
    "                miss_id_list[id1].append(miss)\n",
    "            session_37c53127 = session_miss[session_miss.event_id=='37c53127']\n",
    "            if session_37c53127.shape[0]>0:\n",
    "                session_37c53127['level'] = session_37c53127.event_data.map(lambda x:json.loads(x)['level'])\n",
    "                level_37c53127_list_max.append(np.max(session_37c53127['level']))\n",
    "                for level,miss in zip(session_37c53127['level'],session_37c53127['num_miss']):\n",
    "                    level_37c53127_list.append(level)\n",
    "#                     if level in [1,2,3]:\n",
    "#                         miss_37c53127_dict['123'].append(miss)\n",
    "#                     elif level in [4,5,6]:\n",
    "#                         miss_37c53127_dict['456'].append(miss)\n",
    "#                     elif level in [7,8,9]:\n",
    "#                         miss_37c53127_dict['789'].append(miss)\n",
    "#                     else:\n",
    "#                         miss_37c53127_dict['other_level'].append(miss)\n",
    "                    \n",
    "\n",
    "        ####round\n",
    "        session_round = session[(session.event_data.str.contains('\"round\":'))&(session.event_code==2030)].copy()\n",
    "        if session_round.shape[0]>0:\n",
    "            session_round = session[session.event_data.str.contains('\"round\":')].copy()\n",
    "            session_round['num_round'] = session_round.event_data.map(lambda x:json.loads(x)['round'])\n",
    "            num_round_list.extend(list(session_round.num_round))\n",
    "            num_round_max_list.append(np.max(session_round.num_round))\n",
    "            round_title_max_dict['round_'+session_title+'_max'].append(np.max(session_round.num_round))\n",
    "        if np.sum(session.event_data.str.contains('\"duration\":'))>0:\n",
    "            session_duration = session[(session.event_data.str.contains('\"duration\":'))&(session.event_id.map(lambda x:x in duration_event_id))].copy()\n",
    "            if session_duration.shape[0]>0:\n",
    "                session_duration['duration'] = session_duration.event_data.map(lambda x:json.loads(x)['duration'])\n",
    "                for id1,duration in zip(session_duration['event_id'],session_duration['duration']):\n",
    "\n",
    "                    duration_id_list[id1] += duration\n",
    "                    duration_id_count[id1] += 1\n",
    "        if session_type=='Activity':\n",
    "            activity_abandon_cnt[session_title]+=1\n",
    "            if session_title in ['Bottle Filler (Activity)','Chicken Balancer (Activity)',\n",
    "                                'Fireworks (Activity)','Flower Waterer (Activity)','Sandcastle Builder (Activity)']:\n",
    "                num_4020 = np.sum(session.event_code==4020)\n",
    "                num_4030 = np.sum(session.event_code==4030)\n",
    "                if num_4020==0 or num_4030 ==0:\n",
    "                    activity_abandon_dict[session_title]+=1\n",
    "            elif session_title in ['Bug Measurer (Activity)']:\n",
    "                num_4030 = np.sum(session.event_code==4030)\n",
    "                if num_4030 ==0:\n",
    "                    activity_abandon_dict[session_title]+=1\n",
    "            elif session_title in ['Egg Dropper (Activity)','Watering Hole (Activity)']:\n",
    "                num_4020 = np.sum(session.event_code==4020)\n",
    "                if num_4020 ==0:\n",
    "                    activity_abandon_dict[session_title]+=1\n",
    "\n",
    "\n",
    "\n",
    "    if test_set:\n",
    "        return all_features[-1]    \n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17000/17000 [54:43<00:00,  5.18it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_train(train):\n",
    "    train_all = []\n",
    "    for ins_id,user_sample in tqdm(train.groupby('installation_id',sort=False)):\n",
    "        train_all.extend(get_data(user_sample))\n",
    "    return pd.DataFrame(train_all)\n",
    "train_all=get_train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:20<00:00,  3.12it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_train(train):\n",
    "    train_all = []\n",
    "    for ins_id,user_sample in tqdm(train.groupby('installation_id',sort=False)):\n",
    "        train_all.extend(get_data(user_sample))\n",
    "    return pd.DataFrame(train_all)\n",
    "train_all_test=get_train(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = train_all.append(train_all_test,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:22<00:00,  3.10it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_test(test):\n",
    "    test_all = []\n",
    "    for ins_id,user_sample in tqdm(test.groupby('installation_id',sort=False)):\n",
    "        test_all.append(get_data(user_sample,test_set = True))\n",
    "    return pd.DataFrame(test_all)\n",
    "\n",
    "test_all = get_test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_all.accuracy_group.copy()\n",
    "drop_col = ['accuracy','game_session','accuracy_group','installation_id']\n",
    "ins_id = train_all.installation_id\n",
    "X_train = train_all.drop(drop_col,axis=1)\n",
    "X_test = test_all.drop(['game_session','installation_id'],axis=1)\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_test.columns = X_test.columns.astype(str)\n",
    "X_train = X_train[sorted(X_train.columns.tolist())]\n",
    "X_test = X_test[sorted(X_test.columns.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in X_train.columns:\n",
    "    if (X_train[f].dtype=='object') or (X_test[f].dtype=='object'): \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f])+list(X_test[f]))\n",
    "        X_train[f] = lbl.transform(list(X_train[f]))\n",
    "        X_test[f] = lbl.transform(list(X_test[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = X_train.columns.tolist()\n",
    "num_features = all_features.copy()\n",
    "num_features.remove('world')\n",
    "num_features.remove('title')\n",
    "cat_features = ['world','title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### choose top n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19708, 700)\n"
     ]
    }
   ],
   "source": [
    "X_train.drop(orders[700:],axis=1,inplace = True)\n",
    "X_test.drop(orders[700:],axis=1,inplace = True)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19708, 700)\n",
      "(19708, 873)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "missing_boolen_list = []\n",
    "for _ in num_features:\n",
    "    if _ in X_train.columns:\n",
    "        if X_train[_].min()==-1:\n",
    "            X_train[_+'missing_boolen'] = list(np.where(X_train[_]==-1,1,0))\n",
    "            X_test[_+'missing_boolen'] = list(np.where(X_test[_]==-1,1,0))\n",
    "            missing_boolen_list.append(_+'missing_boolen')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.replace(-1,0,inplace=True)\n",
    "X_test.replace(-1,0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features1 = list(set(num_features).intersection(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train[num_features1] = np.log1p(X_train[num_features1])\n",
    "X_test[num_features1] = np.log1p(X_test[num_features1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train[num_features1].copy()\n",
    "X_test_num = X_test[num_features1].copy()\n",
    "X_train_cat = X_train[cat_features].copy()\n",
    "X_test_cat = X_test[cat_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds = StandardScaler()\n",
    "sds.fit(X_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num_ted = pd.DataFrame(sds.transform(X_train_num),columns=num_features1)\n",
    "X_test_num_ted = pd.DataFrame(sds.transform(X_test_num),columns=num_features1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = OneHotEncoder(sparse=False)\n",
    "one_hot.fit(X_train_cat)\n",
    "X_train_cat_ted = pd.DataFrame(one_hot.transform(X_train_cat),columns=one_hot.get_feature_names(['world','title']))\n",
    "X_test_cat_ted = pd.DataFrame(one_hot.transform(X_test_cat),columns=one_hot.get_feature_names(['world','title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_num_ted,X_train_cat_ted,X_train[missing_boolen_list]],axis=1)\n",
    "X_test = pd.concat([X_test_num_ted,X_test_cat_ted,X_test[missing_boolen_list]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19708, 879)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug for \"LightGBMError: Do not support special JSON characters in feature name.\"\n",
    "\n",
    "X_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_train.columns]\n",
    "X_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19708, 879)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random1(ins_id,sample_size):\n",
    "    list1 = []\n",
    "    for id1 in ins_id.unique():\n",
    "        temp_list = list(ins_id[ins_id == id1].index)\n",
    "        list1.append(list(np.random.choice(temp_list,sample_size)))\n",
    "    return np.array(list1)\n",
    "\n",
    "truncated_groups = random1(ins_id,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 th seed begins----------------------\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.7065 - val_loss: 3.3368\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.7312 - val_loss: 2.0891\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.8472 - val_loss: 1.4752\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.3551 - val_loss: 1.1746\n",
      "Epoch 5/300\n",
      " - 2s - loss: 2.1022 - val_loss: 1.1365\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.9336 - val_loss: 1.0789\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.8073 - val_loss: 1.0352\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6713 - val_loss: 1.0439\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.6121 - val_loss: 1.0378\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.5450 - val_loss: 1.0342\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4742 - val_loss: 1.0086\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.4226 - val_loss: 1.0241\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3871 - val_loss: 1.0179\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.3333 - val_loss: 1.0435\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2922 - val_loss: 0.9989\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2680 - val_loss: 0.9819\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2349 - val_loss: 0.9942\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.2254 - val_loss: 0.9929\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1950 - val_loss: 0.9914\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1586 - val_loss: 0.9837\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1328 - val_loss: 0.9707\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1471 - val_loss: 0.9722\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.1150 - val_loss: 0.9670\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.1296 - val_loss: 0.9683\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0926 - val_loss: 0.9638\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.1129 - val_loss: 0.9763\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0956 - val_loss: 0.9767\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0832 - val_loss: 0.9804\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0791 - val_loss: 0.9772\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0632 - val_loss: 1.0006\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0697 - val_loss: 0.9612\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0486 - val_loss: 0.9713\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0550 - val_loss: 0.9648\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0574 - val_loss: 0.9734\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0297 - val_loss: 0.9630\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0432 - val_loss: 0.9655\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0197 - val_loss: 0.9617\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0387 - val_loss: 0.9689\n",
      "Epoch 39/300\n",
      " - 2s - loss: 1.0127 - val_loss: 0.9649\n",
      "Epoch 40/300\n",
      " - 2s - loss: 1.0169 - val_loss: 0.9771\n",
      "Epoch 41/300\n",
      " - 2s - loss: 1.0089 - val_loss: 0.9650\n",
      "Epoch 42/300\n",
      " - 2s - loss: 1.0032 - val_loss: 0.9653\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9917 - val_loss: 0.9649\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9837 - val_loss: 0.9681\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9888 - val_loss: 0.9670\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9754 - val_loss: 0.9666\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9859 - val_loss: 0.9686\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9739 - val_loss: 0.9670\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9913 - val_loss: 0.9631\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9737 - val_loss: 0.9651\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9701 - val_loss: 0.9748\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9758 - val_loss: 0.9656\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9755 - val_loss: 0.9740\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9599 - val_loss: 0.9708\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9647 - val_loss: 0.9720\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9483 - val_loss: 0.9690\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9621 - val_loss: 0.9768\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9510 - val_loss: 0.9702\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9481 - val_loss: 0.9674\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9398 - val_loss: 0.9709\n",
      "Epoch 61/300\n",
      " - 2s - loss: 0.9522 - val_loss: 0.9698\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00061: early stopping\n",
      "rse: 0.980386511263207\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 3s - loss: 5.3722 - val_loss: 3.4150\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.6605 - val_loss: 2.3118\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7408 - val_loss: 1.6278\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2158 - val_loss: 1.2794\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9667 - val_loss: 1.2108\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8002 - val_loss: 1.1069\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7063 - val_loss: 1.0993\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.5866 - val_loss: 1.0967\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5227 - val_loss: 1.0630\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4500 - val_loss: 1.0755\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4174 - val_loss: 1.0400\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3663 - val_loss: 1.0407\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3160 - val_loss: 1.0393\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2695 - val_loss: 1.0390\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2510 - val_loss: 1.0343\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2147 - val_loss: 1.0158\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.1997 - val_loss: 1.0145\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1712 - val_loss: 1.0196\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1358 - val_loss: 1.0361\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1349 - val_loss: 1.0003\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1083 - val_loss: 1.0011\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1041 - val_loss: 1.0028\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0854 - val_loss: 0.9966\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.1037 - val_loss: 1.0036\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0675 - val_loss: 1.0019\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0761 - val_loss: 1.0232\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0658 - val_loss: 0.9948\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0632 - val_loss: 0.9959\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0461 - val_loss: 1.0056\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0569 - val_loss: 0.9916\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0338 - val_loss: 0.9960\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0462 - val_loss: 1.0101\n",
      "Epoch 33/300\n",
      " - 2s - loss: 0.9998 - val_loss: 0.9990\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0202 - val_loss: 0.9978\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0107 - val_loss: 0.9955\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0019 - val_loss: 1.0034\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0040 - val_loss: 1.0037\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0133 - val_loss: 1.0024\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9939 - val_loss: 1.0047\n",
      "Epoch 40/300\n",
      " - 2s - loss: 0.9897 - val_loss: 1.0135\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9722 - val_loss: 1.0000\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9723 - val_loss: 1.0011\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9774 - val_loss: 0.9991\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9669 - val_loss: 0.9994\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9634 - val_loss: 1.0053\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9503 - val_loss: 1.0019\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9625 - val_loss: 1.0040\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9586 - val_loss: 1.0013\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9542 - val_loss: 1.0069\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9540 - val_loss: 1.0012\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9523 - val_loss: 1.0069\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9401 - val_loss: 1.0041\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9565 - val_loss: 1.0098\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9413 - val_loss: 1.0054\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9448 - val_loss: 1.0095\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9352 - val_loss: 1.0086\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9494 - val_loss: 1.0073\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9400 - val_loss: 1.0074\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9411 - val_loss: 1.0058\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9255 - val_loss: 1.0106\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00060: early stopping\n",
      "rse: 0.9957936891245057\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 3s - loss: 5.2220 - val_loss: 3.0684\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.7271 - val_loss: 2.1278\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7633 - val_loss: 1.5947\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.1885 - val_loss: 1.2406\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9396 - val_loss: 1.1433\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.7652 - val_loss: 1.1306\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.6334 - val_loss: 1.0575\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.5282 - val_loss: 1.0318\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5029 - val_loss: 1.0229\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4435 - val_loss: 1.0829\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.3646 - val_loss: 1.0040\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3349 - val_loss: 1.0000\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3098 - val_loss: 1.0024\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2732 - val_loss: 0.9920\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2168 - val_loss: 0.9911\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2006 - val_loss: 0.9708\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.1769 - val_loss: 0.9666\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1652 - val_loss: 0.9646\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1544 - val_loss: 0.9641\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1202 - val_loss: 0.9610\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.0945 - val_loss: 0.9642\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.0921 - val_loss: 0.9550\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0982 - val_loss: 0.9533\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0944 - val_loss: 0.9631\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0781 - val_loss: 0.9499\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0757 - val_loss: 0.9763\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0523 - val_loss: 0.9493\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0499 - val_loss: 0.9656\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0408 - val_loss: 0.9522\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0402 - val_loss: 0.9628\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0368 - val_loss: 0.9501\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0456 - val_loss: 0.9603\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0106 - val_loss: 0.9698\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0234 - val_loss: 0.9565\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0107 - val_loss: 0.9535\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0101 - val_loss: 0.9567\n",
      "Epoch 37/300\n",
      " - 2s - loss: 0.9976 - val_loss: 0.9612\n",
      "Epoch 38/300\n",
      " - 2s - loss: 0.9973 - val_loss: 0.9589\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9932 - val_loss: 0.9619\n",
      "Epoch 40/300\n",
      " - 2s - loss: 0.9859 - val_loss: 1.0191\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9791 - val_loss: 0.9531\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9784 - val_loss: 0.9652\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9836 - val_loss: 0.9562\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9540 - val_loss: 0.9559\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9717 - val_loss: 0.9601\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9534 - val_loss: 0.9538\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9676 - val_loss: 0.9710\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9569 - val_loss: 0.9617\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9599 - val_loss: 0.9564\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9492 - val_loss: 0.9636\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9615 - val_loss: 0.9706\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9577 - val_loss: 0.9591\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9478 - val_loss: 0.9566\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9415 - val_loss: 0.9578\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9439 - val_loss: 0.9589\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9323 - val_loss: 0.9602\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9432 - val_loss: 0.9610\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00057: early stopping\n",
      "rse: 0.9742976939323093\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 3s - loss: 5.5417 - val_loss: 3.1812\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.7587 - val_loss: 2.3349\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.8229 - val_loss: 1.6440\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2962 - val_loss: 1.3154\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9619 - val_loss: 1.1812\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8536 - val_loss: 1.1573\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7447 - val_loss: 1.1605\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6341 - val_loss: 1.1133\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5543 - val_loss: 1.1205\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.5008 - val_loss: 1.1070\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4386 - val_loss: 1.0711\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3613 - val_loss: 1.0626\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3181 - val_loss: 1.0551\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.3128 - val_loss: 1.0502\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2759 - val_loss: 1.0741\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2376 - val_loss: 1.0495\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.1833 - val_loss: 1.0417\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1817 - val_loss: 1.0328\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1524 - val_loss: 1.0311\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1275 - val_loss: 1.0405\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1214 - val_loss: 1.0189\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1020 - val_loss: 1.0187\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.1098 - val_loss: 1.0159\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0858 - val_loss: 1.0291\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0806 - val_loss: 1.0152\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0630 - val_loss: 1.0191\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0633 - val_loss: 1.0126\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0715 - val_loss: 1.0193\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0463 - val_loss: 1.0159\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0573 - val_loss: 1.0201\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0328 - val_loss: 1.0123\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0354 - val_loss: 1.0263\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0215 - val_loss: 1.0099\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0324 - val_loss: 1.0121\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0186 - val_loss: 1.0100\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0126 - val_loss: 1.0221\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0016 - val_loss: 1.0164\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0012 - val_loss: 1.0282\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9956 - val_loss: 1.0140\n",
      "Epoch 40/300\n",
      " - 2s - loss: 1.0049 - val_loss: 1.0132\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9884 - val_loss: 1.0172\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9742 - val_loss: 1.0129\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9673 - val_loss: 1.0137\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9744 - val_loss: 1.0128\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9750 - val_loss: 1.0136\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9650 - val_loss: 1.0139\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9683 - val_loss: 1.0114\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9533 - val_loss: 1.0119\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9597 - val_loss: 1.0132\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9490 - val_loss: 1.0146\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9617 - val_loss: 1.0165\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9523 - val_loss: 1.0134\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9516 - val_loss: 1.0155\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9387 - val_loss: 1.0146\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9519 - val_loss: 1.0171\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9327 - val_loss: 1.0138\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9466 - val_loss: 1.0201\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9410 - val_loss: 1.0166\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9467 - val_loss: 1.0291\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9374 - val_loss: 1.0174\n",
      "Epoch 61/300\n",
      " - 2s - loss: 0.9368 - val_loss: 1.0181\n",
      "Epoch 62/300\n",
      " - 2s - loss: 0.9301 - val_loss: 1.0227\n",
      "Epoch 63/300\n",
      " - 2s - loss: 0.9263 - val_loss: 1.0190\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00063: early stopping\n",
      "rse: 1.0049524973133994\n",
      "mean rse: 0.9888575979083554\n",
      "mean kappa: 0.5947043436038983\n",
      "oof kappa: 0.5947964018235181\n",
      "[1.047025 1.73499  2.220745]\n",
      "mean cappa 0.5566728690184293\n",
      "New threshold [1.0470249999999992, 1.7349899999999991, 2.220744999999999]\n",
      "3.0    497\n",
      "2.0    182\n",
      "1.0    162\n",
      "0.0    159\n",
      "dtype: int64\n",
      "2 th seed begins----------------------\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.4402 - val_loss: 3.4288\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.6825 - val_loss: 2.0549\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7497 - val_loss: 1.5133\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2539 - val_loss: 1.3080\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9737 - val_loss: 1.1358\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8344 - val_loss: 1.0787\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7172 - val_loss: 1.0814\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6051 - val_loss: 1.0485\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5473 - val_loss: 1.0352\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4720 - val_loss: 1.0373\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4303 - val_loss: 1.0785\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3872 - val_loss: 1.0244\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3392 - val_loss: 0.9972\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2660 - val_loss: 1.0043\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2566 - val_loss: 0.9994\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2281 - val_loss: 0.9952\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2124 - val_loss: 0.9794\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1717 - val_loss: 0.9812\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1618 - val_loss: 0.9854\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1508 - val_loss: 0.9716\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1300 - val_loss: 0.9732\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1185 - val_loss: 0.9719\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.1139 - val_loss: 0.9676\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0932 - val_loss: 0.9690\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0777 - val_loss: 0.9726\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0902 - val_loss: 0.9955\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0651 - val_loss: 0.9601\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0797 - val_loss: 0.9595\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0597 - val_loss: 0.9668\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0544 - val_loss: 0.9804\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0232 - val_loss: 0.9597\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0410 - val_loss: 0.9829\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0255 - val_loss: 0.9620\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0237 - val_loss: 0.9722\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0208 - val_loss: 0.9768\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0216 - val_loss: 0.9663\n",
      "Epoch 37/300\n",
      " - 2s - loss: 0.9946 - val_loss: 0.9771\n",
      "Epoch 38/300\n",
      " - 3s - loss: 1.0191 - val_loss: 0.9699\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9984 - val_loss: 0.9641\n",
      "Epoch 40/300\n",
      " - 2s - loss: 1.0019 - val_loss: 0.9815\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9958 - val_loss: 0.9717\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9703 - val_loss: 0.9680\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9845 - val_loss: 0.9755\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9814 - val_loss: 0.9694\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9761 - val_loss: 0.9657\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9676 - val_loss: 0.9687\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9618 - val_loss: 0.9688\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9592 - val_loss: 0.9686\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9691 - val_loss: 0.9794\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9592 - val_loss: 0.9733\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9557 - val_loss: 0.9768\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9628 - val_loss: 0.9669\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9509 - val_loss: 0.9706\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9538 - val_loss: 0.9686\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9390 - val_loss: 0.9742\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9334 - val_loss: 0.9730\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9454 - val_loss: 0.9840\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9379 - val_loss: 0.9716\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00058: early stopping\n",
      "rse: 0.9795661429645182\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.3458 - val_loss: 3.4663\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.6270 - val_loss: 2.1981\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7603 - val_loss: 1.6203\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2310 - val_loss: 1.2802\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9669 - val_loss: 1.2307\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8053 - val_loss: 1.1668\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.6941 - val_loss: 1.0969\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.5886 - val_loss: 1.0641\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5201 - val_loss: 1.0655\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4707 - val_loss: 1.0690\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.3979 - val_loss: 1.0375\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3364 - val_loss: 1.0253\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3338 - val_loss: 1.0303\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2519 - val_loss: 1.0142\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2591 - val_loss: 1.0537\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2182 - val_loss: 1.0093\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.1952 - val_loss: 1.0137\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1678 - val_loss: 1.0162\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1408 - val_loss: 1.0087\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1270 - val_loss: 1.0270\n",
      "Epoch 21/300\n",
      " - 3s - loss: 1.1086 - val_loss: 0.9927\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.0991 - val_loss: 0.9991\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0798 - val_loss: 0.9907\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0847 - val_loss: 0.9991\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0610 - val_loss: 0.9923\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0770 - val_loss: 0.9971\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0494 - val_loss: 0.9911\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0570 - val_loss: 1.0199\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0384 - val_loss: 0.9904\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0444 - val_loss: 1.0094\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0313 - val_loss: 0.9925\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0170 - val_loss: 0.9933\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0208 - val_loss: 0.9998\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0232 - val_loss: 0.9988\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0057 - val_loss: 0.9984\n",
      "Epoch 36/300\n",
      " - 2s - loss: 0.9991 - val_loss: 1.0022\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0007 - val_loss: 0.9894\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0095 - val_loss: 0.9906\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9892 - val_loss: 1.0105\n",
      "Epoch 40/300\n",
      " - 2s - loss: 0.9942 - val_loss: 0.9959\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9785 - val_loss: 0.9987\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9703 - val_loss: 0.9932\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9744 - val_loss: 0.9909\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9610 - val_loss: 0.9895\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9663 - val_loss: 0.9925\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9562 - val_loss: 0.9912\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9548 - val_loss: 0.9987\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9629 - val_loss: 0.9893\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9508 - val_loss: 0.9919\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9537 - val_loss: 0.9929\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9474 - val_loss: 0.9938\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9415 - val_loss: 0.9969\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9460 - val_loss: 0.9987\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9476 - val_loss: 0.9953\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9577 - val_loss: 1.0062\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9476 - val_loss: 0.9964\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9325 - val_loss: 1.0013\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9337 - val_loss: 0.9950\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9332 - val_loss: 0.9946\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9327 - val_loss: 0.9962\n",
      "Epoch 61/300\n",
      " - 2s - loss: 0.9263 - val_loss: 0.9998\n",
      "Epoch 62/300\n",
      " - 2s - loss: 0.9233 - val_loss: 1.0016\n",
      "Epoch 63/300\n",
      " - 2s - loss: 0.9226 - val_loss: 0.9994\n",
      "Epoch 64/300\n",
      " - 2s - loss: 0.9223 - val_loss: 1.0002\n",
      "Epoch 65/300\n",
      " - 2s - loss: 0.9235 - val_loss: 0.9989\n",
      "Epoch 66/300\n",
      " - 2s - loss: 0.9290 - val_loss: 1.0017\n",
      "Epoch 67/300\n",
      " - 2s - loss: 0.9279 - val_loss: 1.0062\n",
      "Epoch 68/300\n",
      " - 2s - loss: 0.9179 - val_loss: 0.9997\n",
      "Epoch 69/300\n",
      " - 2s - loss: 0.9169 - val_loss: 1.0022\n",
      "Epoch 70/300\n",
      " - 2s - loss: 0.9136 - val_loss: 1.0022\n",
      "Epoch 71/300\n",
      " - 2s - loss: 0.9151 - val_loss: 1.0022\n",
      "Epoch 72/300\n",
      " - 2s - loss: 0.9198 - val_loss: 1.0007\n",
      "Epoch 73/300\n",
      " - 2s - loss: 0.9061 - val_loss: 1.0015\n",
      "Epoch 74/300\n",
      " - 2s - loss: 0.9113 - val_loss: 1.0052\n",
      "Epoch 75/300\n",
      " - 2s - loss: 0.9065 - val_loss: 1.0017\n",
      "Epoch 76/300\n",
      " - 2s - loss: 0.9099 - val_loss: 1.0106\n",
      "Epoch 77/300\n",
      " - 3s - loss: 0.9110 - val_loss: 1.0044\n",
      "Epoch 78/300\n",
      " - 2s - loss: 0.9034 - val_loss: 1.0046\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00078: early stopping\n",
      "rse: 0.9946408904555203\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.4783 - val_loss: 3.0907\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.7471 - val_loss: 2.2143\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.8217 - val_loss: 1.5212\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.3354 - val_loss: 1.3001\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9905 - val_loss: 1.1756\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8663 - val_loss: 1.0940\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7320 - val_loss: 1.0707\n",
      "Epoch 8/300\n",
      " - 3s - loss: 1.6480 - val_loss: 1.0580\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5329 - val_loss: 1.0413\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4745 - val_loss: 1.0604\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4273 - val_loss: 1.0078\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3850 - val_loss: 1.0154\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3395 - val_loss: 0.9965\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2913 - val_loss: 0.9995\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2689 - val_loss: 0.9837\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2341 - val_loss: 0.9824\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2081 - val_loss: 0.9841\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1920 - val_loss: 0.9832\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1712 - val_loss: 0.9788\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1386 - val_loss: 0.9819\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1119 - val_loss: 0.9694\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1094 - val_loss: 0.9664\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.1002 - val_loss: 0.9630\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.1064 - val_loss: 0.9870\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0775 - val_loss: 0.9639\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0957 - val_loss: 0.9583\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0719 - val_loss: 0.9606\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0772 - val_loss: 0.9706\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0560 - val_loss: 0.9577\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0499 - val_loss: 0.9547\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0367 - val_loss: 0.9595\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0448 - val_loss: 0.9692\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0416 - val_loss: 0.9682\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0337 - val_loss: 0.9571\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0149 - val_loss: 0.9586\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0293 - val_loss: 0.9817\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0097 - val_loss: 0.9646\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0167 - val_loss: 0.9587\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9872 - val_loss: 0.9581\n",
      "Epoch 40/300\n",
      " - 2s - loss: 0.9908 - val_loss: 0.9712\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9842 - val_loss: 0.9553\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9847 - val_loss: 0.9571\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9826 - val_loss: 0.9532\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9719 - val_loss: 0.9561\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9778 - val_loss: 0.9589\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9681 - val_loss: 0.9577\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9704 - val_loss: 0.9591\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9613 - val_loss: 0.9601\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9597 - val_loss: 0.9591\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9634 - val_loss: 0.9586\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9545 - val_loss: 0.9632\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9518 - val_loss: 0.9615\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9616 - val_loss: 0.9585\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9575 - val_loss: 0.9587\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9429 - val_loss: 0.9664\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9483 - val_loss: 0.9675\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9410 - val_loss: 0.9657\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9502 - val_loss: 0.9599\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9459 - val_loss: 0.9719\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9321 - val_loss: 0.9616\n",
      "Epoch 61/300\n",
      " - 2s - loss: 0.9442 - val_loss: 0.9622\n",
      "Epoch 62/300\n",
      " - 2s - loss: 0.9284 - val_loss: 0.9641\n",
      "Epoch 63/300\n",
      " - 2s - loss: 0.9276 - val_loss: 0.9649\n",
      "Epoch 64/300\n",
      " - 2s - loss: 0.9241 - val_loss: 0.9624\n",
      "Epoch 65/300\n",
      " - 2s - loss: 0.9281 - val_loss: 0.9677\n",
      "Epoch 66/300\n",
      " - 2s - loss: 0.9118 - val_loss: 0.9681\n",
      "Epoch 67/300\n",
      " - 2s - loss: 0.9238 - val_loss: 0.9711\n",
      "Epoch 68/300\n",
      " - 2s - loss: 0.9214 - val_loss: 0.9632\n",
      "Epoch 69/300\n",
      " - 2s - loss: 0.9303 - val_loss: 0.9672\n",
      "Epoch 70/300\n",
      " - 2s - loss: 0.9121 - val_loss: 0.9660\n",
      "Epoch 71/300\n",
      " - 2s - loss: 0.9264 - val_loss: 0.9642\n",
      "Epoch 72/300\n",
      " - 2s - loss: 0.9195 - val_loss: 0.9637\n",
      "Epoch 73/300\n",
      " - 2s - loss: 0.9164 - val_loss: 0.9631\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00073: early stopping\n",
      "rse: 0.9763426991934305\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.5347 - val_loss: 2.8560\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.7121 - val_loss: 1.9543\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7798 - val_loss: 1.5865\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.3077 - val_loss: 1.2998\n",
      "Epoch 5/300\n",
      " - 2s - loss: 2.0174 - val_loss: 1.1874\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8702 - val_loss: 1.1602\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7498 - val_loss: 1.1087\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6392 - val_loss: 1.1135\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5498 - val_loss: 1.0995\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4917 - val_loss: 1.0743\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4389 - val_loss: 1.0809\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3573 - val_loss: 1.0498\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3205 - val_loss: 1.0522\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2951 - val_loss: 1.0366\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2495 - val_loss: 1.0807\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2441 - val_loss: 1.0359\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2094 - val_loss: 1.0345\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1793 - val_loss: 1.0330\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1535 - val_loss: 1.0586\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1276 - val_loss: 1.0438\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1154 - val_loss: 1.0232\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1061 - val_loss: 1.0286\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0881 - val_loss: 1.0196\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0790 - val_loss: 1.0261\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0769 - val_loss: 1.0190\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0782 - val_loss: 1.0215\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0592 - val_loss: 1.0173\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0646 - val_loss: 1.0200\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0552 - val_loss: 1.0154\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0525 - val_loss: 1.0152\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0386 - val_loss: 1.0159\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0493 - val_loss: 1.0221\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0295 - val_loss: 1.0174\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0196 - val_loss: 1.0204\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0150 - val_loss: 1.0151\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0204 - val_loss: 1.0156\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0053 - val_loss: 1.0180\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0094 - val_loss: 1.0185\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9970 - val_loss: 1.0174\n",
      "Epoch 40/300\n",
      " - 2s - loss: 1.0017 - val_loss: 1.0224\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9838 - val_loss: 1.0218\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9806 - val_loss: 1.0168\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9785 - val_loss: 1.0296\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9612 - val_loss: 1.0195\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9708 - val_loss: 1.0204\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9566 - val_loss: 1.0195\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9570 - val_loss: 1.0162\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9573 - val_loss: 1.0202\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9601 - val_loss: 1.0176\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9530 - val_loss: 1.0200\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9526 - val_loss: 1.0302\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9333 - val_loss: 1.0198\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9547 - val_loss: 1.0224\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9413 - val_loss: 1.0199\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9571 - val_loss: 1.0241\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9384 - val_loss: 1.0208\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9383 - val_loss: 1.0231\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9364 - val_loss: 1.0211\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9378 - val_loss: 1.0339\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9289 - val_loss: 1.0246\n",
      "Epoch 61/300\n",
      " - 2s - loss: 0.9364 - val_loss: 1.0293\n",
      "Epoch 62/300\n",
      " - 2s - loss: 0.9219 - val_loss: 1.0217\n",
      "Epoch 63/300\n",
      " - 2s - loss: 0.9281 - val_loss: 1.0260\n",
      "Epoch 64/300\n",
      " - 2s - loss: 0.9248 - val_loss: 1.0268\n",
      "Epoch 65/300\n",
      " - 2s - loss: 0.9166 - val_loss: 1.0264\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00065: early stopping\n",
      "rse: 1.0075190770706879\n",
      "mean rse: 0.9895172024210392\n",
      "mean kappa: 0.5930380839725568\n",
      "oof kappa: 0.5930989012626107\n",
      "[1.06092 1.72235 2.28305]\n",
      "mean cappa 0.5563146252386821\n",
      "New threshold [1.0609200000000005, 1.7223499999999996, 2.2830499999999967]\n",
      "3.0    469\n",
      "2.0    226\n",
      "0.0    165\n",
      "1.0    140\n",
      "dtype: int64\n",
      "3 th seed begins----------------------\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 3s - loss: 5.5135 - val_loss: 3.2511\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.8224 - val_loss: 2.3015\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.8342 - val_loss: 1.6147\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.3021 - val_loss: 1.3436\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9820 - val_loss: 1.1924\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8656 - val_loss: 1.0792\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7613 - val_loss: 1.0684\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6471 - val_loss: 1.0454\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5640 - val_loss: 1.0961\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4960 - val_loss: 1.0292\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4424 - val_loss: 1.0135\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3788 - val_loss: 1.0302\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3379 - val_loss: 0.9985\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2963 - val_loss: 1.0017\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2958 - val_loss: 0.9805\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2508 - val_loss: 0.9953\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2073 - val_loss: 0.9834\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1850 - val_loss: 0.9738\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1542 - val_loss: 0.9746\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1467 - val_loss: 0.9715\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1314 - val_loss: 0.9687\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1212 - val_loss: 0.9686\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0967 - val_loss: 0.9648\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0865 - val_loss: 0.9641\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0969 - val_loss: 0.9632\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0882 - val_loss: 0.9815\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0761 - val_loss: 0.9643\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0738 - val_loss: 0.9604\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0553 - val_loss: 0.9581\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0721 - val_loss: 0.9583\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0435 - val_loss: 0.9668\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0384 - val_loss: 0.9706\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0235 - val_loss: 0.9596\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0247 - val_loss: 0.9592\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0070 - val_loss: 0.9583\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0171 - val_loss: 0.9603\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0107 - val_loss: 0.9571\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0184 - val_loss: 0.9776\n",
      "Epoch 39/300\n",
      " - 2s - loss: 1.0133 - val_loss: 0.9652\n",
      "Epoch 40/300\n",
      " - 2s - loss: 1.0101 - val_loss: 0.9610\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9864 - val_loss: 0.9601\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9789 - val_loss: 0.9587\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9910 - val_loss: 0.9632\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9819 - val_loss: 0.9583\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9690 - val_loss: 0.9605\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9722 - val_loss: 0.9547\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9743 - val_loss: 0.9662\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9670 - val_loss: 0.9578\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9754 - val_loss: 0.9619\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9626 - val_loss: 0.9586\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9743 - val_loss: 0.9607\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9649 - val_loss: 0.9594\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9614 - val_loss: 0.9690\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9431 - val_loss: 0.9603\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9542 - val_loss: 0.9673\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9428 - val_loss: 0.9630\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9482 - val_loss: 0.9645\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9387 - val_loss: 0.9630\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9490 - val_loss: 0.9655\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9399 - val_loss: 0.9656\n",
      "Epoch 61/300\n",
      " - 2s - loss: 0.9374 - val_loss: 0.9651\n",
      "Epoch 62/300\n",
      " - 2s - loss: 0.9260 - val_loss: 0.9663\n",
      "Epoch 63/300\n",
      " - 2s - loss: 0.9340 - val_loss: 0.9658\n",
      "Epoch 64/300\n",
      " - 2s - loss: 0.9343 - val_loss: 0.9636\n",
      "Epoch 65/300\n",
      " - 2s - loss: 0.9433 - val_loss: 0.9705\n",
      "Epoch 66/300\n",
      " - 2s - loss: 0.9302 - val_loss: 0.9706\n",
      "Epoch 67/300\n",
      " - 2s - loss: 0.9251 - val_loss: 0.9759\n",
      "Epoch 68/300\n",
      " - 2s - loss: 0.9194 - val_loss: 0.9701\n",
      "Epoch 69/300\n",
      " - 2s - loss: 0.9272 - val_loss: 0.9709\n",
      "Epoch 70/300\n",
      " - 2s - loss: 0.9235 - val_loss: 0.9692\n",
      "Epoch 71/300\n",
      " - 2s - loss: 0.9242 - val_loss: 0.9689\n",
      "Epoch 72/300\n",
      " - 2s - loss: 0.9254 - val_loss: 0.9714\n",
      "Epoch 73/300\n",
      " - 2s - loss: 0.9229 - val_loss: 0.9710\n",
      "Epoch 74/300\n",
      " - 2s - loss: 0.9092 - val_loss: 0.9699\n",
      "Epoch 75/300\n",
      " - 2s - loss: 0.9235 - val_loss: 0.9695\n",
      "Epoch 76/300\n",
      " - 2s - loss: 0.9138 - val_loss: 0.9724\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00076: early stopping\n",
      "rse: 0.9770737697656173\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.5019 - val_loss: 3.1912\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.7164 - val_loss: 2.3545\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.8498 - val_loss: 1.7703\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.3171 - val_loss: 1.3434\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9911 - val_loss: 1.2029\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8416 - val_loss: 1.1682\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7139 - val_loss: 1.0887\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6479 - val_loss: 1.0721\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5512 - val_loss: 1.0966\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4745 - val_loss: 1.0469\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4325 - val_loss: 1.0529\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3833 - val_loss: 1.0418\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3309 - val_loss: 1.0623\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2997 - val_loss: 1.0277\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2534 - val_loss: 1.0188\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2324 - val_loss: 1.0693\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2104 - val_loss: 1.0083\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1920 - val_loss: 1.0181\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1483 - val_loss: 1.0069\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1371 - val_loss: 1.0086\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1132 - val_loss: 0.9895\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.0984 - val_loss: 1.0066\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0987 - val_loss: 0.9889\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0960 - val_loss: 1.0004\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0770 - val_loss: 0.9963\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0811 - val_loss: 0.9965\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0650 - val_loss: 1.0041\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0679 - val_loss: 1.0020\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0470 - val_loss: 0.9940\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0549 - val_loss: 0.9934\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0233 - val_loss: 0.9932\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0547 - val_loss: 0.9971\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0235 - val_loss: 0.9907\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0379 - val_loss: 0.9995\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0188 - val_loss: 0.9930\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0186 - val_loss: 0.9993\n",
      "Epoch 37/300\n",
      " - 2s - loss: 0.9981 - val_loss: 0.9948\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0078 - val_loss: 0.9960\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9965 - val_loss: 0.9932\n",
      "Epoch 40/300\n",
      " - 2s - loss: 1.0032 - val_loss: 1.0060\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9880 - val_loss: 1.0007\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9736 - val_loss: 0.9968\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9762 - val_loss: 1.0039\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9745 - val_loss: 0.9937\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9717 - val_loss: 0.9987\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9619 - val_loss: 0.9963\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9671 - val_loss: 0.9962\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9592 - val_loss: 0.9967\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9635 - val_loss: 1.0030\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9518 - val_loss: 1.0020\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9614 - val_loss: 1.0021\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9489 - val_loss: 0.9995\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9621 - val_loss: 0.9985\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00053: early stopping\n",
      "rse: 0.9944298798295985\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 3s - loss: 5.4234 - val_loss: 3.1921\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.6976 - val_loss: 2.1026\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7668 - val_loss: 1.5118\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2464 - val_loss: 1.2571\n",
      "Epoch 5/300\n",
      " - 2s - loss: 2.0145 - val_loss: 1.0893\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8561 - val_loss: 1.0738\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7318 - val_loss: 1.0506\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6435 - val_loss: 1.0223\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5605 - val_loss: 1.0186\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4871 - val_loss: 1.0115\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4433 - val_loss: 0.9921\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3718 - val_loss: 0.9948\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3352 - val_loss: 0.9928\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2969 - val_loss: 0.9937\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2657 - val_loss: 0.9834\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2214 - val_loss: 0.9728\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2109 - val_loss: 0.9787\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1951 - val_loss: 0.9797\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1700 - val_loss: 0.9705\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1476 - val_loss: 1.0170\n",
      "Epoch 21/300\n",
      " - 3s - loss: 1.1255 - val_loss: 0.9608\n",
      "Epoch 22/300\n",
      " - 3s - loss: 1.1184 - val_loss: 0.9664\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.1171 - val_loss: 0.9574\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.1057 - val_loss: 0.9822\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0798 - val_loss: 0.9614\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0935 - val_loss: 0.9582\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0726 - val_loss: 0.9537\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0716 - val_loss: 0.9601\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0532 - val_loss: 0.9516\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0813 - val_loss: 0.9615\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0528 - val_loss: 0.9530\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0468 - val_loss: 0.9588\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0451 - val_loss: 0.9545\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0360 - val_loss: 0.9524\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0299 - val_loss: 0.9666\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0280 - val_loss: 0.9590\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0162 - val_loss: 0.9679\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0228 - val_loss: 0.9630\n",
      "Epoch 39/300\n",
      " - 2s - loss: 1.0073 - val_loss: 0.9546\n",
      "Epoch 40/300\n",
      " - 2s - loss: 1.0079 - val_loss: 0.9576\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9936 - val_loss: 0.9474\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9812 - val_loss: 0.9503\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9965 - val_loss: 0.9768\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9828 - val_loss: 0.9559\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9787 - val_loss: 0.9575\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9729 - val_loss: 0.9600\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9792 - val_loss: 0.9650\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9657 - val_loss: 0.9623\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9805 - val_loss: 0.9617\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9657 - val_loss: 0.9610\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9634 - val_loss: 0.9715\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9563 - val_loss: 0.9647\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9613 - val_loss: 0.9578\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9493 - val_loss: 0.9630\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9551 - val_loss: 0.9629\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9497 - val_loss: 0.9591\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9491 - val_loss: 0.9641\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9402 - val_loss: 0.9625\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9502 - val_loss: 0.9623\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9441 - val_loss: 0.9610\n",
      "Epoch 61/300\n",
      " - 2s - loss: 0.9328 - val_loss: 0.9651\n",
      "Epoch 62/300\n",
      " - 2s - loss: 0.9369 - val_loss: 0.9624\n",
      "Epoch 63/300\n",
      " - 2s - loss: 0.9387 - val_loss: 0.9700\n",
      "Epoch 64/300\n",
      " - 2s - loss: 0.9390 - val_loss: 0.9661\n",
      "Epoch 65/300\n",
      " - 2s - loss: 0.9357 - val_loss: 0.9638\n",
      "Epoch 66/300\n",
      " - 2s - loss: 0.9293 - val_loss: 0.9671\n",
      "Epoch 67/300\n",
      " - 2s - loss: 0.9387 - val_loss: 0.9657\n",
      "Epoch 68/300\n",
      " - 2s - loss: 0.9284 - val_loss: 0.9667\n",
      "Epoch 69/300\n",
      " - 2s - loss: 0.9253 - val_loss: 0.9675\n",
      "Epoch 70/300\n",
      " - 4s - loss: 0.9233 - val_loss: 0.9702\n",
      "Epoch 71/300\n",
      " - 2s - loss: 0.9285 - val_loss: 0.9642\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00071: early stopping\n",
      "rse: 0.9733405890609665\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.4612 - val_loss: 2.9638\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.7388 - val_loss: 2.1026\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7637 - val_loss: 1.6185\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2611 - val_loss: 1.2994\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9722 - val_loss: 1.2050\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8137 - val_loss: 1.1883\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.6776 - val_loss: 1.1193\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.5768 - val_loss: 1.0737\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5019 - val_loss: 1.0858\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4366 - val_loss: 1.0814\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.3870 - val_loss: 1.0650\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3736 - val_loss: 1.0588\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3177 - val_loss: 1.0560\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2536 - val_loss: 1.0605\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2435 - val_loss: 1.0702\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2255 - val_loss: 1.0967\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.1921 - val_loss: 1.0435\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1726 - val_loss: 1.0449\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1566 - val_loss: 1.0409\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1429 - val_loss: 1.0463\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1238 - val_loss: 1.0157\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1015 - val_loss: 1.0138\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0891 - val_loss: 1.0093\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0717 - val_loss: 1.0109\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0712 - val_loss: 1.0101\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0757 - val_loss: 1.0403\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0655 - val_loss: 1.0113\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0605 - val_loss: 1.0135\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0415 - val_loss: 1.0020\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0493 - val_loss: 1.0218\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0275 - val_loss: 1.0126\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0353 - val_loss: 1.0175\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0378 - val_loss: 1.0086\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0130 - val_loss: 1.0135\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0001 - val_loss: 1.0078\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0106 - val_loss: 1.0115\n",
      "Epoch 37/300\n",
      " - 2s - loss: 0.9934 - val_loss: 1.0089\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0070 - val_loss: 1.0120\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9906 - val_loss: 1.0063\n",
      "Epoch 40/300\n",
      " - 2s - loss: 0.9910 - val_loss: 1.0187\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9744 - val_loss: 1.0070\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9748 - val_loss: 1.0068\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9713 - val_loss: 1.0145\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9672 - val_loss: 1.0057\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9753 - val_loss: 1.0061\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9552 - val_loss: 1.0066\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9681 - val_loss: 1.0103\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9660 - val_loss: 1.0077\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9465 - val_loss: 1.0252\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9541 - val_loss: 1.0059\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9535 - val_loss: 1.0084\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9437 - val_loss: 1.0084\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9514 - val_loss: 1.0108\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9448 - val_loss: 1.0161\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9427 - val_loss: 1.0168\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9448 - val_loss: 1.0082\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9473 - val_loss: 1.0185\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9311 - val_loss: 1.0131\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9352 - val_loss: 1.0137\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00059: early stopping\n",
      "rse: 1.0009830026930422\n",
      "mean rse: 0.9864568103373061\n",
      "mean kappa: 0.5965623043464767\n",
      "oof kappa: 0.5969057586925337\n",
      "[0.995755 1.70168  2.234255]\n",
      "mean cappa 0.5598110512280894\n",
      "New threshold [0.9957550000000005, 1.7016799999999965, 2.234254999999999]\n",
      "3.0    480\n",
      "2.0    210\n",
      "0.0    156\n",
      "1.0    154\n",
      "dtype: int64\n",
      "4 th seed begins----------------------\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 3s - loss: 5.5576 - val_loss: 3.1415\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.7385 - val_loss: 2.1258\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.8037 - val_loss: 1.5711\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2977 - val_loss: 1.2471\n",
      "Epoch 5/300\n",
      " - 2s - loss: 2.0134 - val_loss: 1.1257\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8368 - val_loss: 1.0921\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7721 - val_loss: 1.0706\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6500 - val_loss: 1.0473\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5890 - val_loss: 1.0514\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.5125 - val_loss: 1.0183\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4436 - val_loss: 1.0248\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.4200 - val_loss: 1.0149\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3584 - val_loss: 1.0333\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.3172 - val_loss: 1.0093\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2731 - val_loss: 1.0048\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2558 - val_loss: 0.9931\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2292 - val_loss: 0.9785\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1836 - val_loss: 0.9744\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1682 - val_loss: 0.9753\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1637 - val_loss: 0.9798\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1338 - val_loss: 0.9775\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1295 - val_loss: 0.9731\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.1115 - val_loss: 0.9652\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.1075 - val_loss: 0.9782\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0953 - val_loss: 0.9691\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0949 - val_loss: 0.9987\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0818 - val_loss: 0.9644\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0813 - val_loss: 0.9712\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0558 - val_loss: 0.9669\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0730 - val_loss: 0.9660\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0564 - val_loss: 0.9649\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0616 - val_loss: 0.9662\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0335 - val_loss: 0.9625\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0403 - val_loss: 0.9711\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0351 - val_loss: 0.9712\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0271 - val_loss: 0.9653\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0143 - val_loss: 0.9658\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0329 - val_loss: 0.9691\n",
      "Epoch 39/300\n",
      " - 2s - loss: 1.0126 - val_loss: 0.9664\n",
      "Epoch 40/300\n",
      " - 2s - loss: 1.0196 - val_loss: 0.9715\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9995 - val_loss: 0.9639\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9982 - val_loss: 0.9624\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9951 - val_loss: 0.9642\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9735 - val_loss: 0.9653\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9980 - val_loss: 0.9639\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9754 - val_loss: 0.9635\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9707 - val_loss: 0.9664\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9762 - val_loss: 0.9649\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9646 - val_loss: 0.9687\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9742 - val_loss: 0.9655\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9675 - val_loss: 0.9685\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9678 - val_loss: 0.9682\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9707 - val_loss: 0.9784\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9616 - val_loss: 0.9667\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9638 - val_loss: 0.9723\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9600 - val_loss: 0.9677\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9610 - val_loss: 0.9688\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9506 - val_loss: 0.9667\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9442 - val_loss: 0.9789\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9407 - val_loss: 0.9790\n",
      "Epoch 61/300\n",
      " - 2s - loss: 0.9423 - val_loss: 0.9773\n",
      "Epoch 62/300\n",
      " - 2s - loss: 0.9499 - val_loss: 0.9734\n",
      "Epoch 63/300\n",
      " - 2s - loss: 0.9398 - val_loss: 0.9753\n",
      "Epoch 64/300\n",
      " - 2s - loss: 0.9321 - val_loss: 0.9763\n",
      "Epoch 65/300\n",
      " - 2s - loss: 0.9385 - val_loss: 0.9732\n",
      "Epoch 66/300\n",
      " - 2s - loss: 0.9358 - val_loss: 0.9738\n",
      "Epoch 67/300\n",
      " - 2s - loss: 0.9323 - val_loss: 0.9712\n",
      "Epoch 68/300\n",
      " - 2s - loss: 0.9366 - val_loss: 0.9758\n",
      "Epoch 69/300\n",
      " - 2s - loss: 0.9321 - val_loss: 0.9718\n",
      "Epoch 70/300\n",
      " - 2s - loss: 0.9343 - val_loss: 0.9765\n",
      "Epoch 71/300\n",
      " - 2s - loss: 0.9375 - val_loss: 0.9734\n",
      "Epoch 72/300\n",
      " - 2s - loss: 0.9281 - val_loss: 0.9758\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00072: early stopping\n",
      "rse: 0.9810002596733265\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.4559 - val_loss: 3.3953\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.6844 - val_loss: 2.4584\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7723 - val_loss: 1.7649\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2840 - val_loss: 1.3381\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9816 - val_loss: 1.2384\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8201 - val_loss: 1.1508\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.6898 - val_loss: 1.1228\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6256 - val_loss: 1.1125\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5395 - val_loss: 1.1076\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.5022 - val_loss: 1.0658\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4165 - val_loss: 1.0661\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3547 - val_loss: 1.0420\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3204 - val_loss: 1.0194\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2986 - val_loss: 1.0081\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2473 - val_loss: 1.0183\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2136 - val_loss: 1.0264\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2123 - val_loss: 1.0163\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1790 - val_loss: 1.0110\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1619 - val_loss: 1.0229\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1374 - val_loss: 1.0173\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1023 - val_loss: 0.9963\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.0988 - val_loss: 0.9941\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0891 - val_loss: 0.9893\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0707 - val_loss: 0.9940\n",
      "Epoch 25/300\n",
      " - 3s - loss: 1.0846 - val_loss: 0.9944\n",
      "Epoch 26/300\n",
      " - 3s - loss: 1.0758 - val_loss: 0.9965\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0697 - val_loss: 0.9939\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0677 - val_loss: 1.0004\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0474 - val_loss: 1.0051\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0514 - val_loss: 0.9945\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0279 - val_loss: 0.9926\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0302 - val_loss: 0.9957\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0324 - val_loss: 0.9941\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0170 - val_loss: 0.9990\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0020 - val_loss: 1.0001\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0123 - val_loss: 1.0166\n",
      "Epoch 37/300\n",
      " - 2s - loss: 0.9983 - val_loss: 0.9895\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0077 - val_loss: 1.0075\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9855 - val_loss: 0.9960\n",
      "Epoch 40/300\n",
      " - 2s - loss: 0.9984 - val_loss: 0.9999\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9818 - val_loss: 0.9958\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9732 - val_loss: 0.9893\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9771 - val_loss: 0.9978\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9662 - val_loss: 0.9934\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9669 - val_loss: 0.9945\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9620 - val_loss: 0.9925\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9652 - val_loss: 0.9965\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9560 - val_loss: 0.9979\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9665 - val_loss: 1.0015\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9507 - val_loss: 1.0032\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9558 - val_loss: 0.9995\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9539 - val_loss: 0.9952\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9513 - val_loss: 0.9955\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00053: early stopping\n",
      "rse: 0.9946171513275628\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.4768 - val_loss: 3.0331\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.7186 - val_loss: 2.2213\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7932 - val_loss: 1.3931\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.3031 - val_loss: 1.1988\n",
      "Epoch 5/300\n",
      " - 2s - loss: 2.0479 - val_loss: 1.1074\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8648 - val_loss: 1.1053\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7264 - val_loss: 1.0776\n",
      "Epoch 8/300\n",
      " - 3s - loss: 1.6609 - val_loss: 1.0330\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5884 - val_loss: 1.0191\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.5021 - val_loss: 1.0402\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4209 - val_loss: 1.0049\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3959 - val_loss: 1.0170\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3468 - val_loss: 0.9843\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.3112 - val_loss: 1.0024\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2604 - val_loss: 0.9745\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2420 - val_loss: 0.9787\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2060 - val_loss: 0.9755\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1917 - val_loss: 0.9682\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1830 - val_loss: 0.9661\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1384 - val_loss: 0.9685\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1130 - val_loss: 0.9582\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1255 - val_loss: 0.9694\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.1126 - val_loss: 0.9534\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.1070 - val_loss: 0.9752\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0891 - val_loss: 0.9611\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0793 - val_loss: 0.9637\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0666 - val_loss: 0.9566\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0887 - val_loss: 0.9571\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0640 - val_loss: 0.9661\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0605 - val_loss: 0.9912\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0289 - val_loss: 0.9682\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0392 - val_loss: 0.9685\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0347 - val_loss: 0.9556\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0460 - val_loss: 0.9690\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0221 - val_loss: 0.9551\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0259 - val_loss: 0.9584\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0242 - val_loss: 0.9788\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0091 - val_loss: 0.9500\n",
      "Epoch 39/300\n",
      " - 2s - loss: 1.0024 - val_loss: 0.9699\n",
      "Epoch 40/300\n",
      " - 2s - loss: 1.0030 - val_loss: 0.9724\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9974 - val_loss: 0.9524\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9822 - val_loss: 0.9525\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9901 - val_loss: 0.9566\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9796 - val_loss: 0.9531\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9782 - val_loss: 0.9729\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9803 - val_loss: 0.9529\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9856 - val_loss: 0.9547\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9712 - val_loss: 0.9534\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9751 - val_loss: 0.9542\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9590 - val_loss: 0.9569\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9773 - val_loss: 0.9605\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9663 - val_loss: 0.9616\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9648 - val_loss: 0.9560\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9585 - val_loss: 0.9631\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9705 - val_loss: 0.9607\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9535 - val_loss: 0.9600\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9556 - val_loss: 0.9570\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9513 - val_loss: 0.9652\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9536 - val_loss: 0.9613\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9413 - val_loss: 0.9637\n",
      "Epoch 61/300\n",
      " - 2s - loss: 0.9577 - val_loss: 0.9724\n",
      "Epoch 62/300\n",
      " - 2s - loss: 0.9390 - val_loss: 0.9590\n",
      "Epoch 63/300\n",
      " - 2s - loss: 0.9448 - val_loss: 0.9677\n",
      "Epoch 64/300\n",
      " - 2s - loss: 0.9310 - val_loss: 0.9596\n",
      "Epoch 65/300\n",
      " - 2s - loss: 0.9310 - val_loss: 0.9580\n",
      "Epoch 66/300\n",
      " - 2s - loss: 0.9346 - val_loss: 0.9591\n",
      "Epoch 67/300\n",
      " - 2s - loss: 0.9366 - val_loss: 0.9603\n",
      "Epoch 68/300\n",
      " - 2s - loss: 0.9314 - val_loss: 0.9605\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00068: early stopping\n",
      "rse: 0.9746783946336075\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.3858 - val_loss: 3.1157\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.7024 - val_loss: 2.1786\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7340 - val_loss: 1.5079\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2519 - val_loss: 1.2333\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9254 - val_loss: 1.1886\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.7586 - val_loss: 1.1412\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.6778 - val_loss: 1.1404\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.5864 - val_loss: 1.1051\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5338 - val_loss: 1.0942\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4495 - val_loss: 1.0722\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.3930 - val_loss: 1.0722\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3417 - val_loss: 1.0814\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3225 - val_loss: 1.0533\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2705 - val_loss: 1.0424\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2476 - val_loss: 1.0329\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2299 - val_loss: 1.0354\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.1776 - val_loss: 1.0265\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1678 - val_loss: 1.0240\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1476 - val_loss: 1.0315\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1241 - val_loss: 1.0185\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1023 - val_loss: 1.0150\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1046 - val_loss: 1.0185\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0795 - val_loss: 1.0157\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0715 - val_loss: 1.0146\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0677 - val_loss: 1.0123\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0802 - val_loss: 1.0086\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0563 - val_loss: 1.0167\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0578 - val_loss: 1.0175\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0518 - val_loss: 1.0119\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0456 - val_loss: 1.0248\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0263 - val_loss: 1.0124\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0449 - val_loss: 1.0208\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0118 - val_loss: 1.0154\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0155 - val_loss: 1.0345\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0118 - val_loss: 1.0170\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0087 - val_loss: 1.0269\n",
      "Epoch 37/300\n",
      " - 2s - loss: 0.9915 - val_loss: 1.0117\n",
      "Epoch 38/300\n",
      " - 2s - loss: 0.9932 - val_loss: 1.0161\n",
      "Epoch 39/300\n",
      " - 3s - loss: 0.9790 - val_loss: 1.0163\n",
      "Epoch 40/300\n",
      " - 3s - loss: 0.9816 - val_loss: 1.0210\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9645 - val_loss: 1.0247\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9600 - val_loss: 1.0194\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9779 - val_loss: 1.0158\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9563 - val_loss: 1.0146\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9596 - val_loss: 1.0264\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9632 - val_loss: 1.0157\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9629 - val_loss: 1.0213\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9488 - val_loss: 1.0186\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9573 - val_loss: 1.0137\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9524 - val_loss: 1.0161\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9471 - val_loss: 1.0212\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9429 - val_loss: 1.0164\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9444 - val_loss: 1.0207\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9412 - val_loss: 1.0175\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9358 - val_loss: 1.0179\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9266 - val_loss: 1.0205\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00056: early stopping\n",
      "rse: 1.0042920048886317\n",
      "mean rse: 0.9886469526307821\n",
      "mean kappa: 0.5935979710152539\n",
      "oof kappa: 0.5941176708400663\n",
      "[1.054395 1.745095 2.25748 ]\n",
      "mean cappa 0.5561577440029117\n",
      "New threshold [1.0543950000000022, 1.7450950000000016, 2.257479999999999]\n",
      "3.0    480\n",
      "2.0    203\n",
      "0.0    162\n",
      "1.0    155\n",
      "dtype: int64\n",
      "5 th seed begins----------------------\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.3395 - val_loss: 3.5528\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.7106 - val_loss: 2.4844\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.8201 - val_loss: 1.8719\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2804 - val_loss: 1.3607\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9647 - val_loss: 1.1817\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8217 - val_loss: 1.0974\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.6884 - val_loss: 1.0993\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6158 - val_loss: 1.0508\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5378 - val_loss: 1.0914\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4719 - val_loss: 1.0576\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4033 - val_loss: 1.0408\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3619 - val_loss: 1.0272\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3290 - val_loss: 1.0342\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2898 - val_loss: 1.0155\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2385 - val_loss: 1.0277\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2340 - val_loss: 1.0212\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.1961 - val_loss: 1.0233\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1572 - val_loss: 1.0069\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1596 - val_loss: 1.0019\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1245 - val_loss: 1.0190\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1076 - val_loss: 0.9820\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1243 - val_loss: 0.9932\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0909 - val_loss: 0.9867\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0960 - val_loss: 0.9852\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0536 - val_loss: 0.9812\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0872 - val_loss: 0.9965\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0570 - val_loss: 0.9855\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0592 - val_loss: 0.9867\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0450 - val_loss: 0.9773\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0538 - val_loss: 0.9802\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0290 - val_loss: 0.9702\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0409 - val_loss: 0.9830\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0348 - val_loss: 0.9718\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0255 - val_loss: 0.9798\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0068 - val_loss: 0.9721\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0260 - val_loss: 0.9755\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0050 - val_loss: 0.9695\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0071 - val_loss: 0.9801\n",
      "Epoch 39/300\n",
      " - 2s - loss: 1.0006 - val_loss: 0.9738\n",
      "Epoch 40/300\n",
      " - 2s - loss: 0.9948 - val_loss: 0.9790\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9910 - val_loss: 0.9714\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9783 - val_loss: 0.9673\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9754 - val_loss: 0.9689\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9660 - val_loss: 0.9720\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9759 - val_loss: 0.9709\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9693 - val_loss: 0.9686\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9684 - val_loss: 0.9757\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9591 - val_loss: 0.9761\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9622 - val_loss: 0.9753\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9592 - val_loss: 0.9773\n",
      "Epoch 51/300\n",
      " - 3s - loss: 0.9579 - val_loss: 0.9753\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9522 - val_loss: 0.9778\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9597 - val_loss: 0.9866\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9503 - val_loss: 0.9765\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9487 - val_loss: 0.9718\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9492 - val_loss: 0.9742\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9463 - val_loss: 0.9806\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9379 - val_loss: 0.9780\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9493 - val_loss: 0.9797\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9339 - val_loss: 0.9797\n",
      "Epoch 61/300\n",
      " - 2s - loss: 0.9293 - val_loss: 0.9815\n",
      "Epoch 62/300\n",
      " - 2s - loss: 0.9363 - val_loss: 0.9796\n",
      "Epoch 63/300\n",
      " - 2s - loss: 0.9295 - val_loss: 0.9744\n",
      "Epoch 64/300\n",
      " - 2s - loss: 0.9249 - val_loss: 0.9810\n",
      "Epoch 65/300\n",
      " - 2s - loss: 0.9251 - val_loss: 0.9792\n",
      "Epoch 66/300\n",
      " - 2s - loss: 0.9210 - val_loss: 0.9786\n",
      "Epoch 67/300\n",
      " - 2s - loss: 0.9215 - val_loss: 0.9782\n",
      "Epoch 68/300\n",
      " - 2s - loss: 0.9245 - val_loss: 0.9756\n",
      "Epoch 69/300\n",
      " - 2s - loss: 0.9191 - val_loss: 0.9808\n",
      "Epoch 70/300\n",
      " - 2s - loss: 0.9170 - val_loss: 0.9821\n",
      "Epoch 71/300\n",
      " - 2s - loss: 0.9160 - val_loss: 0.9809\n",
      "Epoch 72/300\n",
      " - 2s - loss: 0.9181 - val_loss: 0.9813\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00072: early stopping\n",
      "rse: 0.9835041138621167\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.4821 - val_loss: 3.0663\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.6958 - val_loss: 2.1648\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7761 - val_loss: 1.7026\n",
      "Epoch 4/300\n",
      " - 3s - loss: 2.2504 - val_loss: 1.2210\n",
      "Epoch 5/300\n",
      " - 2s - loss: 2.0033 - val_loss: 1.1460\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8201 - val_loss: 1.1283\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7424 - val_loss: 1.1276\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6143 - val_loss: 1.0636\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5278 - val_loss: 1.0679\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4883 - val_loss: 1.0451\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.3998 - val_loss: 1.0374\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3918 - val_loss: 1.0376\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3474 - val_loss: 1.0261\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2827 - val_loss: 1.0165\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2611 - val_loss: 1.0169\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2206 - val_loss: 1.0109\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2090 - val_loss: 1.0277\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1882 - val_loss: 0.9967\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1552 - val_loss: 1.0043\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1400 - val_loss: 1.0341\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1241 - val_loss: 0.9952\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1149 - val_loss: 1.0185\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.1160 - val_loss: 0.9910\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0900 - val_loss: 0.9922\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0789 - val_loss: 0.9918\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0888 - val_loss: 1.0007\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0723 - val_loss: 0.9899\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0630 - val_loss: 0.9883\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0485 - val_loss: 0.9913\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0600 - val_loss: 1.0083\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0433 - val_loss: 0.9885\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0431 - val_loss: 0.9913\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0330 - val_loss: 0.9891\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0319 - val_loss: 0.9954\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0202 - val_loss: 0.9927\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0275 - val_loss: 0.9961\n",
      "Epoch 37/300\n",
      " - 2s - loss: 0.9988 - val_loss: 0.9927\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0106 - val_loss: 1.0042\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9975 - val_loss: 0.9974\n",
      "Epoch 40/300\n",
      " - 2s - loss: 0.9966 - val_loss: 1.0462\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9984 - val_loss: 0.9959\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9769 - val_loss: 0.9933\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9830 - val_loss: 0.9965\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9611 - val_loss: 1.0022\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9822 - val_loss: 1.0012\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9681 - val_loss: 0.9954\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9662 - val_loss: 0.9975\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9583 - val_loss: 0.9952\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9625 - val_loss: 0.9962\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9522 - val_loss: 0.9998\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9559 - val_loss: 1.0243\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9542 - val_loss: 0.9990\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9573 - val_loss: 0.9999\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9436 - val_loss: 0.9997\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9417 - val_loss: 0.9992\n",
      "Epoch 56/300\n",
      " - 2s - loss: 0.9453 - val_loss: 1.0029\n",
      "Epoch 57/300\n",
      " - 2s - loss: 0.9525 - val_loss: 1.0102\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9473 - val_loss: 1.0028\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00058: early stopping\n",
      "rse: 0.9941243407673057\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.3409 - val_loss: 3.1012\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.6947 - val_loss: 2.0884\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7867 - val_loss: 1.4560\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2156 - val_loss: 1.2174\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9491 - val_loss: 1.1356\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.7983 - val_loss: 1.0771\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.6483 - val_loss: 1.0338\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.5783 - val_loss: 1.0428\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5043 - val_loss: 1.0147\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4412 - val_loss: 1.0027\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.3997 - val_loss: 0.9996\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3593 - val_loss: 0.9980\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3114 - val_loss: 0.9902\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.2790 - val_loss: 0.9844\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2399 - val_loss: 0.9880\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2180 - val_loss: 0.9766\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.2107 - val_loss: 0.9851\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1619 - val_loss: 0.9680\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1546 - val_loss: 0.9698\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1166 - val_loss: 0.9688\n",
      "Epoch 21/300\n",
      " - 3s - loss: 1.1079 - val_loss: 0.9569\n",
      "Epoch 22/300\n",
      " - 3s - loss: 1.1006 - val_loss: 0.9604\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0946 - val_loss: 0.9588\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0984 - val_loss: 0.9652\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0871 - val_loss: 0.9572\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0783 - val_loss: 0.9599\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0668 - val_loss: 0.9570\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0615 - val_loss: 0.9656\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0515 - val_loss: 0.9516\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0574 - val_loss: 0.9555\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0322 - val_loss: 0.9597\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0418 - val_loss: 0.9574\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0286 - val_loss: 0.9494\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0355 - val_loss: 0.9527\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0225 - val_loss: 0.9525\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0288 - val_loss: 0.9650\n",
      "Epoch 37/300\n",
      " - 2s - loss: 1.0118 - val_loss: 0.9628\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0081 - val_loss: 0.9533\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9995 - val_loss: 0.9530\n",
      "Epoch 40/300\n",
      " - 2s - loss: 0.9994 - val_loss: 0.9610\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9833 - val_loss: 0.9537\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9764 - val_loss: 0.9526\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9708 - val_loss: 0.9539\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9648 - val_loss: 0.9520\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9688 - val_loss: 0.9591\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9690 - val_loss: 0.9556\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9714 - val_loss: 0.9549\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9593 - val_loss: 0.9555\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9638 - val_loss: 0.9549\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9497 - val_loss: 0.9552\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9607 - val_loss: 0.9555\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9488 - val_loss: 0.9555\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9554 - val_loss: 0.9553\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9562 - val_loss: 0.9552\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9549 - val_loss: 0.9570\n",
      "Epoch 56/300\n",
      " - 3s - loss: 0.9435 - val_loss: 0.9623\n",
      "Epoch 57/300\n",
      " - 3s - loss: 0.9514 - val_loss: 0.9540\n",
      "Epoch 58/300\n",
      " - 2s - loss: 0.9496 - val_loss: 0.9569\n",
      "Epoch 59/300\n",
      " - 2s - loss: 0.9436 - val_loss: 0.9576\n",
      "Epoch 60/300\n",
      " - 2s - loss: 0.9446 - val_loss: 0.9571\n",
      "Epoch 61/300\n",
      " - 2s - loss: 0.9391 - val_loss: 0.9565\n",
      "Epoch 62/300\n",
      " - 2s - loss: 0.9260 - val_loss: 0.9573\n",
      "Epoch 63/300\n",
      " - 2s - loss: 0.9320 - val_loss: 0.9613\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00063: early stopping\n",
      "rse: 0.9743647759142252\n",
      "Train on 14781 samples, validate on 4927 samples\n",
      "Epoch 1/300\n",
      " - 4s - loss: 5.4430 - val_loss: 3.1254\n",
      "Epoch 2/300\n",
      " - 2s - loss: 3.6997 - val_loss: 2.1485\n",
      "Epoch 3/300\n",
      " - 2s - loss: 2.7809 - val_loss: 1.3904\n",
      "Epoch 4/300\n",
      " - 2s - loss: 2.2708 - val_loss: 1.2960\n",
      "Epoch 5/300\n",
      " - 2s - loss: 1.9844 - val_loss: 1.1886\n",
      "Epoch 6/300\n",
      " - 2s - loss: 1.8734 - val_loss: 1.1600\n",
      "Epoch 7/300\n",
      " - 2s - loss: 1.7019 - val_loss: 1.1516\n",
      "Epoch 8/300\n",
      " - 2s - loss: 1.6119 - val_loss: 1.1112\n",
      "Epoch 9/300\n",
      " - 2s - loss: 1.5392 - val_loss: 1.0979\n",
      "Epoch 10/300\n",
      " - 2s - loss: 1.4646 - val_loss: 1.0845\n",
      "Epoch 11/300\n",
      " - 2s - loss: 1.4045 - val_loss: 1.0858\n",
      "Epoch 12/300\n",
      " - 2s - loss: 1.3470 - val_loss: 1.0747\n",
      "Epoch 13/300\n",
      " - 2s - loss: 1.3337 - val_loss: 1.0604\n",
      "Epoch 14/300\n",
      " - 2s - loss: 1.3013 - val_loss: 1.0406\n",
      "Epoch 15/300\n",
      " - 2s - loss: 1.2413 - val_loss: 1.0429\n",
      "Epoch 16/300\n",
      " - 2s - loss: 1.2250 - val_loss: 1.0407\n",
      "Epoch 17/300\n",
      " - 2s - loss: 1.1803 - val_loss: 1.0422\n",
      "Epoch 18/300\n",
      " - 2s - loss: 1.1747 - val_loss: 1.0467\n",
      "Epoch 19/300\n",
      " - 2s - loss: 1.1494 - val_loss: 1.0348\n",
      "Epoch 20/300\n",
      " - 2s - loss: 1.1370 - val_loss: 1.0268\n",
      "Epoch 21/300\n",
      " - 2s - loss: 1.1164 - val_loss: 1.0162\n",
      "Epoch 22/300\n",
      " - 2s - loss: 1.1026 - val_loss: 1.0568\n",
      "Epoch 23/300\n",
      " - 2s - loss: 1.0863 - val_loss: 1.0208\n",
      "Epoch 24/300\n",
      " - 2s - loss: 1.0793 - val_loss: 1.0279\n",
      "Epoch 25/300\n",
      " - 2s - loss: 1.0824 - val_loss: 1.0154\n",
      "Epoch 26/300\n",
      " - 2s - loss: 1.0644 - val_loss: 1.0259\n",
      "Epoch 27/300\n",
      " - 2s - loss: 1.0624 - val_loss: 1.0178\n",
      "Epoch 28/300\n",
      " - 2s - loss: 1.0586 - val_loss: 1.0432\n",
      "Epoch 29/300\n",
      " - 2s - loss: 1.0524 - val_loss: 1.0181\n",
      "Epoch 30/300\n",
      " - 2s - loss: 1.0619 - val_loss: 1.0207\n",
      "Epoch 31/300\n",
      " - 2s - loss: 1.0351 - val_loss: 1.0156\n",
      "Epoch 32/300\n",
      " - 2s - loss: 1.0355 - val_loss: 1.0306\n",
      "Epoch 33/300\n",
      " - 2s - loss: 1.0271 - val_loss: 1.0165\n",
      "Epoch 34/300\n",
      " - 2s - loss: 1.0204 - val_loss: 1.0393\n",
      "Epoch 35/300\n",
      " - 2s - loss: 1.0023 - val_loss: 1.0263\n",
      "Epoch 36/300\n",
      " - 2s - loss: 1.0238 - val_loss: 1.0265\n",
      "Epoch 37/300\n",
      " - 2s - loss: 0.9994 - val_loss: 1.0158\n",
      "Epoch 38/300\n",
      " - 2s - loss: 1.0057 - val_loss: 1.0229\n",
      "Epoch 39/300\n",
      " - 2s - loss: 0.9891 - val_loss: 1.0287\n",
      "Epoch 40/300\n",
      " - 2s - loss: 0.9904 - val_loss: 1.0168\n",
      "Epoch 41/300\n",
      " - 2s - loss: 0.9803 - val_loss: 1.0173\n",
      "Epoch 42/300\n",
      " - 2s - loss: 0.9722 - val_loss: 1.0175\n",
      "Epoch 43/300\n",
      " - 2s - loss: 0.9796 - val_loss: 1.0350\n",
      "Epoch 44/300\n",
      " - 2s - loss: 0.9685 - val_loss: 1.0191\n",
      "Epoch 45/300\n",
      " - 2s - loss: 0.9765 - val_loss: 1.0209\n",
      "Epoch 46/300\n",
      " - 2s - loss: 0.9636 - val_loss: 1.0164\n",
      "Epoch 47/300\n",
      " - 2s - loss: 0.9596 - val_loss: 1.0241\n",
      "Epoch 48/300\n",
      " - 2s - loss: 0.9531 - val_loss: 1.0209\n",
      "Epoch 49/300\n",
      " - 2s - loss: 0.9535 - val_loss: 1.0296\n",
      "Epoch 50/300\n",
      " - 2s - loss: 0.9493 - val_loss: 1.0241\n",
      "Epoch 51/300\n",
      " - 2s - loss: 0.9524 - val_loss: 1.0271\n",
      "Epoch 52/300\n",
      " - 2s - loss: 0.9449 - val_loss: 1.0210\n",
      "Epoch 53/300\n",
      " - 2s - loss: 0.9432 - val_loss: 1.0222\n",
      "Epoch 54/300\n",
      " - 2s - loss: 0.9467 - val_loss: 1.0237\n",
      "Epoch 55/300\n",
      " - 2s - loss: 0.9408 - val_loss: 1.0245\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00055: early stopping\n",
      "rse: 1.007656278800506\n",
      "mean rse: 0.9899123773360383\n",
      "mean kappa: 0.5892697556742557\n",
      "oof kappa: 0.5896975391580779\n",
      "[1.00672 1.72316 2.25154]\n",
      "mean cappa 0.5518848122420462\n",
      "New threshold [1.006720000000001, 1.7231600000000007, 2.2515400000000017]\n",
      "3.0    500\n",
      "2.0    189\n",
      "1.0    167\n",
      "0.0    144\n",
      "dtype: int64\n",
      "Overall situation-----------------------\n",
      "Mean rmse 0.98868\n",
      "Mean cappa 0.55617\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-49d7a4a20c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpred_lgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimpor1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moof_class_lgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moof_num_lgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_num1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_all_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mins_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqwk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_class_lgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_th_assess\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_th_assess\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqwk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moof_class_lgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_th_assess\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_th_assess\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "pred_lgb,impor1,oof_class_lgb,oof_num_lgb,pred_num1 = run_all_nn(X_train,y_train,ins_id,X_test)\n",
    "print(qwk(oof_class_lgb[X_train.num_th_assess ==0],y_train[X_train.num_th_assess ==0]))\n",
    "print(qwk(oof_class_lgb[X_train.num_th_assess !=0],y_train[X_train.num_th_assess !=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.484\n",
       "2    0.202\n",
       "1    0.160\n",
       "0    0.154\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['accuracy_group'] = pred_lgb.astype(int)\n",
    "sample_submission.to_csv('./submission.csv', index=False)\n",
    "sample_submission['accuracy_group'].value_counts(normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
