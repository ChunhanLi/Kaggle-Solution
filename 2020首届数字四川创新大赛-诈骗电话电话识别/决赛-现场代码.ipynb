{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit,StratifiedKFold,TimeSeriesSplit,KFold,GroupKFold,train_test_split,GroupShuffleSplit,StratifiedShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error,log_loss,confusion_matrix,accuracy_score,f1_score\n",
    "\n",
    "import gc\n",
    "\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "test_app = pd.read_csv('../../raw_data/test_xianchang/test/test_app.csv')\n",
    "test_sms = pd.read_csv('../../raw_data/test_xianchang/test/test_sms.csv')\n",
    "test_user = pd.read_csv('../../raw_data/test_xianchang/test/test_user.csv')\n",
    "test_voc = pd.read_csv('../../raw_data/test_xianchang/test/test_voc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = pd.read_csv('../../raw_data/test_xianchang/test/test_user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000     101\n",
       "19.000000     37\n",
       "13.600000     23\n",
       "59.000000     20\n",
       "9.000000      17\n",
       "            ... \n",
       "12.920000      1\n",
       "31.190001      1\n",
       "64.889999      1\n",
       "19.379999      1\n",
       "22.600000      1\n",
       "Name: arpu_202005, Length: 893, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user_fusai.arpu_202005.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.00      199\n",
       "19.00     129\n",
       "59.00      63\n",
       "49.00      54\n",
       "9.00       30\n",
       "         ... \n",
       "3.40        1\n",
       "32.73       1\n",
       "83.27       1\n",
       "414.92      1\n",
       "64.82       1\n",
       "Name: arpu_202007, Length: 1698, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user.arpu_202007.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "####如果有NA要改 数据格式\n",
    "test_user = test_user.replace('\\\\N',np.nan)\n",
    "test_user.arpu_202007 = test_user.arpu_202007.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "####读取数据\n",
    "train_app = pd.read_csv('../../raw_data/201908_202003/train_app.csv')\n",
    "train_sms = pd.read_csv('../../raw_data/201908_202003/train_sms.csv')\n",
    "train_user = pd.read_csv('../../raw_data/201908_202003/train_user.csv')\n",
    "train_voc = pd.read_csv('../../raw_data/201908_202003/train_voc.csv')\n",
    "\n",
    "test_app_juesai = pd.read_csv('../../raw_data/202006/train_app.csv')\n",
    "test_sms_juesai = pd.read_csv('../../raw_data/202006/train_sms.csv')\n",
    "test_user_juesai = pd.read_csv('../../raw_data/202006/train_user.csv')\n",
    "test_voc_juesai = pd.read_csv('../../raw_data/202006/train_voc.csv')\n",
    "\n",
    "\n",
    "test_app_chusai = pd.read_csv('../../raw_data/202004/train_app.csv')\n",
    "test_sms_chusai = pd.read_csv('../../raw_data/202004/train_sms.csv')\n",
    "test_user_chusai = pd.read_csv('../../raw_data/202004/train_user.csv')\n",
    "test_voc_chusai = pd.read_csv('../../raw_data/202004/train_voc.csv')\n",
    "\n",
    "test_user_fusai = pd.read_csv('../../raw_data/202005/train_user.csv')\n",
    "test_voc_fusai  = pd.read_csv('../../raw_data/202005/train_voc.csv')\n",
    "test_app_fusai  = pd.read_csv('../../raw_data/202005/train_app.csv')\n",
    "test_sms_fusai  = pd.read_csv('../../raw_data/202005/train_sms.csv')\n",
    "\n",
    "test_user_fusai = test_user_fusai.replace('\\\\N',np.nan)\n",
    "test_user_fusai.arpu_202005 = test_user_fusai.arpu_202005.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_dict = {'成都': 22,\n",
    " 'nan': 21,\n",
    " '绵阳': 20,\n",
    " '达州': 19,\n",
    " '宜宾': 18,\n",
    " '凉山': 17,\n",
    " '乐山': 16,\n",
    " '南充': 15,\n",
    " '广元': 14,\n",
    " '自贡': 13,\n",
    " '德阳': 12,\n",
    " '泸州': 11,\n",
    " '眉山': 10,\n",
    " '雅安': 9,\n",
    " '内江': 8,\n",
    " '遂宁': 7,\n",
    " '资阳': 6,\n",
    " '攀枝花': 5,\n",
    " '巴中': 4,\n",
    " '广安': 3,\n",
    " '阿坝': 2,\n",
    " '甘孜': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voc_feats(train_voc):\n",
    "    \"\"\"\n",
    "    构建通话记录voc表的特征\n",
    "    \"\"\"\n",
    "    combine_list = []\n",
    "    ### voc表时间转换\n",
    "    train_voc['start_datetime'] = pd.to_datetime(train_voc['start_datetime'])\n",
    "    train_voc['weekday'] = train_voc.start_datetime.dt.weekday\n",
    "    train_voc['hour'] = train_voc.start_datetime.dt.hour\n",
    "    train_voc['minute'] = train_voc.start_datetime.dt.minute\n",
    "    train_voc['second'] = train_voc.start_datetime.dt.second\n",
    "    train_voc['date'] = train_voc.start_datetime.dt.date\n",
    "    ### 给多少人打过电话/打过多少个电话\n",
    "    num_pep_voc_train = train_voc.groupby(['phone_no_m'])['opposite_no_m'].agg(num_call_voc = 'count',num_pep_voc = 'nunique').reset_index()\n",
    "    combine_list.append(num_pep_voc_train)\n",
    "    #### 打电话的人里面次数最大小次/平均\n",
    "    tmp_train = train_voc.groupby(['phone_no_m','opposite_no_m'],as_index=False)['calltype_id'].count()\n",
    "    num_mean_max_min_for_one_pep_train = \\\n",
    "        tmp_train.groupby(['phone_no_m'])['calltype_id'].agg(num_call_for_1pep_mean = 'mean',\n",
    "                                                                            num_call_for_1pep_min = 'min',\n",
    "                                                                            num_call_for_1pep_max = 'max').reset_index()\n",
    "    combine_list.append(num_mean_max_min_for_one_pep_train)\n",
    "    #### 一个手机登录了几个IMEI\n",
    "    num_imei_train = train_voc.groupby(['phone_no_m'],as_index=True)['imei_m'].agg(num_imei_voc = 'nunique').reset_index()\n",
    "    combine_list.append(num_imei_train)\n",
    "    \n",
    "    #### calltype_id count ratio/数量差/比例差\n",
    "    tmp_phone_call_id = train_voc.groupby(['phone_no_m','calltype_id']).size().reset_index()\n",
    "    tmp_phone_call_id.columns = ['phone_no_m','calltype_id','num_call_per_calltype']\n",
    "    ## 每个用户的通话总数\n",
    "    \n",
    "    tmp_phone = train_voc.groupby(['phone_no_m']).size().reset_index()\n",
    "    tmp_phone.columns = ['phone_no_m','number_call']\n",
    "    \n",
    "    tmp_phone_call_id = tmp_phone_call_id.merge(tmp_phone,how='left',on='phone_no_m')\n",
    "    \n",
    "    tmp_phone_call_id['ratio_call_per_calltype'] = tmp_phone_call_id.num_call_per_calltype/tmp_phone_call_id.number_call\n",
    "    tmp_all = pd.pivot(tmp_phone_call_id[['phone_no_m','calltype_id','num_call_per_calltype','ratio_call_per_calltype']],index='phone_no_m',columns='calltype_id').fillna(0)\n",
    "    tmp_list = []\n",
    "    for a,b in tmp_all.columns:\n",
    "        tmp_list.append(str(a)+'_'+str(b))\n",
    "    tmp_all.columns = tmp_list\n",
    "    tmp_all = tmp_all.reset_index()\n",
    "    tmp_all['diff_num_calls_1_2'] = tmp_all['num_call_per_calltype_1'] - tmp_all['num_call_per_calltype_2']\n",
    "    tmp_all['diff_ratio_calls_1_2'] = tmp_all['ratio_call_per_calltype_1'] - tmp_all['ratio_call_per_calltype_2']\n",
    "    combine_list.append(tmp_all)\n",
    "    ####增加电话时长的一些统计信息\n",
    "    call_dur = train_voc.groupby('phone_no_m')['call_dur'].agg(\n",
    "                                                                call_dur_mean = 'mean',\n",
    "                                                                call_dur_quantile25 = lambda x:np.quantile(x,0.25),\n",
    "                                                                call_dur_quantile75 = lambda x:np.quantile(x,0.75),\n",
    "                                                                call_dur_median = 'median',\n",
    "                                                                call_dur_max = 'max',\n",
    "                                                                call_dur_min = 'min',\n",
    "                                                                call_dur_skew = lambda x:x.skew(),\n",
    "                                                                call_dur_kurt = lambda x:x.kurt(),\n",
    "                                                                call_dur_std = 'std'\n",
    "                                                                            ).reset_index()\n",
    "    combine_list.append(call_dur)\n",
    "    #### calltype_id打电话时长均值的差/比例的差\n",
    "\n",
    "    tmp2 = train_voc.groupby(['phone_no_m','calltype_id'],as_index=False)['call_dur'].mean()\n",
    "    tmp3 = pd.pivot(tmp2,index='phone_no_m',columns='calltype_id').fillna(0)\n",
    "    col_list = []\n",
    "    for a,b in tmp3.columns:\n",
    "        col_list.append(str(a)+'_'+str(b))\n",
    "    tmp3.columns=col_list\n",
    "    tmp3['diff_mean_dur_1_2'] = tmp3['call_dur_1'] - tmp3['call_dur_2']\n",
    "    tmp3['ratio_mean_dur_1_2'] = tmp3['call_dur_1'] / tmp3['call_dur_2']\n",
    "    diff_ratio_call_dur =tmp3[['diff_mean_dur_1_2','ratio_mean_dur_1_2']].reset_index()\n",
    "    combine_list.append(diff_ratio_call_dur)\n",
    "    \n",
    "    \n",
    "    #### city is null ratio \n",
    "\n",
    "    train_voc['is_na_city_raio'] = train_voc.city_name.isna()+0\n",
    "    tmp_is_null_ratio = train_voc.groupby(['phone_no_m'])['is_na_city_raio'].mean().reset_index()\n",
    "    combine_list.append(tmp_is_null_ratio)\n",
    "    ### 每天打电话次数的均值/方差/方差均值之比/有打电话的天数\n",
    "\n",
    "    tmp_call_day = train_voc.groupby(['phone_no_m','date'],as_index=False)['opposite_no_m'].count()\n",
    "    tmp_1 = tmp_call_day.groupby(['phone_no_m'])['opposite_no_m'].agg(mean_call_per_day='mean',std_call_per_day='std',max_call_per_day = 'max').reset_index()\n",
    "    #tmp_1['std_mean_ratio_call_per_day'] = tmp_1['std_call_per_day']/tmp_1['mean_call_per_day']\n",
    "    tmp_2 = tmp_call_day.groupby(['phone_no_m'])['date'].agg(voc_nunique_day='nunique').reset_index()\n",
    "    combine_list.append(tmp_1)\n",
    "    combine_list.append(tmp_2)\n",
    "\n",
    "    ### add voc hour_min_max/std/mean 每天打电话时间的最早小时和最晚小时的方差和均值 众数小时的方差和均值\n",
    "\n",
    "    tmp_min = train_voc.groupby(['phone_no_m','date'],as_index=False)['hour'].min()\n",
    "    tmp_min_std = tmp_min.groupby(['phone_no_m'])['hour'].agg(voc_hour_min_std='std').reset_index()\n",
    "\n",
    "    tmp_max = train_voc.groupby(['phone_no_m','date'],as_index=False)['hour'].max()\n",
    "    tmp_max_std = tmp_max.groupby(['phone_no_m'])['hour'].agg(voc_hour_max_std='std').reset_index()\n",
    "\n",
    "    tmp_min = train_voc.groupby(['phone_no_m','date'],as_index=False)['hour'].min()\n",
    "    tmp_min_mean = tmp_min.groupby(['phone_no_m'])['hour'].agg(voc_hour_min_mean='mean').reset_index()\n",
    "\n",
    "    tmp_max = train_voc.groupby(['phone_no_m','date'],as_index=False)['hour'].max()\n",
    "    tmp_max_mean = tmp_max.groupby(['phone_no_m'])['hour'].agg(voc_hour_max_mean='mean').reset_index()\n",
    "    \n",
    "    tmp_mode = train_voc.groupby(['phone_no_m','date'],as_index=False)['hour'].agg(lambda x:x.mode()[0])\n",
    "    tmp_mode_std = tmp_mode.groupby(['phone_no_m'])['hour'].agg(voc_hour_mode_std='std').reset_index()\n",
    "    \n",
    "    tmp_mode = train_voc.groupby(['phone_no_m','date'],as_index=False)['hour'].agg(lambda x:x.mode()[0])\n",
    "    tmp_mode_mean = tmp_mode.groupby(['phone_no_m'])['hour'].agg(voc_hour_mode_mean='mean').reset_index()\n",
    "    \n",
    "    combine_list.append(tmp_min_std)\n",
    "    combine_list.append(tmp_max_std)\n",
    "    combine_list.append(tmp_min_mean)\n",
    "    combine_list.append(tmp_max_mean)\n",
    "    \n",
    "    combine_list.append(tmp_mode_std)\n",
    "    combine_list.append(tmp_mode_mean)\n",
    "    \n",
    "    #### add hour 比例分布\n",
    "    hour_tmp1 = train_voc.groupby(['phone_no_m','hour'],as_index=False)['opposite_no_m'].count()\n",
    "    hour_tmp2 = hour_tmp1.groupby(['phone_no_m'])['opposite_no_m'].transform('sum')\n",
    "    hour_tmp1['opposite_no_m'] = hour_tmp1['opposite_no_m']/hour_tmp2\n",
    "    hour_tmp1.columns = ['phone_no_m','hour','call_ratio']\n",
    "    tmp_a = pd.pivot(hour_tmp1,index='phone_no_m',columns='hour')\n",
    "    assert tmp_a.shape[1]==24\n",
    "    tmp_a = tmp_a.fillna(0)\n",
    "    list1 = []\n",
    "    for name1,name2 in tmp_a:\n",
    "        list1.append(str(name1)+'_hour_'+str(name2))\n",
    "    tmp_a.columns = list1\n",
    "    tmp_a = tmp_a.reset_index()\n",
    "    combine_list.append(tmp_a)\n",
    "    \n",
    "    ### 打电话所在地情况\n",
    "    def transform_list(series):\n",
    "        tmp = series.value_counts()\n",
    "        max_val = tmp.max()\n",
    "        return sorted(list(tmp[tmp==max_val].index),key = lambda x:order_dict[x])[0]\n",
    "    \n",
    "    tmp = train_voc[['phone_no_m','city_name']]\n",
    "    tmp['city_name'] = tmp['city_name'].astype(str)\n",
    "    tmp_1 = tmp.groupby(['phone_no_m'])['city_name'].agg(lambda x:transform_list(x)).reset_index()\n",
    "    tmp_1.columns = ['phone_no_m','city_name_call_mode']\n",
    "    combine_list.append(tmp_1)\n",
    "    \n",
    "    return combine_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sms_feats(train_sms):\n",
    "    \"\"\"\n",
    "    构建短信记录sms表的特征\n",
    "    \"\"\"\n",
    "    ### 结合各部分特征\n",
    "    combine_list = []\n",
    "    ### 转换时间\n",
    "    train_sms['request_datetime'] = pd.to_datetime(train_sms['request_datetime'])\n",
    "    train_sms['weekday'] = train_sms.request_datetime.dt.weekday\n",
    "    train_sms['hour'] = train_sms.request_datetime.dt.hour\n",
    "    train_sms['minute'] = train_sms.request_datetime.dt.minute\n",
    "    train_sms['second'] = train_sms.request_datetime.dt.second\n",
    "    train_sms['date'] = train_sms.request_datetime.dt.date\n",
    "    #### 短信 calltype count ratio、收发短信数量/比例差\n",
    "    temp = train_sms.groupby(['phone_no_m']).size().reset_index()\n",
    "    temp = temp.rename({0:'count_sms'},axis = 1)\n",
    "    #计算各个用户不同calltype下短信数量\n",
    "    temp_id = train_sms.groupby(['phone_no_m','calltype_id']).size().reset_index()\n",
    "    temp_id = temp_id.rename({0:'count_calltype_sms'},axis = 1)\n",
    "    #合并\n",
    "    temp2 = temp.merge(temp_id,how ='left',on ='phone_no_m')\n",
    "    #计算各个用户下不同calltype短信数量 占 总短信数量比例\n",
    "    temp2['ratio_sms_per_calltype'] = temp2['count_calltype_sms']/temp2['count_sms']\n",
    "    #重组\n",
    "    temp_all = pd.pivot(temp2[['phone_no_m','calltype_id','count_calltype_sms','ratio_sms_per_calltype']], index = 'phone_no_m', columns='calltype_id').fillna(0)\n",
    "    col_name = [col[0] + '_'+ str(col[1]) for col in temp_all.columns]\n",
    "    temp_all.columns = col_name\n",
    "    #计算不同calltype下短信数量差值\n",
    "    temp_all['diff_count_sms_1_2'] = temp_all['count_calltype_sms_1'] - temp_all['count_calltype_sms_2']\n",
    "    #计算不同calltype下短信比例差值\n",
    "    temp_all['diff_ratio_sms_1_2'] = temp_all['ratio_sms_per_calltype_1'] - temp_all['ratio_sms_per_calltype_2']\n",
    "    temp_all = temp_all.reset_index()\n",
    "    combine_list.append(temp_all)\n",
    "    ### 短信 给多少个人短信/多少条/平均\n",
    "    num_pep_sms_train = train_sms.groupby(['phone_no_m'])['opposite_no_m'].agg(num_txt_sms = 'count',num_pep_sms='nunique').reset_index()\n",
    "    combine_list.append(num_pep_sms_train)\n",
    "    #### 短信的人里面次数最大小次/平均\n",
    "    tmp_train = train_sms.groupby(['phone_no_m','opposite_no_m'],as_index=False)['calltype_id'].count()\n",
    "    num_mean_max_min_for_one_pep_sms_train = tmp_train.groupby(['phone_no_m'],as_index=False)['calltype_id'].agg(['mean','min','max']).add_prefix('num_txt_for_1pep_').reset_index()\n",
    "    combine_list.append(num_mean_max_min_for_one_pep_sms_train)\n",
    "\n",
    "    return combine_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_feats(train_app):\n",
    "    \"\"\"\n",
    "    构建app记录app表的特征\n",
    "    \"\"\"\n",
    "    combine_list = []\n",
    "    #### app 登录过多少个APP/用过的总流量\n",
    "    nunique_app_train = train_app.groupby(['phone_no_m'])['busi_name'].agg(num_app='nunique',num_app_log = 'count').reset_index()\n",
    "    combine_list.append(nunique_app_train)\n",
    "    sum_flow_train = train_app.groupby(['phone_no_m'])['flow'].agg(sum_flow = 'sum').reset_index()\n",
    "    combine_list.append(sum_flow_train)\n",
    "    return combine_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe_train_month(train_user,train_voc,train_sms,train_app,month,year):\n",
    "    \"\"\"\n",
    "    对各月数据进行各部分特征进行组合\n",
    "    \"\"\"\n",
    "    if 'type' in train_user.columns:\n",
    "        keep_list = ['phone_no_m','city_name','county_name','idcard_cnt',f'arpu_{str(year)+str(month)}','label','type']\n",
    "    elif 'label' in train_user.columns:\n",
    "        keep_list = ['phone_no_m','city_name','county_name','idcard_cnt',f'arpu_{str(year)+str(month)}','label']\n",
    "    else:\n",
    "        keep_list = ['phone_no_m','city_name','county_name','idcard_cnt',f'arpu_{str(year)+str(month)}']\n",
    "    train_user = train_user[keep_list].copy()\n",
    "    train_user.rename({f'arpu_{str(year)+str(month)}':'last_month_amt'},axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "    combine_list_train = []\n",
    "    \n",
    "    combine_list_train.extend(get_voc_feats(train_voc))\n",
    "    combine_list_train.extend(get_sms_feats(train_sms))\n",
    "    combine_list_train.extend(get_app_feats(train_app))\n",
    "    \n",
    "    for _ in combine_list_train:\n",
    "        train_user = train_user.merge(_,how='left',on='phone_no_m')\n",
    "    train_user['month'] = f'{year}-{month}'\n",
    "    return train_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 将app中null app标记为unknown 方便区别未使用app和 未知的app\n",
    "train_app = train_app[~((train_app.busi_name.isna())&(train_app.month_id.isna()))]\n",
    "test_app = test_app[~((test_app.busi_name.isna())&(test_app.month_id.isna()))]\n",
    "test_app_chusai = test_app_chusai[~((test_app_chusai.busi_name.isna())&(test_app_chusai.month_id.isna()))]\n",
    "test_app_fusai = test_app_fusai[~((test_app_fusai.busi_name.isna())&(test_app_fusai.month_id.isna()))]\n",
    "test_app_juesai = test_app_juesai[~((test_app_juesai.busi_name.isna())&(test_app_juesai.month_id.isna()))]\n",
    "\n",
    "train_app.loc[(train_app.busi_name.isna())&(~train_app.month_id.isna()),'busi_name'] = 'unknown'\n",
    "test_app.loc[(test_app.busi_name.isna())&(~test_app.month_id.isna()),'busi_name'] = 'unknown'\n",
    "test_app_chusai.loc[(test_app_chusai.busi_name.isna())&(~test_app_chusai.month_id.isna()),'busi_name'] = 'unknown'\n",
    "test_app_fusai.loc[(test_app_fusai.busi_name.isna())&(~test_app_fusai.month_id.isna()),'busi_name'] = 'unknown'\n",
    "test_app_juesai.loc[(test_app_juesai.busi_name.isna())&(~test_app_juesai.month_id.isna()),'busi_name'] = 'unknown'\n",
    "\n",
    "#### 区分各月数据\n",
    "train_voc_201908 = train_voc[(train_voc.start_datetime>='2019-08-01 00:00:00')&(train_voc.start_datetime<'2019-09-01 00:00:00')].copy()\n",
    "train_voc_201909 = train_voc[(train_voc.start_datetime>='2019-09-01 00:00:00')&(train_voc.start_datetime<'2019-10-01 00:00:00')].copy()\n",
    "train_voc_201910 = train_voc[(train_voc.start_datetime>='2019-10-01 00:00:00')&(train_voc.start_datetime<'2019-11-01 00:00:00')].copy()\n",
    "train_voc_201911 = train_voc[(train_voc.start_datetime>='2019-11-01 00:00:00')&(train_voc.start_datetime<'2019-12-01 00:00:00')].copy()\n",
    "train_voc_201912 = train_voc[(train_voc.start_datetime>='2019-12-01 00:00:00')&(train_voc.start_datetime<'2020-01-01 00:00:00')].copy()\n",
    "train_voc_202001 = train_voc[(train_voc.start_datetime>='2020-01-01 00:00:00')&(train_voc.start_datetime<'2020-02-01 00:00:00')].copy()\n",
    "train_voc_202002 = train_voc[(train_voc.start_datetime>='2020-02-01 00:00:00')&(train_voc.start_datetime<'2020-03-01 00:00:00')].copy()\n",
    "train_voc_202003 = train_voc[(train_voc.start_datetime>='2020-03-01 00:00:00')&(train_voc.start_datetime<'2020-04-01 00:00:00')].copy()\n",
    "train_sms_201908 = train_sms[(train_sms.request_datetime>='2019-08-01 00:00:00')&(train_sms.request_datetime<'2019-09-01 00:00:00')].copy()\n",
    "train_sms_201909 = train_sms[(train_sms.request_datetime>='2019-09-01 00:00:00')&(train_sms.request_datetime<'2019-10-01 00:00:00')].copy()\n",
    "train_sms_201910 = train_sms[(train_sms.request_datetime>='2019-10-01 00:00:00')&(train_sms.request_datetime<'2019-11-01 00:00:00')].copy()\n",
    "train_sms_201911 = train_sms[(train_sms.request_datetime>='2019-11-01 00:00:00')&(train_sms.request_datetime<'2019-12-01 00:00:00')].copy()\n",
    "train_sms_201912 = train_sms[(train_sms.request_datetime>='2019-12-01 00:00:00')&(train_sms.request_datetime<'2020-01-01 00:00:00')].copy()\n",
    "train_sms_202001 = train_sms[(train_sms.request_datetime>='2020-01-01 00:00:00')&(train_sms.request_datetime<'2020-02-01 00:00:00')].copy()\n",
    "train_sms_202002 = train_sms[(train_sms.request_datetime>='2020-02-01 00:00:00')&(train_sms.request_datetime<'2020-03-01 00:00:00')].copy()\n",
    "train_sms_202003 = train_sms[(train_sms.request_datetime>='2020-03-01 00:00:00')&(train_sms.request_datetime<'2020-04-01 00:00:00')].copy()\n",
    "train_app_201908 = train_app[train_app.month_id=='2019-08']\n",
    "train_app_201909 = train_app[train_app.month_id=='2019-09']\n",
    "train_app_201910 = train_app[train_app.month_id=='2019-10']\n",
    "train_app_201911 = train_app[train_app.month_id=='2019-11']\n",
    "train_app_201912 = train_app[train_app.month_id=='2019-12']\n",
    "train_app_202001 = train_app[train_app.month_id=='2020-01']\n",
    "train_app_202002 = train_app[train_app.month_id=='2020-02']\n",
    "train_app_202003 = train_app[train_app.month_id=='2020-03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#### 各月数据特征加工\n",
    "test_fe = fe_train_month(test_user,test_voc,test_sms,test_app,'07','2020')\n",
    "print('Done')\n",
    "##### 可能要改\n",
    "test_fe_chusai = fe_train_month(test_user_chusai,test_voc_chusai,test_sms_chusai,test_app_chusai,'04','2020')\n",
    "print('Done')\n",
    "test_fe_fusai = fe_train_month(test_user_fusai,test_voc_fusai,test_sms_fusai,test_app_fusai,'05','2020')\n",
    "print('Done')\n",
    "test_fe_juesai = fe_train_month(test_user_juesai,test_voc_juesai,test_sms_juesai,test_app_juesai,'06','2020')\n",
    "print('Done')\n",
    "train_fe_201908 = fe_train_month(train_user,train_voc_201908,train_sms_201908,train_app_201908,'08','2019')\n",
    "print('Done')\n",
    "train_fe_201909 = fe_train_month(train_user,train_voc_201909,train_sms_201909,train_app_201909,'09','2019')\n",
    "print('Done')\n",
    "train_fe_201910 = fe_train_month(train_user,train_voc_201910,train_sms_201910,train_app_201909,'10','2019')\n",
    "print('Done')\n",
    "train_fe_201911 = fe_train_month(train_user,train_voc_201911,train_sms_201911,train_app_201911,'11','2019')\n",
    "print('Done')\n",
    "train_fe_201912 = fe_train_month(train_user,train_voc_201912,train_sms_201912,train_app_201912,'12','2019')\n",
    "print('Done')\n",
    "train_fe_202001 = fe_train_month(train_user,train_voc_202001,train_sms_202001,train_app_202001,'01','2020')\n",
    "print('Done')\n",
    "train_fe_202002 = fe_train_month(train_user,train_voc_202002,train_sms_202002,train_app_202002,'02','2020')\n",
    "print('Done')\n",
    "train_fe_202003 = fe_train_month(train_user,train_voc_202003,train_sms_202003,train_app_202003,'03','2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48848, 85)\n"
     ]
    }
   ],
   "source": [
    "#### 组合2019.8-2019.3月数据\n",
    "train_fe = pd.DataFrame()\n",
    "for _ in [train_fe_201908,train_fe_201909,train_fe_201910,train_fe_201911,train_fe_201912,train_fe_202001,train_fe_202002,train_fe_202003]:\n",
    "    train_fe = train_fe.append(_,ignore_index=True)\n",
    "#### 处理特征county_name和city_name\n",
    "train_fe['county_name'] = train_fe.city_name.astype(str) + '_'+train_fe.county_name.astype(str)\n",
    "test_fe['county_name'] = test_fe.city_name.astype(str) + '_'+test_fe.county_name.astype(str)\n",
    "test_fe_chusai['county_name'] = test_fe_chusai.city_name.astype(str) + '_'+test_fe_chusai.county_name.astype(str)\n",
    "test_fe_fusai['county_name'] = test_fe_fusai.city_name.astype(str) + '_'+test_fe_fusai.county_name.astype(str)\n",
    "test_fe_juesai['county_name'] = test_fe_juesai.city_name.astype(str) + '_'+test_fe_juesai.county_name.astype(str)\n",
    "\n",
    "\n",
    "count_columns = ['county_name','city_name','city_name_call_mode']\n",
    "for i in count_columns:\n",
    "    train_fe[i+'_count_full'] = train_fe[i].map(pd.concat([train_fe[i], test_fe_chusai[i],test_fe_fusai[i],test_fe_juesai[i],test_fe[i]], ignore_index=True).value_counts(dropna=False))\n",
    "    test_fe[i+'_count_full'] = test_fe[i].map(pd.concat([train_fe[i], test_fe_chusai[i],test_fe_fusai[i],test_fe_juesai[i],test_fe[i]], ignore_index=True).value_counts(dropna=False))\n",
    "    test_fe_chusai[i+'_count_full'] = test_fe_chusai[i].map(pd.concat([train_fe[i], test_fe_chusai[i],test_fe_fusai[i],test_fe_juesai[i],test_fe[i]], ignore_index=True).value_counts(dropna=False))\n",
    "    test_fe_fusai[i+'_count_full'] = test_fe_fusai[i].map(pd.concat([train_fe[i], test_fe_chusai[i],test_fe_fusai[i],test_fe_juesai[i],test_fe[i]], ignore_index=True).value_counts(dropna=False))\n",
    "    test_fe_juesai[i+'_count_full'] = test_fe_juesai[i].map(pd.concat([train_fe[i], test_fe_chusai[i],test_fe_fusai[i],test_fe_juesai[i],test_fe[i]], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "train_fe_clean = train_fe.copy()\n",
    "print(train_fe_clean.shape)\n",
    "#### label encoding\n",
    "cat_list = ['city_name','county_name','city_name_call_mode']\n",
    "for feature in cat_list:\n",
    "    label_encod = LabelEncoder()\n",
    "    label_encod.fit(list(train_fe_clean[feature].astype(str).values) + list(test_fe[feature].astype(str).values) + \\\n",
    "                    list(test_fe_chusai[feature].astype(str).values) + list(test_fe_fusai[feature].astype(str).values) +\\\n",
    "                   list(test_fe_juesai[feature].astype(str).values))\n",
    "    train_fe_clean[feature] = label_encod.transform(list(train_fe_clean[feature].astype(str).values))\n",
    "    test_fe[feature] = label_encod.transform(list(test_fe[feature].astype(str).values))\n",
    "    test_fe_chusai[feature] = label_encod.transform(list(test_fe_chusai[feature].astype(str).values))\n",
    "    test_fe_fusai[feature] = label_encod.transform(list(test_fe_fusai[feature].astype(str).values))\n",
    "    test_fe_juesai[feature] = label_encod.transform(list(test_fe_juesai[feature].astype(str).values))\n",
    "### 填空值\n",
    "train_fe_clean.fillna(-999,inplace=True)\n",
    "test_fe.fillna(-999,inplace=True)\n",
    "test_fe_chusai.fillna(-999,inplace=True)\n",
    "test_fe_fusai.fillna(-999,inplace=True)\n",
    "test_fe_juesai.fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 去掉无用字段\n",
    "train_fe_clean = train_fe_clean.drop(['month'],axis=1)\n",
    "test_fe_chusai = test_fe_chusai.drop(['month'],axis=1)\n",
    "test_fe_fusai = test_fe_fusai.drop(['month'],axis=1)\n",
    "test_fe_juesai = test_fe_juesai.drop(['month'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40866, 84)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_fe_clean = train_fe_clean.drop_duplicates()\n",
    "train_fe_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 去掉无用字段\n",
    "X_train = train_fe_clean.drop(['phone_no_m'],axis=1)\n",
    "y_train =  X_train['label']\n",
    "X_train.drop(['label'],axis=1,inplace=True)\n",
    "X_test = test_fe.drop(['phone_no_m','month'],axis=1)\n",
    "X_test_chusai = test_fe_chusai.drop(['phone_no_m','label'],axis=1)\n",
    "y_test_chusai = test_fe_chusai['label']\n",
    "X_test_fusai = test_fe_fusai.drop(['phone_no_m','label'],axis=1)\n",
    "y_test_fusai = test_fe_fusai['label']\n",
    "\n",
    "X_test_juesai = test_fe_juesai.drop(['phone_no_m','label'],axis=1)\n",
    "y_test_juesai = test_fe_juesai['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40866, 82)\n",
      "(40866,)\n",
      "(2798, 82)\n",
      "(2045, 82)\n",
      "(2045,)\n",
      "(1450, 82)\n",
      "(1450,)\n",
      "(1895, 82)\n",
      "(1895,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_test_chusai.shape)\n",
    "print(y_test_chusai.shape)\n",
    "print(X_test_fusai.shape)\n",
    "print(y_test_fusai.shape)\n",
    "print(X_test_juesai.shape)\n",
    "print(y_test_juesai.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 合并新四月份数据\n",
    "X_train = X_train.append(X_test_chusai,ignore_index=True)\n",
    "y_train = y_train.append(y_test_chusai,ignore_index=True)\n",
    "X_train = X_train.append(X_test_fusai,ignore_index=True)\n",
    "y_train = y_train.append(y_test_fusai,ignore_index=True)\n",
    "X_train = X_train.append(X_test_juesai,ignore_index=True)\n",
    "y_train = y_train.append(y_test_juesai,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46256, 82)\n",
      "(46256,)\n",
      "(2798, 82)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[X_train.last_month_amt!=-999]\n",
    "X_train = X_train[X_train.last_month_amt!=-999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43523, 82)\n",
      "(43523,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LGB参数\n",
    "bayes_params = \\\n",
    "{'colsample_bytree': 0.3052191680417529,\n",
    " 'min_child_samples': int(77.99927234100667),\n",
    " 'min_child_weight': 0.35416028763298746,\n",
    " 'min_split_gain': 0.06605021932915423,\n",
    " 'num_leaves': int(7.019404890990211),\n",
    " 'reg_alpha': 0.24669417297789042,\n",
    " 'reg_lambda': 1.870655415074352,\n",
    " 'subsample': 0.7992481953020549}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = X_test.replace('\\\\N',-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test.last_month_amt = X_test.last_month_amt.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_1*********************************************\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's f1_macro: 0.775622\n",
      "[100]\tvalid_0's f1_macro: 0.806537\n",
      "[150]\tvalid_0's f1_macro: 0.815918\n",
      "[200]\tvalid_0's f1_macro: 0.819322\n",
      "[250]\tvalid_0's f1_macro: 0.821262\n",
      "[300]\tvalid_0's f1_macro: 0.824071\n",
      "[350]\tvalid_0's f1_macro: 0.828572\n",
      "[400]\tvalid_0's f1_macro: 0.83141\n",
      "[450]\tvalid_0's f1_macro: 0.832368\n",
      "[500]\tvalid_0's f1_macro: 0.834716\n",
      "[550]\tvalid_0's f1_macro: 0.836356\n",
      "[600]\tvalid_0's f1_macro: 0.837354\n",
      "[650]\tvalid_0's f1_macro: 0.838012\n",
      "[700]\tvalid_0's f1_macro: 0.8381\n",
      "[750]\tvalid_0's f1_macro: 0.839589\n",
      "[800]\tvalid_0's f1_macro: 0.839093\n",
      "[850]\tvalid_0's f1_macro: 0.84017\n",
      "[900]\tvalid_0's f1_macro: 0.839341\n",
      "[950]\tvalid_0's f1_macro: 0.841395\n",
      "[1000]\tvalid_0's f1_macro: 0.841158\n",
      "[1050]\tvalid_0's f1_macro: 0.841319\n",
      "[1100]\tvalid_0's f1_macro: 0.843443\n",
      "[1150]\tvalid_0's f1_macro: 0.843689\n",
      "[1200]\tvalid_0's f1_macro: 0.843857\n",
      "[1250]\tvalid_0's f1_macro: 0.845324\n",
      "[1300]\tvalid_0's f1_macro: 0.844259\n",
      "[1350]\tvalid_0's f1_macro: 0.845814\n",
      "[1400]\tvalid_0's f1_macro: 0.846221\n",
      "[1450]\tvalid_0's f1_macro: 0.84655\n",
      "[1500]\tvalid_0's f1_macro: 0.847444\n",
      "[1550]\tvalid_0's f1_macro: 0.847282\n",
      "[1600]\tvalid_0's f1_macro: 0.847363\n",
      "[1650]\tvalid_0's f1_macro: 0.847687\n",
      "[1700]\tvalid_0's f1_macro: 0.848416\n",
      "[1750]\tvalid_0's f1_macro: 0.849064\n",
      "[1800]\tvalid_0's f1_macro: 0.848742\n",
      "[1850]\tvalid_0's f1_macro: 0.84939\n",
      "[1900]\tvalid_0's f1_macro: 0.848498\n",
      "[1950]\tvalid_0's f1_macro: 0.84785\n",
      "[2000]\tvalid_0's f1_macro: 0.848093\n",
      "[2050]\tvalid_0's f1_macro: 0.847769\n",
      "Early stopping, best iteration is:\n",
      "[1851]\tvalid_0's f1_macro: 0.849633\n",
      "fold_2*********************************************\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's f1_macro: 0.794741\n",
      "[100]\tvalid_0's f1_macro: 0.830246\n",
      "[150]\tvalid_0's f1_macro: 0.838827\n",
      "[200]\tvalid_0's f1_macro: 0.842969\n",
      "[250]\tvalid_0's f1_macro: 0.846195\n",
      "[300]\tvalid_0's f1_macro: 0.847757\n",
      "[350]\tvalid_0's f1_macro: 0.850623\n",
      "[400]\tvalid_0's f1_macro: 0.8538\n",
      "[450]\tvalid_0's f1_macro: 0.854678\n",
      "[500]\tvalid_0's f1_macro: 0.856446\n",
      "[550]\tvalid_0's f1_macro: 0.857486\n",
      "[600]\tvalid_0's f1_macro: 0.856008\n",
      "[650]\tvalid_0's f1_macro: 0.85746\n",
      "[700]\tvalid_0's f1_macro: 0.858253\n",
      "[750]\tvalid_0's f1_macro: 0.858567\n",
      "[800]\tvalid_0's f1_macro: 0.859596\n",
      "[850]\tvalid_0's f1_macro: 0.858463\n",
      "[900]\tvalid_0's f1_macro: 0.860383\n",
      "[950]\tvalid_0's f1_macro: 0.860858\n",
      "[1000]\tvalid_0's f1_macro: 0.861405\n",
      "[1050]\tvalid_0's f1_macro: 0.861313\n",
      "[1100]\tvalid_0's f1_macro: 0.862352\n",
      "[1150]\tvalid_0's f1_macro: 0.861767\n",
      "[1200]\tvalid_0's f1_macro: 0.861983\n",
      "[1250]\tvalid_0's f1_macro: 0.863958\n",
      "[1300]\tvalid_0's f1_macro: 0.863652\n",
      "[1350]\tvalid_0's f1_macro: 0.86391\n",
      "[1400]\tvalid_0's f1_macro: 0.863253\n",
      "[1450]\tvalid_0's f1_macro: 0.864193\n",
      "[1500]\tvalid_0's f1_macro: 0.864005\n",
      "[1550]\tvalid_0's f1_macro: 0.86506\n",
      "[1600]\tvalid_0's f1_macro: 0.864193\n",
      "[1650]\tvalid_0's f1_macro: 0.865179\n",
      "[1700]\tvalid_0's f1_macro: 0.86492\n",
      "[1750]\tvalid_0's f1_macro: 0.865249\n",
      "[1800]\tvalid_0's f1_macro: 0.865295\n",
      "[1850]\tvalid_0's f1_macro: 0.86682\n",
      "[1900]\tvalid_0's f1_macro: 0.867027\n",
      "[1950]\tvalid_0's f1_macro: 0.867122\n",
      "[2000]\tvalid_0's f1_macro: 0.866724\n",
      "[2050]\tvalid_0's f1_macro: 0.867823\n",
      "[2100]\tvalid_0's f1_macro: 0.868454\n",
      "[2150]\tvalid_0's f1_macro: 0.86985\n",
      "[2200]\tvalid_0's f1_macro: 0.869348\n",
      "[2250]\tvalid_0's f1_macro: 0.868522\n",
      "[2300]\tvalid_0's f1_macro: 0.869115\n",
      "[2350]\tvalid_0's f1_macro: 0.869716\n",
      "[2400]\tvalid_0's f1_macro: 0.871008\n",
      "[2450]\tvalid_0's f1_macro: 0.871075\n",
      "[2500]\tvalid_0's f1_macro: 0.871307\n",
      "[2550]\tvalid_0's f1_macro: 0.871771\n",
      "[2600]\tvalid_0's f1_macro: 0.872235\n",
      "[2650]\tvalid_0's f1_macro: 0.872666\n",
      "[2700]\tvalid_0's f1_macro: 0.871738\n",
      "[2750]\tvalid_0's f1_macro: 0.871109\n",
      "[2800]\tvalid_0's f1_macro: 0.871042\n",
      "[2850]\tvalid_0's f1_macro: 0.871506\n",
      "Early stopping, best iteration is:\n",
      "[2660]\tvalid_0's f1_macro: 0.873528\n",
      "fold_3*********************************************\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's f1_macro: 0.785317\n",
      "[100]\tvalid_0's f1_macro: 0.823286\n",
      "[150]\tvalid_0's f1_macro: 0.83657\n",
      "[200]\tvalid_0's f1_macro: 0.842184\n",
      "[250]\tvalid_0's f1_macro: 0.842688\n",
      "[300]\tvalid_0's f1_macro: 0.846135\n",
      "[350]\tvalid_0's f1_macro: 0.846542\n",
      "[400]\tvalid_0's f1_macro: 0.849312\n",
      "[450]\tvalid_0's f1_macro: 0.851738\n",
      "[500]\tvalid_0's f1_macro: 0.851333\n",
      "[550]\tvalid_0's f1_macro: 0.851492\n",
      "[600]\tvalid_0's f1_macro: 0.852138\n",
      "[650]\tvalid_0's f1_macro: 0.852614\n",
      "[700]\tvalid_0's f1_macro: 0.853406\n",
      "[750]\tvalid_0's f1_macro: 0.853981\n",
      "[800]\tvalid_0's f1_macro: 0.854854\n",
      "[850]\tvalid_0's f1_macro: 0.855812\n",
      "[900]\tvalid_0's f1_macro: 0.856591\n",
      "[950]\tvalid_0's f1_macro: 0.857244\n",
      "[1000]\tvalid_0's f1_macro: 0.857005\n",
      "[1050]\tvalid_0's f1_macro: 0.858225\n",
      "[1100]\tvalid_0's f1_macro: 0.859637\n",
      "[1150]\tvalid_0's f1_macro: 0.860038\n",
      "[1200]\tvalid_0's f1_macro: 0.8598\n",
      "[1250]\tvalid_0's f1_macro: 0.86084\n",
      "[1300]\tvalid_0's f1_macro: 0.860767\n",
      "[1350]\tvalid_0's f1_macro: 0.861661\n",
      "[1400]\tvalid_0's f1_macro: 0.862372\n",
      "[1450]\tvalid_0's f1_macro: 0.862424\n",
      "[1500]\tvalid_0's f1_macro: 0.862187\n",
      "[1550]\tvalid_0's f1_macro: 0.862495\n",
      "[1600]\tvalid_0's f1_macro: 0.862495\n",
      "[1650]\tvalid_0's f1_macro: 0.863603\n",
      "[1700]\tvalid_0's f1_macro: 0.86311\n",
      "[1750]\tvalid_0's f1_macro: 0.863839\n",
      "[1800]\tvalid_0's f1_macro: 0.865014\n",
      "[1850]\tvalid_0's f1_macro: 0.86391\n",
      "[1900]\tvalid_0's f1_macro: 0.864403\n",
      "[1950]\tvalid_0's f1_macro: 0.864168\n",
      "Early stopping, best iteration is:\n",
      "[1785]\tvalid_0's f1_macro: 0.865908\n",
      "fold_4*********************************************\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's f1_macro: 0.786801\n",
      "[100]\tvalid_0's f1_macro: 0.819659\n",
      "[150]\tvalid_0's f1_macro: 0.829775\n",
      "[200]\tvalid_0's f1_macro: 0.834337\n",
      "[250]\tvalid_0's f1_macro: 0.835475\n",
      "[300]\tvalid_0's f1_macro: 0.837712\n",
      "[350]\tvalid_0's f1_macro: 0.840205\n",
      "[400]\tvalid_0's f1_macro: 0.842599\n",
      "[450]\tvalid_0's f1_macro: 0.845144\n",
      "[500]\tvalid_0's f1_macro: 0.844908\n",
      "[550]\tvalid_0's f1_macro: 0.844825\n",
      "[600]\tvalid_0's f1_macro: 0.846542\n",
      "[650]\tvalid_0's f1_macro: 0.847439\n",
      "[700]\tvalid_0's f1_macro: 0.848657\n",
      "[750]\tvalid_0's f1_macro: 0.849063\n",
      "[800]\tvalid_0's f1_macro: 0.850037\n",
      "[850]\tvalid_0's f1_macro: 0.850921\n",
      "[900]\tvalid_0's f1_macro: 0.851167\n",
      "[950]\tvalid_0's f1_macro: 0.852134\n",
      "[1000]\tvalid_0's f1_macro: 0.852448\n",
      "[1050]\tvalid_0's f1_macro: 0.853093\n",
      "[1100]\tvalid_0's f1_macro: 0.85317\n",
      "[1150]\tvalid_0's f1_macro: 0.854054\n",
      "[1200]\tvalid_0's f1_macro: 0.85631\n",
      "[1250]\tvalid_0's f1_macro: 0.856864\n",
      "[1300]\tvalid_0's f1_macro: 0.857983\n",
      "[1350]\tvalid_0's f1_macro: 0.857833\n",
      "[1400]\tvalid_0's f1_macro: 0.857833\n",
      "[1450]\tvalid_0's f1_macro: 0.857819\n",
      "[1500]\tvalid_0's f1_macro: 0.857028\n",
      "[1550]\tvalid_0's f1_macro: 0.857492\n",
      "Early stopping, best iteration is:\n",
      "[1357]\tvalid_0's f1_macro: 0.858549\n",
      "fold_5*********************************************\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's f1_macro: 0.784296\n",
      "[100]\tvalid_0's f1_macro: 0.818479\n",
      "[150]\tvalid_0's f1_macro: 0.828332\n",
      "[200]\tvalid_0's f1_macro: 0.836675\n",
      "[250]\tvalid_0's f1_macro: 0.837946\n",
      "[300]\tvalid_0's f1_macro: 0.83921\n",
      "[350]\tvalid_0's f1_macro: 0.84482\n",
      "[400]\tvalid_0's f1_macro: 0.84375\n",
      "[450]\tvalid_0's f1_macro: 0.843841\n",
      "[500]\tvalid_0's f1_macro: 0.844417\n",
      "[550]\tvalid_0's f1_macro: 0.845969\n",
      "[600]\tvalid_0's f1_macro: 0.846379\n",
      "[650]\tvalid_0's f1_macro: 0.847275\n",
      "[700]\tvalid_0's f1_macro: 0.847926\n",
      "[750]\tvalid_0's f1_macro: 0.849877\n",
      "[800]\tvalid_0's f1_macro: 0.849794\n",
      "[850]\tvalid_0's f1_macro: 0.850117\n",
      "[900]\tvalid_0's f1_macro: 0.85028\n",
      "[950]\tvalid_0's f1_macro: 0.851242\n",
      "[1000]\tvalid_0's f1_macro: 0.852696\n",
      "[1050]\tvalid_0's f1_macro: 0.852696\n",
      "[1100]\tvalid_0's f1_macro: 0.853667\n",
      "[1150]\tvalid_0's f1_macro: 0.852611\n",
      "[1200]\tvalid_0's f1_macro: 0.85438\n",
      "[1250]\tvalid_0's f1_macro: 0.8551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\tvalid_0's f1_macro: 0.854937\n",
      "[1350]\tvalid_0's f1_macro: 0.856386\n",
      "[1400]\tvalid_0's f1_macro: 0.854947\n",
      "[1450]\tvalid_0's f1_macro: 0.855819\n",
      "[1500]\tvalid_0's f1_macro: 0.856158\n",
      "[1550]\tvalid_0's f1_macro: 0.856321\n",
      "[1600]\tvalid_0's f1_macro: 0.856713\n",
      "[1650]\tvalid_0's f1_macro: 0.85583\n",
      "[1700]\tvalid_0's f1_macro: 0.856788\n",
      "[1750]\tvalid_0's f1_macro: 0.856688\n",
      "[1800]\tvalid_0's f1_macro: 0.857553\n",
      "[1850]\tvalid_0's f1_macro: 0.857717\n",
      "[1900]\tvalid_0's f1_macro: 0.858683\n",
      "[1950]\tvalid_0's f1_macro: 0.858905\n",
      "[2000]\tvalid_0's f1_macro: 0.859158\n",
      "[2050]\tvalid_0's f1_macro: 0.859232\n",
      "[2100]\tvalid_0's f1_macro: 0.860435\n",
      "[2150]\tvalid_0's f1_macro: 0.860763\n",
      "[2200]\tvalid_0's f1_macro: 0.861329\n",
      "[2250]\tvalid_0's f1_macro: 0.861019\n",
      "[2300]\tvalid_0's f1_macro: 0.861256\n",
      "[2350]\tvalid_0's f1_macro: 0.862039\n",
      "[2400]\tvalid_0's f1_macro: 0.86242\n",
      "[2450]\tvalid_0's f1_macro: 0.861803\n",
      "[2500]\tvalid_0's f1_macro: 0.861092\n",
      "[2550]\tvalid_0's f1_macro: 0.862388\n",
      "[2600]\tvalid_0's f1_macro: 0.863006\n",
      "Early stopping, best iteration is:\n",
      "[2402]\tvalid_0's f1_macro: 0.863293\n",
      "Mean f1_macro: 0.86218204071216\n",
      "oof 0.8622347691572312\n"
     ]
    }
   ],
   "source": [
    "#### 五折 LGB\n",
    "kf = StratifiedKFold(n_splits=5,shuffle=True,random_state=32)\n",
    "fea_impor = 0\n",
    "k = 1\n",
    "oof = np.zeros(y_train.shape)\n",
    "pred = 0\n",
    "score_list = []\n",
    "for train_index,test_index in kf.split(X_train,y_train):\n",
    "    print(f'fold_{k}*********************************************')\n",
    "    k+=1\n",
    "    X_train2 = X_train.iloc[train_index,:]\n",
    "    y_train2 = y_train.iloc[train_index]\n",
    "    X_test2 = X_train.iloc[test_index,:]\n",
    "    y_test2 = y_train.iloc[test_index]\n",
    "    clf = lgb.LGBMClassifier(n_estimators=10000, random_state=32,learning_rate=0.06,\\\n",
    "                             importance_type = 'gain',n_jobs = -1,bagging_freq=1,metric='None',**bayes_params)\n",
    "    def f1_score_custom(y_true,y_pred):\n",
    "        #print(y_pred,y_true.shape)\n",
    "        y_pred = y_pred.round()\n",
    "        return 'f1_macro', f1_score(y_true,y_pred,average='macro'), True\n",
    "    clf.fit(X_train2,y_train2,eval_set = [(X_test2,y_test2)],\n",
    "            early_stopping_rounds=200,verbose=50,eval_metric=lambda y_true,y_pred:f1_score_custom(y_true,y_pred))\n",
    "    #joblib.dump(clf, f'lightgbm_adam_fold{k-1}.pkl')\n",
    "    temp = clf.predict_proba(X_test2)[:,1]\n",
    "    oof[test_index] = temp\n",
    "    score_list.append(f1_score(y_test2,temp.round(),average='macro'))\n",
    "    fea_impor += clf.feature_importances_/kf.n_splits\n",
    "    pred += clf.predict_proba(X_test)/kf.n_splits\n",
    "    #break\n",
    "print('Mean f1_macro:',np.mean(score_list))\n",
    "print('oof',f1_score(y_train,oof.round(),average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_impo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>city_name_call_mode</th>\n",
       "      <td>16309.090979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_call_for_1pep_mean</th>\n",
       "      <td>14625.732654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_call_per_day</th>\n",
       "      <td>13241.281789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voc_hour_min_std</th>\n",
       "      <td>6596.303250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idcard_cnt</th>\n",
       "      <td>6474.516357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county_name_count_full</th>\n",
       "      <td>6391.136864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_month_amt</th>\n",
       "      <td>6340.150135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voc_nunique_day</th>\n",
       "      <td>5530.826383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_pep_sms</th>\n",
       "      <td>5499.349807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_call_per_day</th>\n",
       "      <td>5159.481992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_call_per_day</th>\n",
       "      <td>4797.360055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>county_name</th>\n",
       "      <td>4395.206051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_sms_per_calltype_2</th>\n",
       "      <td>4161.405420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_imei_voc</th>\n",
       "      <td>3856.975696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_txt_for_1pep_mean</th>\n",
       "      <td>3718.991086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_call_per_calltype_2</th>\n",
       "      <td>3335.668844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_app</th>\n",
       "      <td>3192.190893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_pep_voc</th>\n",
       "      <td>3185.251659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_calltype_sms_1</th>\n",
       "      <td>2938.528364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_txt_sms</th>\n",
       "      <td>2921.003153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_num_calls_1_2</th>\n",
       "      <td>2670.640507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_flow</th>\n",
       "      <td>2565.468586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_ratio_hour_8</th>\n",
       "      <td>2458.372073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_app_log</th>\n",
       "      <td>2417.915283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_calltype_sms_2</th>\n",
       "      <td>2240.912571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_ratio_hour_23</th>\n",
       "      <td>2173.588001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_call_per_calltype_2</th>\n",
       "      <td>2084.127772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voc_hour_mode_std</th>\n",
       "      <td>2046.849125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_name_count_full</th>\n",
       "      <td>1928.228824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_ratio_hour_7</th>\n",
       "      <td>1839.456481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_txt_for_1pep_max</th>\n",
       "      <td>1788.477061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_na_city_raio</th>\n",
       "      <td>1783.654058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_call_for_1pep_max</th>\n",
       "      <td>1612.986532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_count_sms_1_2</th>\n",
       "      <td>1583.557814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_name_call_mode_count_full</th>\n",
       "      <td>1502.871909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_ratio_hour_0</th>\n",
       "      <td>1502.377670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_sms_per_calltype_1</th>\n",
       "      <td>1396.974134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_name</th>\n",
       "      <td>1379.149826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_call_per_calltype_1</th>\n",
       "      <td>1302.297021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_ratio_hour_9</th>\n",
       "      <td>1172.277955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_dur_quantile75</th>\n",
       "      <td>1131.902131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_ratio_sms_1_2</th>\n",
       "      <td>1082.732232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_ratio_calls_1_2</th>\n",
       "      <td>1040.599146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_call_per_calltype_1</th>\n",
       "      <td>1038.365651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_ratio_hour_18</th>\n",
       "      <td>1009.227089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_ratio_hour_20</th>\n",
       "      <td>988.296014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_dur_quantile25</th>\n",
       "      <td>852.618381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_ratio_hour_11</th>\n",
       "      <td>847.040466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_mean_dur_1_2</th>\n",
       "      <td>804.887818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_dur_median</th>\n",
       "      <td>773.171974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature_impo\n",
       "city_name_call_mode             16309.090979\n",
       "num_call_for_1pep_mean          14625.732654\n",
       "mean_call_per_day               13241.281789\n",
       "voc_hour_min_std                 6596.303250\n",
       "idcard_cnt                       6474.516357\n",
       "county_name_count_full           6391.136864\n",
       "last_month_amt                   6340.150135\n",
       "voc_nunique_day                  5530.826383\n",
       "num_pep_sms                      5499.349807\n",
       "std_call_per_day                 5159.481992\n",
       "max_call_per_day                 4797.360055\n",
       "county_name                      4395.206051\n",
       "ratio_sms_per_calltype_2         4161.405420\n",
       "num_imei_voc                     3856.975696\n",
       "num_txt_for_1pep_mean            3718.991086\n",
       "ratio_call_per_calltype_2        3335.668844\n",
       "num_app                          3192.190893\n",
       "num_pep_voc                      3185.251659\n",
       "count_calltype_sms_1             2938.528364\n",
       "num_txt_sms                      2921.003153\n",
       "diff_num_calls_1_2               2670.640507\n",
       "sum_flow                         2565.468586\n",
       "call_ratio_hour_8                2458.372073\n",
       "num_app_log                      2417.915283\n",
       "count_calltype_sms_2             2240.912571\n",
       "call_ratio_hour_23               2173.588001\n",
       "num_call_per_calltype_2          2084.127772\n",
       "voc_hour_mode_std                2046.849125\n",
       "city_name_count_full             1928.228824\n",
       "call_ratio_hour_7                1839.456481\n",
       "num_txt_for_1pep_max             1788.477061\n",
       "is_na_city_raio                  1783.654058\n",
       "num_call_for_1pep_max            1612.986532\n",
       "diff_count_sms_1_2               1583.557814\n",
       "city_name_call_mode_count_full   1502.871909\n",
       "call_ratio_hour_0                1502.377670\n",
       "ratio_sms_per_calltype_1         1396.974134\n",
       "city_name                        1379.149826\n",
       "num_call_per_calltype_1          1302.297021\n",
       "call_ratio_hour_9                1172.277955\n",
       "call_dur_quantile75              1131.902131\n",
       "diff_ratio_sms_1_2               1082.732232\n",
       "diff_ratio_calls_1_2             1040.599146\n",
       "ratio_call_per_calltype_1        1038.365651\n",
       "call_ratio_hour_18               1009.227089\n",
       "call_ratio_hour_20                988.296014\n",
       "call_dur_quantile25               852.618381\n",
       "call_ratio_hour_11                847.040466\n",
       "diff_mean_dur_1_2                 804.887818\n",
       "call_dur_median                   773.171974"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 特征重要性\n",
    "fea = pd.DataFrame(fea_impor,columns=['feature_impo'],index=X_train.columns).sort_values('feature_impo',ascending=False)\n",
    "fea.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold_list = []\n",
    "# f1_score_list = []\n",
    "# score_df = pd.DataFrame()\n",
    "# for _ in tqdm(np.arange(0.05,1,0.01)):\n",
    "#     threshold_list.append(_)\n",
    "#     f1_score_list.append(f1_score(test_user_fusai.label,pd.Series(pred[:,1]).map(lambda x:1 if x>=_ else 0),average='macro'))\n",
    "# score_df['thres'] = threshold_list\n",
    "# score_df['f1_score'] = f1_score_list\n",
    "# score_df.sort_values('f1_score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = pd.read_csv('../../raw_data/test_xianchang/test/test_user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2042\n",
       "1     756\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 金额为空值(-999)直接标记为黑样本\n",
    "#### 预测概率大于0.7标记为黑样本\n",
    "#### 没交\n",
    "sub = pd.DataFrame()\n",
    "sub['phone_no_m'] = test_user['phone_no_m']\n",
    "sub['label'] = list(pd.Series(pred[:,1]).map(lambda x:1 if x>=0.77 else 0).astype(np.int64))\n",
    "sub['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8 742 0.905\n",
    "    839 0.892\n",
    "0.7 801 0.90*\n",
    "0.75 766 0.906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('2020-11-3-v5-756.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2032\n",
       "1     766\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File data/raw_data_fusai/test/submit_example.csv does not exist: 'data/raw_data_fusai/test/submit_example.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f2a7ea772d0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### 金额为空值(-999)直接标记为黑样本\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#### 预测概率大于0.7标记为黑样本\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/raw_data_fusai/test/submit_example.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0.7\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_month_amt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File data/raw_data_fusai/test/submit_example.csv does not exist: 'data/raw_data_fusai/test/submit_example.csv'"
     ]
    }
   ],
   "source": [
    "#### 金额为空值(-999)直接标记为黑样本\n",
    "#### 预测概率大于0.7标记为黑样本\n",
    "sub = pd.read_csv('data/raw_data_fusai/test/submit_example.csv')\n",
    "sub.label = list(pd.Series(pred[:,1]).map(lambda x:1 if x>=0.7 else 0).astype(np.int64))\n",
    "sub.loc[X_test.last_month_amt==-999,'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
