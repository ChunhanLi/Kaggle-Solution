{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nfl-big-data-bowl-2020/train.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/test.csv.encrypted\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/competition.cpython-36m-x86_64-linux-gnu.so\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2020/kaggle/competitions/nflrush/sample_submission.csv.encrypted\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "v3: new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "###raw mae\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold,TimeSeriesSplit,KFold,GroupKFold\n",
    "from sklearn.metrics import roc_auc_score,mean_squared_error,mean_absolute_error,log_loss\n",
    "import sqlite3\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import pearsonr\n",
    "import gc\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from bayes_opt import BayesianOptimization\n",
    "from kaggle.competitions import nflrush\n",
    "import re\n",
    "from string import punctuation\n",
    "from scipy.spatial import Voronoi\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.spatial import Delaunay\n",
    "env = nflrush.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv',low_memory=False)\n",
    "train.loc[train['Season'] == 2017, 'S'] = (train['S'][train['Season'] == 2017] - 2.4355) / 1.2930 * 1.4551 + 2.7570"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n",
    "train.loc[train.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n",
    "train.loc[train.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n",
    "train.loc[train.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n",
    "\n",
    "train.loc[train.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n",
    "train.loc[train.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"\n",
    "\n",
    "train.loc[train.Season==2017,'Orientation'] = np.mod(train.loc[train.Season==2017,'Orientation'] + 90,360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_features = list(train.columns).copy()\n",
    "# person_feature = []\n",
    "# for i in train.columns:\n",
    "#     if train.loc[train.PlayId ==20170907000118,i].nunique()!=1 and i!='PlayId':\n",
    "#             print(i)\n",
    "#             team_features.remove(i)\n",
    "#             person_feature.append(i)\n",
    "person_feature = ['Team',\n",
    " 'X',\n",
    " 'Y',\n",
    " 'S',\n",
    " 'A',\n",
    " 'Dis',\n",
    " 'Orientation',\n",
    " 'Dir',\n",
    " 'NflId',\n",
    " 'DisplayName',\n",
    " 'JerseyNumber',\n",
    " 'PlayerHeight',\n",
    " 'PlayerWeight',\n",
    " 'PlayerBirthDate',\n",
    " 'PlayerCollegeName',\n",
    " 'Position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ToLeft'] = train.PlayDirection == \"left\"\n",
    "train['X_std'] = train.X\n",
    "train.loc[train.ToLeft, 'X_std'] = 120 - train.loc[train.ToLeft, 'X'] \n",
    "train['X'] = train['X_std'].copy()\n",
    "train['Y_std'] = train.Y\n",
    "train.loc[train.ToLeft, 'Y_std'] = 160/3 - train.loc[train.ToLeft, 'Y'] \n",
    "train['Y'] = train['Y_std'].copy()\n",
    "train['Orientation_std'] = np.mod(train.Orientation-90, 360)\n",
    "train.loc[train.ToLeft, 'Orientation_std'] = np.mod(180 + train.loc[train.ToLeft, 'Orientation_std'].copy(),360)\n",
    "train['Orientation'] = train['Orientation_std'].copy()\n",
    "train['Dir_rad'] = np.mod(train.Dir-90, 360) * np.pi/180.0\n",
    "train['Dir_std'] = train.Dir_rad.copy()\n",
    "train.loc[train.ToLeft, 'Dir_std'] = np.mod(np.pi + train.loc[train.ToLeft, 'Dir_rad'], 2*np.pi)\n",
    "train['Dir'] = train['Dir_std'].copy()\n",
    "person_feature.append('PlayId')\n",
    "person_info = train[person_feature].copy()\n",
    "person_info['player_mark'] = ['player'+ str(i) for i in range(1,12)]*int(person_info.shape[0]/11)\n",
    "te = pd.pivot_table(person_info,columns=['Team','player_mark'],index=['PlayId'],aggfunc=lambda x:x)\n",
    "te.columns = ['_'.join(a) for a in te.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### drop TeamOnoffsen isonoffense\n",
    "train['TeamOnOffense'] = \"home\"\n",
    "train.loc[train.PossessionTeam != train.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "train['IsOnOffense'] = train.Team == train.TeamOnOffense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_run'] = train.NflId == train.NflIdRusher\n",
    "train_single = train[train.is_run==True].copy()\n",
    "train_single['diff_Ori_dir'] = np.abs(train_single.Orientation - train_single.Dir/np.pi*180)\n",
    "temp1 = pd.DataFrame(train_single['diff_Ori_dir'].copy())\n",
    "temp1['c1'] = 360 - temp1.diff_Ori_dir\n",
    "train_single['diff_Ori_dir']= np.min(temp1,axis=1).tolist()\n",
    "def transform_time_quarter(str1):\n",
    "    try:\n",
    "        return int(str1[:2])*60 + int(str1[3:5])\n",
    "    except:\n",
    "        return np.nan\n",
    "def transform_time_all(str1,quarter):\n",
    "    try:\n",
    "        if quarter<=4:\n",
    "            return 15*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "        if quarter ==5:\n",
    "            return 10*60 - (int(str1[:2])*60 + int(str1[3:5])) + (quarter-1)*15*60\n",
    "    except:\n",
    "        return np.nan\n",
    "train_single['time_quarter'] = train_single.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "train_single['time_end'] = train_single.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n",
    "train_single['TimeHandoff'] = train_single['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "train_single['TimeSnap'] = train_single['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "train_single['date_game'] = train_single.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n",
    "train_single['runner_age'] = (train_single.date_game.map(pd.to_datetime) - train_single.PlayerBirthDate.map(pd.to_datetime)).map(lambda x:x.days)/365.25\n",
    "def transform_height(te):\n",
    "    try:\n",
    "        if pd.isna(te):\n",
    "            return np.nan\n",
    "        return (int(te.split('-')[0])*12 + int(te.split('-')[1]))*2.54/100\n",
    "    except:\n",
    "        return np.nan\n",
    "train_single['runner_height'] = train_single.PlayerHeight.map(transform_height)\n",
    "train_single['own_field'] = (train_single['FieldPosition'] == train_single['PossessionTeam']).astype(int)\n",
    "train_single['dist_to_end'] = train_single.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n",
    "def transform_YardLine_x(row):\n",
    "    try:\n",
    "        if row.own_field ==1:\n",
    "            return  row.YardLine + 10\n",
    "        if row.own_field ==0:\n",
    "            return 110 - row.YardLine\n",
    "    except:\n",
    "        return np.nan\n",
    "def transform_dist_to_line(row):\n",
    "    try:\n",
    "        return row.X - row.YardLine_x\n",
    "    except:\n",
    "        return np.nan\n",
    "train_single['YardLine_x'] = train_single.apply(transform_YardLine_x,axis=1)\n",
    "train_single['dist_to_line'] = train_single.apply(transform_dist_to_line,axis=1)\n",
    "train['is_QB'] = train.Position=='QB'\n",
    "qb_number = train.groupby(['PlayId'])['is_QB'].sum()\n",
    "train_single['qb_number'] = train_single.PlayId.map(qb_number)\n",
    "te1 = train.loc[(train.is_run==True)|(train.is_QB==1),['PlayId','X','Y','is_run','is_QB','A','S',\n",
    "                                                       'Dis','Orientation','Dir','PlayerHeight','PlayerWeight','PlayerBirthDate']]\n",
    "te1 = te1.set_index(['PlayId'])\n",
    "run_info = te1[te1.is_run==True].copy()\n",
    "run_info.rename({'X':'run_x','Y':'run_y'},axis=1,inplace=True)\n",
    "qb_info = te1[te1.is_QB==1].copy()\n",
    "qb_info.reset_index(inplace=True)\n",
    "# 要改万一大于2个\n",
    "drop_index=[]\n",
    "for num_index in qb_number.index[qb_number>=2]:\n",
    "    temp = qb_info.loc[qb_info.PlayId==num_index,['X','Y']]\n",
    "    dist_to_close = []\n",
    "    for num in temp.index:\n",
    "        temp_a = np.sqrt(np.sum((temp.loc[num].values - run_info.loc[run_info.index==num_index,['run_x','run_y']].values[0,])**2))\n",
    "        #print(num_index)\n",
    "        dist_to_close.append(temp_a)\n",
    "    drop_index.extend([temp.index.tolist()[i] for i in list(np.argsort(dist_to_close))[1:]])\n",
    "qb_info.drop(drop_index,axis=0,inplace=True)\n",
    "# drop_index=[]\n",
    "# for num_index in qb_number.index[qb_number==2]:\n",
    "#     temp = qb_info.loc[qb_info.PlayId==num_index,['X','Y']]\n",
    "#     dist_to_close = []\n",
    "#     for num in temp.index:\n",
    "#         temp_a = np.sqrt(np.sum((temp.loc[num].values - run_info.loc[run_info.index==num_index,['run_x','run_y']].values[0,])**2))\n",
    "#         #print(num_index)\n",
    "#         dist_to_close.append(temp_a)\n",
    "#     if dist_to_close[0]>dist_to_close[1]:\n",
    "#         drop_index.append(temp.index.tolist()[0])\n",
    "#     else:\n",
    "#         drop_index.append(temp.index.tolist()[1])\n",
    "# qb_info.drop(drop_index,axis=0,inplace=True)\n",
    "train_single.rename({'X':'run_x','Y':'run_y'},axis=1,inplace=True)\n",
    "qb_info.rename({'A':'QB_A','S':'QB_S','Dis':'QB_Dis','Orientation':'QB_Orientation',\n",
    "                'Dir':'QB_dir','PlayerHeight':'QB_PlayerHeight',\n",
    "                'PlayerWeight':'QB_PlayerWeight','PlayerBirthDate':'QB_PlayerBirthDate'},axis=1,inplace=True)\n",
    "train_single = pd.merge(train_single,qb_info[['PlayId','X','Y','QB_A','QB_S','QB_Dis','QB_Orientation',\n",
    "                                             'QB_dir','QB_PlayerHeight','QB_PlayerWeight',\n",
    "                                             'QB_PlayerBirthDate']],on='PlayId',how='left')\n",
    "train_single.rename({'X':'QB_x','Y':'QB_y'},axis=1,inplace=True)\n",
    "def transform_qb_to_line(row):\n",
    "    try:\n",
    "        return row.QB_x- row.YardLine_x\n",
    "    except:\n",
    "        return np.nan\n",
    "train_single['qb_to_line'] = train_single.apply(transform_qb_to_line,axis=1)\n",
    "def transform_run_dist_qb(row):\n",
    "    try:\n",
    "        x_dist = row.QB_x - row.run_x\n",
    "        y_dist = row.QB_y - row.run_y\n",
    "        return np.sqrt(x_dist**2 + y_dist**2)\n",
    "    except:\n",
    "        return np.nan\n",
    "train_single['run_dist_qb'] = train_single.apply(transform_run_dist_qb,axis=1)\n",
    "train_single['QB_PlayerHeight'] = train_single.QB_PlayerHeight.map(transform_height)\n",
    "train_single['QB_age'] = (train_single.date_game.map(pd.to_datetime) - train_single.QB_PlayerBirthDate.map(pd.to_datetime)).map(lambda x:x.days)/365.25\n",
    "\n",
    "train_single['diff_Ori_dir_qb'] = np.abs(train_single.QB_Orientation - train_single.QB_dir/np.pi*180)\n",
    "temp1 = pd.DataFrame(train_single['diff_Ori_dir_qb'].copy())\n",
    "temp1['c1'] = 360 - temp1.diff_Ori_dir_qb\n",
    "train_single['diff_Ori_dir_qb']= np.min(temp1,axis=1).tolist()\n",
    "\n",
    "train_single['diff_qb_runner_dir'] = np.abs(train_single.Dir/np.pi*180 - train_single.QB_dir/np.pi*180)\n",
    "temp1 = pd.DataFrame(train_single['diff_qb_runner_dir'].copy())\n",
    "temp1['c1'] = 360 - temp1.diff_qb_runner_dir\n",
    "train_single['diff_qb_runner_dir']= np.min(temp1,axis=1).tolist()\n",
    "\n",
    "train_single['diff_qb_runner_ori'] = np.abs(train_single.Orientation - train_single.QB_Orientation)\n",
    "temp1 = pd.DataFrame(train_single['diff_qb_runner_ori'].copy())\n",
    "temp1['c1'] = 360 - temp1.diff_qb_runner_ori\n",
    "train_single['diff_qb_runner_ori']= np.min(temp1,axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_single['score_difference'] = train_single.apply(lambda x:\n",
    "                                    x.loc['HomeScoreBeforePlay'] - x.loc['VisitorScoreBeforePlay'] if x.loc['PossessionTeam'] == x.loc['HomeTeamAbbr']\n",
    "                                                      else x.loc['VisitorScoreBeforePlay'] - x.loc['HomeScoreBeforePlay'],axis=1)\n",
    "train_single['offense_score'] = train_single.apply(lambda x:\n",
    "                                    x.loc['HomeScoreBeforePlay']  if x.loc['PossessionTeam'] == x.loc['HomeTeamAbbr']\n",
    "                                                      else x.loc['VisitorScoreBeforePlay'] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_features = ['GameId','PlayId','DisplayName','GameClock','TimeHandoff','TimeSnap','TeamOnOffense','IsOnOffense']\n",
    "remove_features.append('HomeTeamAbbr')\n",
    "remove_features.append('VisitorTeamAbbr')\n",
    "remove_features.append('PlayerBirthDate')\n",
    "remove_features.append('is_run')\n",
    "remove_features.append('PossessionTeam')\n",
    "remove_features.append('FieldPosition')\n",
    "remove_features.append('PlayerHeight')\n",
    "remove_features.append('NflIdRusher')\n",
    "remove_features.append('date_game')\n",
    "remove_features.append('YardLine_x')\n",
    "remove_features.append('QB_x')\n",
    "remove_features.append('QB_PlayerBirthDate')\n",
    "remove_features.extend(te.columns.tolist())\n",
    "remove_features.append('Turf')\n",
    "remove_features.extend(['QB_A','QB_Dis','QB_Orientation','QB_PlayerHeight','QB_PlayerWeight','QB_age'])\n",
    "remove_features.extend(['YardLine','X_std','Y_std','ToLeft','Dir_rad','Dir_std','Orientation_std'])\n",
    "remove_features.extend(['HomeScoreBeforePlay','VisitorScoreBeforePlay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single = pd.merge(train_single,te,on='PlayId',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "def dist1_divide_S(row):\n",
    "    try:\n",
    "        dist_list_def = []\n",
    "        S_list_def = []\n",
    "        Dir_list_def = []\n",
    "        X_list_def  = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'away'\n",
    "        else:\n",
    "            team_def = 'home'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            if row[x_str] < row.run_x:\n",
    "                continue\n",
    "            dist1 = np.sqrt((row[x_str] - row.run_x)**2 + (row[y_str] - row.run_y)**2)\n",
    "            dist_list_def.append(dist1)\n",
    "            X_list_def.append(row['X_'+team_def+'_player'+str(i)])\n",
    "            Dir_list_def.append(row['Dir_'+team_def+'_player'+str(i)])\n",
    "            S_list_def.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            S_max = np.array(S_list_def)[np.argsort(dist_list_def)][0]\n",
    "            Dir_max = np.array(Dir_list_def)[np.argsort(dist_list_def)][0]\n",
    "            X_max = np.array(X_list_def)[np.argsort(dist_list_def)][0]\n",
    "            S_hor_def  = np.abs(S_max * np.cos(Dir_max))\n",
    "        if sorted(dist_list_def)[0]/S_max == np.inf:\n",
    "            return 999\n",
    "        return np.clip(sorted(dist_list_def)[0]/S_max,0,999)\n",
    "    except:\n",
    "        return np.nan\n",
    "train_single['dist1_divide_S'] = train_single.apply(dist1_divide_S,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "def dist1_divide_S_hor(row):\n",
    "    try:\n",
    "        dist_list_def = []\n",
    "        S_list_def = []\n",
    "        Dir_list_def = []\n",
    "        X_list_def  = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'away'\n",
    "        else:\n",
    "            team_def = 'home'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            if row[x_str] < row.run_x:\n",
    "                continue\n",
    "            dist1 = np.sqrt((row[x_str] - row.run_x)**2 + (row[y_str] - row.run_y)**2)\n",
    "            dist_list_def.append(dist1)\n",
    "            X_list_def.append(row['X_'+team_def+'_player'+str(i)])\n",
    "            Dir_list_def.append(row['Dir_'+team_def+'_player'+str(i)])\n",
    "            S_list_def.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            S_max = np.array(S_list_def)[np.argsort(dist_list_def)][0]\n",
    "            Dir_max = np.array(Dir_list_def)[np.argsort(dist_list_def)][0]\n",
    "            X_max = np.array(X_list_def)[np.argsort(dist_list_def)][0]\n",
    "            S_hor_def  = np.abs(S_max * np.cos(Dir_max))\n",
    "            temp = (X_max - row.run_x)/S_hor_def\n",
    "        if temp == np.inf:\n",
    "            return 999\n",
    "        return np.clip(temp,0,999)\n",
    "    except:\n",
    "        return np.nan\n",
    "train_single['dist1_divide_S_hor'] = train_single.apply(dist1_divide_S_hor,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "def time1_dist_S(row):\n",
    "    try:\n",
    "        dist_list_def = []\n",
    "        S_list_def = []\n",
    "        Dir_list_def = []\n",
    "        X_list_def  = []\n",
    "        time_list_def = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'away'\n",
    "        else:\n",
    "            team_def = 'home'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            if row[x_str] < row.run_x:\n",
    "                continue\n",
    "            dist1 = np.sqrt((row[x_str] - row.run_x)**2 + (row[y_str] - row.run_y)**2)\n",
    "            dist_list_def.append(dist1)\n",
    "            time_list_def.append(dist1/row['S_'+team_def+'_player'+str(i)])\n",
    "        return np.clip(sorted(time_list_def)[0],0,999)\n",
    "    except:\n",
    "        return np.nan\n",
    "train_single['time1_dist_S'] = train_single.apply(time1_dist_S,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "def time1_dist_S_hor(row):\n",
    "    try:\n",
    "        dist_list_def = []\n",
    "        S_list_def = []\n",
    "        Dir_list_def = []\n",
    "        X_list_def  = []\n",
    "        time_list_def = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'away'\n",
    "        else:\n",
    "            team_def = 'home'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            if row[x_str] < row.run_x:\n",
    "                continue\n",
    "            dist1 = np.sqrt((row[x_str] - row.run_x)**2 + (row[y_str] - row.run_y)**2)\n",
    "            time_list_def.append((row[x_str] - row.run_x)/np.abs(row['S_'+team_def+'_player'+str(i)] * np.cos(row['Dir_'+team_def+'_player'+str(i)])))\n",
    "        return np.clip(sorted(time_list_def)[0],0,999)\n",
    "    except:\n",
    "        return np.nan\n",
    "train_single['time1_dist_S_hor'] = train_single.apply(time1_dist_S_hor,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_close_who(row):\n",
    "    try:\n",
    "        dist_list_off = []\n",
    "        if row.Team == 'home':\n",
    "            team_off = 'home'\n",
    "        else:\n",
    "            team_off = 'away'\n",
    "        for i in range(1,12):\n",
    "            if row['Position_'+team_off+'_player'+str(i)] =='QB':\n",
    "                continue\n",
    "            if row['X_'+team_off+'_player'+str(i)]<row.run_x:\n",
    "                continue\n",
    "            x_str = 'X_'+team_off+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_off+'_player'+str(i)\n",
    "            dist1 = np.sqrt((row[x_str] - row.run_x)**2 + (row[y_str] - row.run_y)**2)\n",
    "            dist_list_off.append(dist1)\n",
    "\n",
    "        dist_list_def = []\n",
    "        S_list_def = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'away'\n",
    "        else:\n",
    "            team_def = 'home'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            if row[x_str] < row.run_x:\n",
    "                continue\n",
    "            dist1 = np.sqrt((row[x_str] - row.run_x)**2 + (row[y_str] - row.run_y)**2)\n",
    "            dist_list_def.append(dist1)\n",
    "            S_list_def.append(row['S_'+team_def+'_player'+str(i)])\n",
    "        dist_list_off = list(filter(lambda x: x!=0,dist_list_off))\n",
    "    #    return dist_list_def,list(filter(lambda x: x!=0,dist_list_off))\n",
    "        if len(dist_list_def) ==0 or len(dist_list_off)==0:\n",
    "            return np.nan\n",
    "        if np.min(dist_list_def) <= np.min(dist_list_off):\n",
    "            return (np.array(S_list_def)[np.argsort(dist_list_def)][0])/row.S\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single['close_who_S_ratio']= train_single.apply(transform_close_who,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dist_close123_defender_runner(row):\n",
    "    try:\n",
    "        ###return the attributes of 3 closest defender\n",
    "        dist_list = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'away'\n",
    "        else:\n",
    "            team_def = 'home'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            dist1 = np.sqrt((row[x_str] - row.run_x)**2 + (row[y_str] - row.run_y)**2)\n",
    "            dist_list.append(dist1)\n",
    "        first_close = sorted(dist_list)[0]\n",
    "        min1_num = dist_list.index(first_close)+1\n",
    "        A_min1_dist = row['A_'+team_def+'_player'+str(min1_num)]\n",
    "        S_min1_dist = row['S_'+team_def+'_player'+str(min1_num)]\n",
    "\n",
    "        first2_close = sorted(dist_list)[1]\n",
    "        min2_num = dist_list.index(first2_close)+1\n",
    "        A_min2_dist = row['A_'+team_def+'_player'+str(min2_num)]\n",
    "        S_min2_dist = row['S_'+team_def+'_player'+str(min2_num)]\n",
    "\n",
    "        first3_close = sorted(dist_list)[2]\n",
    "        min3_num = dist_list.index(first3_close)+1\n",
    "        A_min3_dist = row['A_'+team_def+'_player'+str(min3_num)]\n",
    "        S_min3_dist = row['S_'+team_def+'_player'+str(min3_num)]\n",
    "\n",
    "        first4_close = sorted(dist_list)[3]\n",
    "        min4_num = dist_list.index(first4_close)+1\n",
    "        A_min4_dist = row['A_'+team_def+'_player'+str(min4_num)]\n",
    "        S_min4_dist = row['S_'+team_def+'_player'+str(min4_num)]\n",
    "\n",
    "        first5_close = sorted(dist_list)[4]\n",
    "        min5_num = dist_list.index(first5_close)+1\n",
    "        A_min5_dist = row['A_'+team_def+'_player'+str(min5_num)]\n",
    "        S_min5_dist = row['S_'+team_def+'_player'+str(min5_num)]\n",
    "\n",
    "        return first_close,A_min1_dist,S_min1_dist,first2_close,A_min2_dist,S_min2_dist,first3_close,A_min3_dist,S_min3_dist,first4_close,A_min4_dist,S_min4_dist,first5_close,A_min5_dist,S_min5_dist\n",
    "    except:\n",
    "        return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "def transform_dist_close123_offense_runner(row):\n",
    "    try:\n",
    "        dist_list = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'home'\n",
    "        else:\n",
    "            team_def = 'away'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            dist1 = np.sqrt((row[x_str] - row.run_x)**2 + (row[y_str] - row.run_y)**2)\n",
    "            dist_list.append(dist1)\n",
    "        first_close = sorted(dist_list)[1]\n",
    "        min1_num = dist_list.index(first_close)+1\n",
    "        A_min1_dist = row['A_'+team_def+'_player'+str(min1_num)]\n",
    "        S_min1_dist = row['S_'+team_def+'_player'+str(min1_num)]\n",
    "\n",
    "        first2_close = sorted(dist_list)[2]\n",
    "        min2_num = dist_list.index(first2_close)+1\n",
    "        A_min2_dist = row['A_'+team_def+'_player'+str(min2_num)]\n",
    "        S_min2_dist = row['S_'+team_def+'_player'+str(min2_num)]\n",
    "\n",
    "        first3_close = sorted(dist_list)[3]\n",
    "        min3_num = dist_list.index(first3_close)+1\n",
    "        A_min3_dist = row['A_'+team_def+'_player'+str(min3_num)]\n",
    "        S_min3_dist = row['S_'+team_def+'_player'+str(min3_num)]\n",
    "\n",
    "        first4_close = sorted(dist_list)[4]\n",
    "        min4_num = dist_list.index(first4_close)+1\n",
    "        A_min4_dist = row['A_'+team_def+'_player'+str(min4_num)]\n",
    "        S_min4_dist = row['S_'+team_def+'_player'+str(min4_num)]\n",
    "\n",
    "        first5_close = sorted(dist_list)[5]\n",
    "        min5_num = dist_list.index(first5_close)+1\n",
    "        A_min5_dist = row['A_'+team_def+'_player'+str(min5_num)]\n",
    "        S_min5_dist = row['S_'+team_def+'_player'+str(min5_num)]\n",
    "\n",
    "        return first_close,A_min1_dist,S_min1_dist,first2_close,A_min2_dist,S_min2_dist,first3_close,A_min3_dist,S_min3_dist,first4_close,A_min4_dist,S_min4_dist,first5_close,A_min5_dist,S_min5_dist\n",
    "    except:\n",
    "        return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1  = train_single.apply(transform_dist_close123_offense_runner,axis=1)\n",
    "names = ['dist_1_off','A_1_off','S_1_off','dist_2_off','A_2_off','S_2_off','dist_3_off','A_3_off','S_3_off',\n",
    "        'dist_4_off','A_4_off','S_4_off','dist_5_off','A_5_off','S_5_off']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "temp1  = train_single.apply(transform_dist_close123_defender_runner,axis=1)\n",
    "names = ['dist_1_def','A_1_def','S_1_def','dist_2_def','A_2_def','S_2_def','dist_3_def','A_3_def','S_3_def',\n",
    "        'dist_4_def','A_4_def','S_4_def','dist_5_def','A_5_def','S_5_def']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "for i in [1]:\n",
    "    train_single['dist_'+str(i)+'_S_ratio'] = train_single['S_'+str(i)+'_def'] / train_single.S\n",
    "    train_single['dist_'+str(i)+'_S_ratio'] = np.where(np.isinf(train_single['dist_'+str(i)+'_S_ratio']),999,train_single['dist_'+str(i)+'_S_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dist_close123_defender_QB(row):\n",
    "    try:\n",
    "        if pd.isna(row.QB_x):\n",
    "            return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "        dist_list = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'away'\n",
    "        else:\n",
    "            team_def = 'home'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            dist1 = np.sqrt((row[x_str] - row.QB_x)**2 + (row[y_str] - row.QB_y)**2)\n",
    "            dist_list.append(dist1)\n",
    "        first_close = sorted(dist_list)[0]\n",
    "        min1_num = dist_list.index(first_close)+1\n",
    "        A_min1_dist = row['A_'+team_def+'_player'+str(min1_num)]\n",
    "        S_min1_dist = row['S_'+team_def+'_player'+str(min1_num)]\n",
    "\n",
    "        first2_close = sorted(dist_list)[1]\n",
    "        min2_num = dist_list.index(first2_close)+1\n",
    "        A_min2_dist = row['A_'+team_def+'_player'+str(min2_num)]\n",
    "        S_min2_dist = row['S_'+team_def+'_player'+str(min2_num)]\n",
    "\n",
    "        first3_close = sorted(dist_list)[2]\n",
    "        min3_num = dist_list.index(first3_close)+1\n",
    "        A_min3_dist = row['A_'+team_def+'_player'+str(min3_num)]\n",
    "        S_min3_dist = row['S_'+team_def+'_player'+str(min3_num)]\n",
    "\n",
    "        first4_close = sorted(dist_list)[3]\n",
    "        min4_num = dist_list.index(first4_close)+1\n",
    "        A_min4_dist = row['A_'+team_def+'_player'+str(min4_num)]\n",
    "        S_min4_dist = row['S_'+team_def+'_player'+str(min4_num)]\n",
    "\n",
    "        first5_close = sorted(dist_list)[4]\n",
    "        min5_num = dist_list.index(first5_close)+1\n",
    "        A_min5_dist = row['A_'+team_def+'_player'+str(min5_num)]\n",
    "        S_min5_dist = row['S_'+team_def+'_player'+str(min5_num)]\n",
    "\n",
    "        return first_close,A_min1_dist,S_min1_dist,first2_close,A_min2_dist,S_min2_dist,first3_close,A_min3_dist,S_min3_dist,first4_close,A_min4_dist,S_min4_dist,first5_close,A_min5_dist,S_min5_dist\n",
    "    except:\n",
    "        return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "\n",
    "def transform_dist_close123_offense_QB(row):\n",
    "    try:\n",
    "        if pd.isna(row.QB_x):\n",
    "            return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "        dist_list = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'home'\n",
    "        else:\n",
    "            team_def = 'away'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            dist1 = np.sqrt((row[x_str] - row.QB_x)**2 + (row[y_str] - row.QB_y)**2)\n",
    "            dist_list.append(dist1)\n",
    "        first_close = sorted(dist_list)[1]\n",
    "        min1_num = dist_list.index(first_close)+1\n",
    "        A_min1_dist = row['A_'+team_def+'_player'+str(min1_num)]\n",
    "        S_min1_dist = row['S_'+team_def+'_player'+str(min1_num)]\n",
    "\n",
    "        first2_close = sorted(dist_list)[2]\n",
    "        min2_num = dist_list.index(first2_close)+1\n",
    "        A_min2_dist = row['A_'+team_def+'_player'+str(min2_num)]\n",
    "        S_min2_dist = row['S_'+team_def+'_player'+str(min2_num)]\n",
    "\n",
    "        first3_close = sorted(dist_list)[3]\n",
    "        min3_num = dist_list.index(first3_close)+1\n",
    "        A_min3_dist = row['A_'+team_def+'_player'+str(min3_num)]\n",
    "        S_min3_dist = row['S_'+team_def+'_player'+str(min3_num)]\n",
    "\n",
    "        first4_close = sorted(dist_list)[4]\n",
    "        min4_num = dist_list.index(first4_close)+1\n",
    "        A_min4_dist = row['A_'+team_def+'_player'+str(min4_num)]\n",
    "        S_min4_dist = row['S_'+team_def+'_player'+str(min4_num)]\n",
    "\n",
    "        first5_close = sorted(dist_list)[5]\n",
    "        min5_num = dist_list.index(first5_close)+1\n",
    "        A_min5_dist = row['A_'+team_def+'_player'+str(min5_num)]\n",
    "        S_min5_dist = row['S_'+team_def+'_player'+str(min5_num)]\n",
    "        return first_close,A_min1_dist,S_min1_dist,first2_close,A_min2_dist,S_min2_dist,first3_close,A_min3_dist,S_min3_dist,first4_close,A_min4_dist,S_min4_dist,first5_close,A_min5_dist,S_min5_dist\n",
    "    except:\n",
    "        return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1  = train_single.apply(transform_dist_close123_offense_QB,axis=1)\n",
    "names = ['dist_1_off_qb','A_1_off_qb','S_1_off_qb','dist_2_off_qb','A_2_off_qb','S_2_off_qb','dist_3_off_qb','A_3_off_qb','S_3_off_qb',\n",
    "        'dist_4_off_qb','A_4_off_qb','S_4_off_qb','dist_5_off_qb','A_5_off_qb','S_5_off_qb']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "temp1  = train_single.apply(transform_dist_close123_defender_QB,axis=1)\n",
    "names = ['dist_1_def_qb','A_1_def_qb','S_1_def_qb','dist_2_def_qb','A_2_def_qb','S_2_def_qb','dist_3_def_qb','A_3_def_qb','S_3_def_qb',\n",
    "        'dist_4_def_qb','A_4_def_qb','S_4_def_qb','dist_5_def_qb','A_5_def_qb','S_5_def_qb']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = temp1.map(lambda x:x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dist2_num_defender(row):\n",
    "    try:\n",
    "        #### 5/10\n",
    "        dist_dict = {}\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'away'\n",
    "        else:\n",
    "            team_def = 'home'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            dist1 = np.sqrt((row[x_str] - row.run_x)**2 + (row[y_str] - row.run_y)**2)\n",
    "            dist_dict[i] = dist1\n",
    "\n",
    "        want_list5 = []\n",
    "        for a,b in dist_dict.items():\n",
    "            if b<=5:\n",
    "                want_list5.append(a)\n",
    "        num5 = len(want_list5)\n",
    "        speed_list5 = []\n",
    "        A_list5 = []\n",
    "        for i in want_list5:\n",
    "            speed_list5.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            A_list5.append(row['A_'+team_def+'_player'+str(i)])\n",
    "        want_list10 = []\n",
    "        for a,b in dist_dict.items():\n",
    "            if b<=10:\n",
    "                want_list10.append(a)\n",
    "        num10 = len(want_list10)\n",
    "        speed_list10 = []\n",
    "        A_list10 = []\n",
    "        for i in want_list10:\n",
    "            speed_list10.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            A_list10.append(row['A_'+team_def+'_player'+str(i)])\n",
    "        return num5,np.mean(speed_list5),np.mean(A_list5),num10,np.mean(speed_list10),np.mean(A_list10)\n",
    "    except:\n",
    "        return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "    \n",
    "def transform_dist2_num_offense(row):\n",
    "    try:\n",
    "        dist_dict = {}\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'home'\n",
    "        else:\n",
    "            team_def = 'away'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            dist1 = np.sqrt((row[x_str] - row.run_x)**2 + (row[y_str] - row.run_y)**2)\n",
    "            dist_dict[i] = dist1\n",
    "\n",
    "        want_list5 = []\n",
    "        for a,b in dist_dict.items():\n",
    "            if b<=2:\n",
    "                want_list5.append(a)\n",
    "        num5 = len(want_list5)\n",
    "        speed_list5 = []\n",
    "        A_list5 = []\n",
    "        for i in want_list5:\n",
    "            speed_list5.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            A_list5.append(row['A_'+team_def+'_player'+str(i)])\n",
    "        want_list10 = []\n",
    "        for a,b in dist_dict.items():\n",
    "            if b<=5:\n",
    "                want_list10.append(a)\n",
    "        num10 = len(want_list10)\n",
    "        speed_list10 = []\n",
    "        A_list10 = []\n",
    "        for i in want_list10:\n",
    "            speed_list10.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            A_list10.append(row['A_'+team_def+'_player'+str(i)])\n",
    "        want_list15 = []\n",
    "        for a,b in dist_dict.items():\n",
    "            if b<=10:\n",
    "                want_list15.append(a)\n",
    "        num15 = len(want_list15)\n",
    "        speed_list15 = []\n",
    "        A_list15 = []\n",
    "        for i in want_list15:\n",
    "            speed_list15.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            A_list15.append(row['A_'+team_def+'_player'+str(i)])\n",
    "        return num5,np.mean(speed_list5),np.mean(A_list5),num10,np.mean(speed_list10),np.mean(A_list10),num15,np.mean(speed_list15),np.mean(A_list15)\n",
    "    except:\n",
    "        return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "temp1  = train_single.apply(transform_dist2_num_defender,axis=1)\n",
    "names = ['num_dist5_def','S_5_def_mean','A_5_def_mean','num_dist10_def','S_10_def_mean','A_10_def_mean']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "temp1  = train_single.apply(transform_dist2_num_offense,axis=1)\n",
    "names = ['num_dist2_off','S_2_off_mean','A_2_off_mean','num_dist5_off','S_5_off_mean','A_5_off_mean','num_dist10_off','S_10_off_mean','A_10_off_mean']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = temp1.map(lambda x:x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dist2_num_defender_QB(row):\n",
    "    try:\n",
    "        if pd.isna(row.QB_x):\n",
    "            return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "        #### 5/10\n",
    "        dist_dict = {}\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'away'\n",
    "        else:\n",
    "            team_def = 'home'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            dist1 = np.sqrt((row[x_str] - row.QB_x)**2 + (row[y_str] - row.QB_y)**2)\n",
    "            dist_dict[i] = dist1\n",
    "\n",
    "        want_list5 = []\n",
    "        for a,b in dist_dict.items():\n",
    "            if b<=5:\n",
    "                want_list5.append(a)\n",
    "        num5 = len(want_list5)\n",
    "        speed_list5 = []\n",
    "        A_list5 = []\n",
    "        for i in want_list5:\n",
    "            speed_list5.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            A_list5.append(row['A_'+team_def+'_player'+str(i)])\n",
    "        want_list10 = []\n",
    "        for a,b in dist_dict.items():\n",
    "            if b<=10:\n",
    "                want_list10.append(a)\n",
    "        num10 = len(want_list10)\n",
    "        speed_list10 = []\n",
    "        A_list10 = []\n",
    "        for i in want_list10:\n",
    "            speed_list10.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            A_list10.append(row['A_'+team_def+'_player'+str(i)])\n",
    "        return num5,np.mean(speed_list5),np.mean(A_list5),num10,np.mean(speed_list10),np.mean(A_list10)\n",
    "    except:\n",
    "        return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "        \n",
    "    \n",
    "def transform_dist2_num_offense_QB(row):\n",
    "    try:\n",
    "        if pd.isna(row.QB_x):\n",
    "            return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "        ### 2/5\n",
    "        dist_dict = {}\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'home'\n",
    "        else:\n",
    "            team_def = 'away'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            dist1 = np.sqrt((row[x_str] - row.QB_x)**2 + (row[y_str] - row.QB_y)**2)\n",
    "            dist_dict[i] = dist1\n",
    "\n",
    "        want_list5 = []\n",
    "        for a,b in dist_dict.items():\n",
    "            if b<=2:\n",
    "                want_list5.append(a)\n",
    "        num5 = len(want_list5)\n",
    "        speed_list5 = []\n",
    "        A_list5 = []\n",
    "        for i in want_list5:\n",
    "            speed_list5.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            A_list5.append(row['A_'+team_def+'_player'+str(i)])\n",
    "        want_list10 = []\n",
    "        for a,b in dist_dict.items():\n",
    "            if b<=5:\n",
    "                want_list10.append(a)\n",
    "        num10 = len(want_list10)\n",
    "        speed_list10 = []\n",
    "        A_list10 = []\n",
    "        for i in want_list10:\n",
    "            speed_list10.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            A_list10.append(row['A_'+team_def+'_player'+str(i)])\n",
    "        want_list15 = []\n",
    "        for a,b in dist_dict.items():\n",
    "            if b<=10:\n",
    "                want_list15.append(a)\n",
    "        num15 = len(want_list15)\n",
    "        speed_list15 = []\n",
    "        A_list15 = []\n",
    "        for i in want_list15:\n",
    "            speed_list15.append(row['S_'+team_def+'_player'+str(i)])\n",
    "            A_list15.append(row['A_'+team_def+'_player'+str(i)])\n",
    "        return num5,np.mean(speed_list5),np.mean(A_list5),num10,np.mean(speed_list10),np.mean(A_list10),num15,np.mean(speed_list15),np.mean(A_list15)\n",
    "    except:\n",
    "        return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1  = train_single.apply(transform_dist2_num_defender_QB,axis=1)\n",
    "names = ['num_dist5_def_QB','S_5_def_QB_mean','A_5_def_QB_mean','num_dist10_def_QB','S_10_def_QB_mean','A_10_def_QB_mean']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "temp1  = train_single.apply(transform_dist2_num_offense_QB,axis=1)\n",
    "names = ['num_dist2_off_QB','S_2_off_QB_mean','A_2_off_QB_mean','num_dist5_off_QB','S_5_off_QB_mean','A_5_off_QB_mean','num_dist10_off_QB','S_10_off_QB_mean','A_10_off_QB_mean']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = temp1.map(lambda x:x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### std of offense defense and all on x y\n",
    "def transform_defend_X_Y_std(row):\n",
    "    try:\n",
    "        def_X = []\n",
    "        def_Y = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'away'\n",
    "        else:\n",
    "            team_def = 'home'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            def_X.append(row[x_str])\n",
    "            def_Y.append(row[y_str])\n",
    "        return np.std(def_X),np.std(def_Y)\n",
    "    except:\n",
    "        return np.nan,np.nan\n",
    "\n",
    "def transform_offense_X_Y_std(row):\n",
    "    try:\n",
    "        def_X = []\n",
    "        def_Y = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'home'\n",
    "        else:\n",
    "            team_def = 'away'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            def_X.append(row[x_str])\n",
    "            def_Y.append(row[y_str])\n",
    "        return np.std(def_X),np.std(def_Y)\n",
    "    except:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "def transform_all_X_Y_std(row):\n",
    "    try:\n",
    "        def_X = []\n",
    "        def_Y = []\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'home'\n",
    "        else:\n",
    "            team_def = 'away'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            def_X.append(row[x_str])\n",
    "            def_Y.append(row[y_str])\n",
    "\n",
    "        if row.Team == 'home':\n",
    "            team_def = 'away'\n",
    "        else:\n",
    "            team_def = 'home'\n",
    "        for i in range(1,12):\n",
    "            x_str = 'X_'+team_def+'_player'+str(i)\n",
    "            y_str = 'Y_'+team_def+'_player'+str(i)\n",
    "            def_X.append(row[x_str])\n",
    "            def_Y.append(row[y_str])\n",
    "        return np.std(def_X),np.std(def_Y)\n",
    "    except:\n",
    "        return np.nan, np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1  = train_single.apply(transform_defend_X_Y_std,axis=1)\n",
    "names = ['std_def_X','std_def_Y']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "temp1  = train_single.apply(transform_offense_X_Y_std,axis=1)\n",
    "names = ['std_off_X','std_off_Y']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "    \n",
    "temp1  = train_single.apply(transform_all_X_Y_std,axis=1)\n",
    "names = ['std_all_X','std_all_Y']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = temp1.map(lambda x:x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OffensePersonnelSplit(x):\n",
    "    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n",
    "    for xx in x.split(\",\"):\n",
    "        xxs = xx.split(\" \")\n",
    "        if xxs[-1] in dic:\n",
    "            dic[xxs[-1]] = int(xxs[-2])\n",
    "    return dic\n",
    "\n",
    "def DefensePersonnelSplit(x):\n",
    "    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n",
    "    for xx in x.split(\",\"):\n",
    "        xxs = xx.split(\" \")\n",
    "        if xxs[-1] in dic:\n",
    "            dic[xxs[-1]] = int(xxs[-2])\n",
    "    return dic\n",
    "temp1 = train_single.OffensePersonnel.apply(lambda x: pd.Series(OffensePersonnelSplit(x)))\n",
    "names = ['DB','DL','LB','OL','QB','RB','TE','WR']\n",
    "for i in range(len(names)):\n",
    "    train_single['off_num_' + names[i]] = temp1.apply(lambda x:x[names[i]],axis=1)\n",
    "    \n",
    "temp1 = train_single.DefensePersonnel.apply(lambda x: pd.Series(DefensePersonnelSplit(x)))\n",
    "names = ['DB','DL','LB','OL']\n",
    "for i in range(len(names)):\n",
    "    train_single['Def_num_' + names[i]] = temp1.apply(lambda x:x[names[i]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single['S_horizontal'] = np.cos(train_single.Dir) * train_single.S\n",
    "train_single['S_vertical'] = np.abs(np.sin(train_single.Dir) * train_single.S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:69: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:71: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "def is_in_poly(polygon,array):\n",
    "    try:\n",
    "        k = 0\n",
    "        temp = Delaunay(polygon)\n",
    "        for i in range(array.shape[0]):\n",
    "            if temp.find_simplex(array[i,:]) >=0:\n",
    "                k+=1\n",
    "        return k\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def calculate_voroni(row):\n",
    "    try:\n",
    "        df=train[train.PlayId==row.PlayId]\n",
    "        df_offense = df[(df.NflIdRusher != df.NflId)&(df.IsOnOffense)].copy()\n",
    "        pp = df_offense[['X_std','Y_std']].values.copy()\n",
    "        df = df[(df.NflIdRusher == df.NflId) | ~df.IsOnOffense] \n",
    "        xy = df[['X_std', 'Y_std']].values\n",
    "        n_points = xy.shape[0]\n",
    "        xy1 = xy.copy()\n",
    "        xy1[:,1] = - xy[:,1]\n",
    "        xy2 = xy.copy()\n",
    "        xy2[:,1] = 320/3 - xy[:,1]\n",
    "        xy3 = xy.copy()\n",
    "        xy3[:,0] =  - xy[:,0]\n",
    "        xy4 = xy.copy()\n",
    "        xy4[:,0] = 240 - xy[:,0]\n",
    "        xy = np.concatenate((xy, xy1, xy2, xy3, xy4), axis=0)\n",
    "        offense = df.IsOnOffense.values\n",
    "        vor = Voronoi(xy)\n",
    "        num_adj = []\n",
    "        adj_vertice = []\n",
    "        X_temp = []\n",
    "        Y_temp = []\n",
    "        S_temp = []\n",
    "        Dir_temp = []\n",
    "        for r in range(n_points):\n",
    "            if offense[r]:\n",
    "                rusher_num = r\n",
    "                rusher_region_points = vor.regions[vor.point_region[r]]\n",
    "        for r in range(n_points):\n",
    "            region = vor.regions[vor.point_region[r]]\n",
    "            if not -1 in region:\n",
    "                polygon = [vor.vertices[i] for i in region]\n",
    "                if offense[r]:\n",
    "                    temp_area = ConvexHull(polygon)\n",
    "                    voroni_area = temp_area.volume\n",
    "                    x_max = np.max(np.array(polygon)[:,0])\n",
    "                    x_min = np.min(np.array(polygon)[:,0])\n",
    "                else:\n",
    "                    if len(set(rusher_region_points).intersection(set(region)))>=1:\n",
    "                        num_adj.append(r)\n",
    "                        adj_vertice.append(polygon)\n",
    "        X_temp = df.X_std.values.copy()[num_adj]\n",
    "        X_Y_temp = df[['X_std','Y_std']].values.copy()[num_adj,:]\n",
    "        S_temp = df.S.values.copy()[num_adj]\n",
    "        Dir_temp = df.Dir.values.copy()[num_adj]\n",
    "        num_in_adj_cell = [is_in_poly(np.array(poly),pp) for poly in adj_vertice]\n",
    "        num_0_cell = len(list(filter(lambda x:x==0,num_in_adj_cell)))\n",
    "        sum_num_adj_cell = np.sum(num_in_adj_cell)\n",
    "\n",
    "        if num_0_cell==0:\n",
    "            dist1 = np.nan\n",
    "            S_ratio = np.nan\n",
    "            time1 = np.nan\n",
    "            time1_h = np.nan\n",
    "        else:\n",
    "            #dist1 = np.min(np.sqrt(np.sum((X_Y_temp[list(np.array(num_in_adj_cell)==0),:] - np.array([row.run_x,row.run_y]))**2,axis=1)))\n",
    "            S_ratio = np.clip(np.max(S_temp[list(np.array(num_in_adj_cell)==0)]/row.S),0,300)\n",
    "            #time1 = np.clip(np.min(np.sqrt(np.sum((X_Y_temp[list(np.array(num_in_adj_cell)==0),:] - np.array([row.run_x,row.run_y]))**2,axis=1))/S_temp[list(np.array(num_in_adj_cell)==0)]),0,500)\n",
    "            time1_h = np.clip(np.min(np.abs(X_temp[list(np.array(num_in_adj_cell)==0)] - row.run_x)/np.abs(S_temp[list(np.array(num_in_adj_cell)==0)]*np.cos(Dir_temp[list(np.array(num_in_adj_cell)==0)]))),0,500)\n",
    "        return voroni_area,110- x_max,x_max-row.run_x, x_max - row.YardLine_x,len(adj_vertice),sum_num_adj_cell,num_0_cell,S_ratio,time1_h\n",
    "    except:\n",
    "        return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "\n",
    "\n",
    "te = train_single.apply(calculate_voroni,axis=1)\n",
    "names = ['voroni_area','voroni_bc_close','voroni_bc_x_max_minus_x','voroni_max_yardline','adj_cell_num','adj_off_num','adj_def_num_no_offense','voro0_S_ratio_max','voro0_time_min_h']\n",
    "for i in range(len(names)):\n",
    "    train_single[names[i]] = te.map(lambda x:x[i])\n",
    "train_single['voro_diff_num'] = train_single['adj_cell_num'] - train_single['adj_off_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###注意下在test的情况\n",
    "train_single['mean_player_100'] = 0\n",
    "train_single['std_player_100'] = 0\n",
    "train_single['min_player_100'] = 0\n",
    "train_single['quan25_player_100'] = 0\n",
    "train_single['quan75_player_100'] = 0\n",
    "for player in list(train_single.NflId.unique()):\n",
    "\n",
    "    temp = train_single.loc[train_single.NflId==player,'Yards']\n",
    "    mean1 = temp.shift(1).rolling(100,min_periods=20).mean()\n",
    "    std1 = temp.shift(1).rolling(100,min_periods=20).std()\n",
    "    min1 = temp.shift(1).rolling(100,min_periods=20).min()\n",
    "    quan25 = temp.shift(1).rolling(100,min_periods=20).quantile(0.10)\n",
    "    quan75 = temp.shift(1).rolling(100,min_periods=20).quantile(0.90)\n",
    "    train_single.loc[mean1.index,'mean_player_100'] = mean1\n",
    "    train_single.loc[mean1.index,'std_player_100'] = std1\n",
    "    train_single.loc[mean1.index,'min_player_100'] = min1\n",
    "    train_single.loc[mean1.index,'quan25_player_100'] = quan25\n",
    "    train_single.loc[mean1.index,'quan75_player_100'] = quan75\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_single['DefendersInTheBox_vs_Distance'] = train_single['DefendersInTheBox'] / train_single['Distance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_WindDirection(txt):\n",
    "    try:\n",
    "        if pd.isna(txt):\n",
    "            return np.nan\n",
    "        txt = txt.lower()\n",
    "        txt = ''.join([c for c in txt if c not in punctuation])\n",
    "        txt = txt.replace('from', '')\n",
    "        txt = txt.replace(' ', '')\n",
    "        txt = txt.replace('north', 'n')\n",
    "        txt = txt.replace('south', 's')\n",
    "        txt = txt.replace('west', 'w')\n",
    "        txt = txt.replace('east', 'e')\n",
    "        return txt\n",
    "    except:\n",
    "        return np.nan\n",
    "train_single['WindDirection'] = train_single['WindDirection'].apply(clean_WindDirection)\n",
    "def transform_WindDirection(txt):\n",
    "    try:\n",
    "        if pd.isna(txt):\n",
    "            return np.nan\n",
    "\n",
    "        if txt=='n':\n",
    "            return 0\n",
    "        if txt=='nne' or txt=='nen':\n",
    "            return 1/8\n",
    "        if txt=='ne':\n",
    "            return 2/8\n",
    "        if txt=='ene' or txt=='nee':\n",
    "            return 3/8\n",
    "        if txt=='e':\n",
    "            return 4/8\n",
    "        if txt=='ese' or txt=='see':\n",
    "            return 5/8\n",
    "        if txt=='se':\n",
    "            return 6/8\n",
    "        if txt=='ses' or txt=='sse':\n",
    "            return 7/8\n",
    "        if txt=='s':\n",
    "            return 8/8\n",
    "        if txt=='ssw' or txt=='sws':\n",
    "            return 9/8\n",
    "        if txt=='sw':\n",
    "            return 10/8\n",
    "        if txt=='sww' or txt=='wsw':\n",
    "            return 11/8\n",
    "        if txt=='w':\n",
    "            return 12/8\n",
    "        if txt=='wnw' or txt=='nww':\n",
    "            return 13/8\n",
    "        if txt=='nw':\n",
    "            return 14/8\n",
    "        if txt=='nwn' or txt=='nnw':\n",
    "            return 15/8\n",
    "        return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "train_single['WindDirection'] = train_single['WindDirection'].apply(transform_WindDirection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single['S_horizontal_qb'] = np.cos(train_single.QB_dir) * train_single.QB_S\n",
    "train_single['S_vertical_qb'] = np.sin(train_single.QB_dir) * train_single.QB_S\n",
    "train_single['S_h_diff'] = np.abs(train_single['S_horizontal_qb'] - train_single.S_horizontal)\n",
    "train_single['S_v_diff'] = np.abs(train_single['S_vertical_qb'] - np.sin(train_single.Dir) * train_single.S)\n",
    "train_single.drop(['QB_S','QB_dir'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "playid1 = train_single.PlayId.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single123 = train_single.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single.drop(remove_features,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list222 = ['S_5_def_qb',\n",
    " 'dist_5_off',\n",
    " 'A_2_off',\n",
    " 'A_3_off',\n",
    " 'A_5_def',\n",
    " 'S_10_def_mean',\n",
    " 'S_3_def',\n",
    " 'S_5_def',\n",
    " 'A_4_def',\n",
    " 'A_4_off',\n",
    " 'S_3_off_qb',\n",
    " 'S_vertical_qb',\n",
    " 'S_5_def_QB_mean',\n",
    " 'S_5_off',\n",
    " 'S_2_def',\n",
    " 'PlayerCollegeName',\n",
    " 'dist_3_off_qb',\n",
    " 'dist_5_off_qb',\n",
    " 'Stadium',\n",
    " 'Temperature',\n",
    " 'std_all_Y',\n",
    " 'dist_4_off',\n",
    " 'Location',\n",
    " 'Season',\n",
    " 'S_1_def',\n",
    " 'PlayerWeight',\n",
    " 'Week',\n",
    " 'WindSpeed',\n",
    " 'runner_height',\n",
    " 'num_dist5_off',\n",
    " 'PlayDirection',\n",
    " 'OffenseFormation',\n",
    " 'off_num_WR',\n",
    " 'StadiumType',\n",
    " 'Quarter',\n",
    " 'num_dist5_def_QB',\n",
    " 'Def_num_DL',\n",
    " 'off_num_OL',\n",
    " 'num_dist2_off',\n",
    " 'Def_num_OL',\n",
    " 'off_num_DB',\n",
    " 'off_num_QB',\n",
    " 'off_num_LB',\n",
    " 'off_num_DL',\n",
    " 'qb_number']\n",
    "train_single.drop(drop_list222,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = ['run_y',  'dist_2_def', 'A_2_def', 'A_5_off_mean','A','A_1_off_qb']\n",
    "\n",
    "train_single.drop(['A_2_off_QB_mean','A_5_off_QB_mean','A_5_def_QB_mean','A_10_def_QB_mean','A_10_off_QB_mean','A_5_def_qb','A_4_def_qb','A_4_off_qb','A_3_def_qb','A_3_off_qb','A_1_def_qb','A_2_def_qb','A_2_off_qb','A_5_off_qb'],axis=1,inplace=True)\n",
    "train_single.drop(temp1,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_single.fillna(-999,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23171, 120)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_single.Yards\n",
    "X_train = train_single.drop(['Yards'],axis=1)\n",
    "X_train_123 = X_train.copy()\n",
    "for f in X_train.columns:\n",
    "    if X_train[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(X_train[f])+[-999])\n",
    "        X_train[f] = lbl.transform(list(X_train[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[-100,-6,-3,-1,0,1,2,3,4,5,7,10,13,16,21,26,36,50,99]\n",
    "def y_to_cate(y_train,bins):\n",
    "    k = 101\n",
    "    y_train_transform = y_train.copy()\n",
    "    for i in range(len(bins)-1):\n",
    "        y_train_transform[(y_train_transform>bins[i])&(y_train_transform<=bins[i+1])] = k\n",
    "        k +=1\n",
    "    return y_train_transform-101\n",
    "def cal_CPRS(y_true_array,y_pred_array):\n",
    "    return np.mean((y_true_array - y_pred_array)**2)\n",
    "def raw_y_to_array2(pred,num_counts,bins,dist_to_ends):\n",
    "    y_pred_array = np.zeros((pred.shape[0],199))\n",
    "    n1 = pred.shape[0]\n",
    "    n = len(bins)-1\n",
    "    for j in range(n):\n",
    "        temp = (num_counts.loc[list(range(bins[j]+1,bins[j+1]+1))])\n",
    "        temp1 = list(temp/np.sum(temp))\n",
    "        temp_s = np.tile(temp1,(n1,1))\n",
    "        temp_block = (pred[:,j]*temp_s.transpose()).transpose()\n",
    "        y_pred_array[:,(bins[j]+100):(bins[j+1]+100)] = temp_block.copy()\n",
    "    temp_array = np.clip(np.cumsum(y_pred_array,axis=1),0,1)\n",
    "    for i in range(temp_array.shape[0]):\n",
    "        temp_array[i,(dist_to_ends.iloc[i]+99):] = 1\n",
    "    return temp_array\n",
    "def raw_y_to_array2_test(pred,num_counts,bins,dist_to_ends):\n",
    "    y_pred_array = np.zeros((1,199))\n",
    "    pred = pred.reshape(1,-1)\n",
    "    n1 = pred.shape[0]\n",
    "    n = len(bins)-1\n",
    "    num_counts_copy = num_counts.copy()\n",
    "    num_counts_copy.loc[list(range(dist_to_ends.values[0]+1,100))] = 0\n",
    "    for j in range(n-1,-1,-1):\n",
    "        temp = (num_counts_copy.loc[list(range(bins[j]+1,bins[j+1]+1))])\n",
    "        if np.sum(temp.values)==0:\n",
    "            #print('all zeros happens')\n",
    "            pred[:,j-1] += pred[:,j] \n",
    "            temp1 = list(temp).copy()\n",
    "        else:\n",
    "            temp1 = list(temp/np.sum(temp))\n",
    "        temp_s = np.tile(temp1,(n1,1))\n",
    "        temp_block = (pred[:,j]*temp_s.transpose()).transpose()\n",
    "        y_pred_array[:,(bins[j]+100):(bins[j+1]+100)] = temp_block.copy()\n",
    "    temp_array = np.clip(np.cumsum(y_pred_array,axis=1),0,1)\n",
    "    temp_array[0,(dist_to_ends.values[0]+99):] = 1\n",
    "    return temp_array\n",
    "def y_true_array(y_true):\n",
    "    temp = np.zeros((y_true.shape[0],199))\n",
    "    for i,value in enumerate(y_true):\n",
    "        temp[i,(value+99):] = 1\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRPS_eval(y_true, y_prob):\n",
    "    y_prob =  y_prob.reshape((len(y_true),-1),order='F')\n",
    "    global a\n",
    "    a=y_prob.copy()\n",
    "    \n",
    "\n",
    "    if len(y_true) < y_train.shape[0]/3:\n",
    "        index1 = test_index.copy()\n",
    "    else:\n",
    "        index1 = train_index.copy()\n",
    "    y_pred_array1 = raw_y_to_array2(y_prob,num_counts,bins,train_single['dist_to_end'].iloc[index1])\n",
    "    return 'CRPS', cal_CPRS(y_true_array1[index1,:],y_pred_array1), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23171, 120)\n"
     ]
    }
   ],
   "source": [
    "print(train_single.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_counts = y_train.value_counts().copy()\n",
    "for i in range(-99,100):\n",
    "    if i not in set(num_counts.index):\n",
    "        num_counts[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's CRPS: 0.0135237\n",
      "[100]\tvalid_0's CRPS: 0.0132966\n",
      "[150]\tvalid_0's CRPS: 0.0131207\n",
      "[200]\tvalid_0's CRPS: 0.0129828\n",
      "[250]\tvalid_0's CRPS: 0.0128793\n",
      "[300]\tvalid_0's CRPS: 0.0127984\n",
      "[350]\tvalid_0's CRPS: 0.0127332\n",
      "[400]\tvalid_0's CRPS: 0.0126791\n",
      "[450]\tvalid_0's CRPS: 0.012633\n",
      "[500]\tvalid_0's CRPS: 0.0125967\n",
      "[550]\tvalid_0's CRPS: 0.012564\n",
      "[600]\tvalid_0's CRPS: 0.0125379\n",
      "[650]\tvalid_0's CRPS: 0.0125148\n",
      "[700]\tvalid_0's CRPS: 0.0124962\n",
      "[750]\tvalid_0's CRPS: 0.0124788\n",
      "[800]\tvalid_0's CRPS: 0.0124667\n",
      "[850]\tvalid_0's CRPS: 0.0124555\n",
      "[900]\tvalid_0's CRPS: 0.0124433\n",
      "[950]\tvalid_0's CRPS: 0.0124346\n",
      "[1000]\tvalid_0's CRPS: 0.0124269\n",
      "[1050]\tvalid_0's CRPS: 0.0124209\n",
      "[1100]\tvalid_0's CRPS: 0.012415\n",
      "[1150]\tvalid_0's CRPS: 0.0124105\n",
      "[1200]\tvalid_0's CRPS: 0.0124054\n",
      "[1250]\tvalid_0's CRPS: 0.0124016\n",
      "[1300]\tvalid_0's CRPS: 0.0123981\n",
      "[1350]\tvalid_0's CRPS: 0.0123952\n",
      "[1400]\tvalid_0's CRPS: 0.0123921\n",
      "[1450]\tvalid_0's CRPS: 0.0123904\n",
      "[1500]\tvalid_0's CRPS: 0.0123884\n",
      "[1550]\tvalid_0's CRPS: 0.0123869\n",
      "[1600]\tvalid_0's CRPS: 0.0123851\n",
      "[1650]\tvalid_0's CRPS: 0.0123846\n",
      "[1700]\tvalid_0's CRPS: 0.0123841\n",
      "[1750]\tvalid_0's CRPS: 0.0123828\n",
      "[1800]\tvalid_0's CRPS: 0.0123825\n",
      "[1850]\tvalid_0's CRPS: 0.0123818\n",
      "[1900]\tvalid_0's CRPS: 0.0123824\n",
      "[1950]\tvalid_0's CRPS: 0.0123806\n",
      "[2000]\tvalid_0's CRPS: 0.0123807\n",
      "[2050]\tvalid_0's CRPS: 0.0123808\n",
      "[2100]\tvalid_0's CRPS: 0.0123819\n",
      "[2150]\tvalid_0's CRPS: 0.0123825\n",
      "Early stopping, best iteration is:\n",
      "[1955]\tvalid_0's CRPS: 0.0123803\n",
      "0.012380262253841243\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's CRPS: 0.0133651\n",
      "[100]\tvalid_0's CRPS: 0.013134\n",
      "[150]\tvalid_0's CRPS: 0.0129537\n",
      "[200]\tvalid_0's CRPS: 0.0128152\n",
      "[250]\tvalid_0's CRPS: 0.0127085\n",
      "[300]\tvalid_0's CRPS: 0.0126247\n",
      "[350]\tvalid_0's CRPS: 0.0125589\n",
      "[400]\tvalid_0's CRPS: 0.0125029\n",
      "[450]\tvalid_0's CRPS: 0.0124582\n",
      "[500]\tvalid_0's CRPS: 0.0124225\n",
      "[550]\tvalid_0's CRPS: 0.012391\n",
      "[600]\tvalid_0's CRPS: 0.0123643\n",
      "[650]\tvalid_0's CRPS: 0.0123403\n",
      "[700]\tvalid_0's CRPS: 0.0123196\n",
      "[750]\tvalid_0's CRPS: 0.0123003\n",
      "[800]\tvalid_0's CRPS: 0.0122857\n",
      "[850]\tvalid_0's CRPS: 0.0122724\n",
      "[900]\tvalid_0's CRPS: 0.0122597\n",
      "[950]\tvalid_0's CRPS: 0.0122491\n",
      "[1000]\tvalid_0's CRPS: 0.01224\n",
      "[1050]\tvalid_0's CRPS: 0.0122322\n",
      "[1100]\tvalid_0's CRPS: 0.012225\n",
      "[1150]\tvalid_0's CRPS: 0.0122196\n",
      "[1200]\tvalid_0's CRPS: 0.0122155\n",
      "[1250]\tvalid_0's CRPS: 0.0122122\n",
      "[1300]\tvalid_0's CRPS: 0.0122093\n",
      "[1350]\tvalid_0's CRPS: 0.0122058\n",
      "[1400]\tvalid_0's CRPS: 0.0122025\n",
      "[1450]\tvalid_0's CRPS: 0.012201\n",
      "[1500]\tvalid_0's CRPS: 0.0121991\n",
      "[1550]\tvalid_0's CRPS: 0.0121972\n",
      "[1600]\tvalid_0's CRPS: 0.0121959\n",
      "[1650]\tvalid_0's CRPS: 0.0121959\n",
      "[1700]\tvalid_0's CRPS: 0.012196\n",
      "[1750]\tvalid_0's CRPS: 0.0121959\n",
      "[1800]\tvalid_0's CRPS: 0.0121958\n",
      "[1850]\tvalid_0's CRPS: 0.0121949\n",
      "[1900]\tvalid_0's CRPS: 0.0121949\n",
      "[1950]\tvalid_0's CRPS: 0.012195\n",
      "[2000]\tvalid_0's CRPS: 0.012195\n",
      "[2050]\tvalid_0's CRPS: 0.0121954\n",
      "Early stopping, best iteration is:\n",
      "[1863]\tvalid_0's CRPS: 0.0121944\n",
      "0.012194357289315422\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's CRPS: 0.0126447\n",
      "[100]\tvalid_0's CRPS: 0.0124488\n",
      "[150]\tvalid_0's CRPS: 0.0123011\n",
      "[200]\tvalid_0's CRPS: 0.0121899\n",
      "[250]\tvalid_0's CRPS: 0.0121087\n",
      "[300]\tvalid_0's CRPS: 0.0120464\n",
      "[350]\tvalid_0's CRPS: 0.0119973\n",
      "[400]\tvalid_0's CRPS: 0.0119572\n",
      "[450]\tvalid_0's CRPS: 0.0119253\n",
      "[500]\tvalid_0's CRPS: 0.0118984\n",
      "[550]\tvalid_0's CRPS: 0.011877\n",
      "[600]\tvalid_0's CRPS: 0.0118592\n",
      "[650]\tvalid_0's CRPS: 0.0118451\n",
      "[700]\tvalid_0's CRPS: 0.0118328\n",
      "[750]\tvalid_0's CRPS: 0.0118218\n",
      "[800]\tvalid_0's CRPS: 0.0118135\n",
      "[850]\tvalid_0's CRPS: 0.0118068\n",
      "[900]\tvalid_0's CRPS: 0.0118008\n",
      "[950]\tvalid_0's CRPS: 0.0117962\n",
      "[1000]\tvalid_0's CRPS: 0.0117915\n",
      "[1050]\tvalid_0's CRPS: 0.0117875\n",
      "[1100]\tvalid_0's CRPS: 0.0117844\n",
      "[1150]\tvalid_0's CRPS: 0.0117817\n",
      "[1200]\tvalid_0's CRPS: 0.011781\n",
      "[1250]\tvalid_0's CRPS: 0.0117801\n",
      "[1300]\tvalid_0's CRPS: 0.0117792\n",
      "[1350]\tvalid_0's CRPS: 0.0117795\n",
      "[1400]\tvalid_0's CRPS: 0.0117788\n",
      "[1450]\tvalid_0's CRPS: 0.0117796\n",
      "[1500]\tvalid_0's CRPS: 0.0117794\n",
      "[1550]\tvalid_0's CRPS: 0.0117807\n",
      "[1600]\tvalid_0's CRPS: 0.0117811\n",
      "Early stopping, best iteration is:\n",
      "[1411]\tvalid_0's CRPS: 0.0117785\n",
      "0.011778514605981796\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's CRPS: 0.0145246\n",
      "[100]\tvalid_0's CRPS: 0.0143717\n",
      "[150]\tvalid_0's CRPS: 0.0142605\n",
      "[200]\tvalid_0's CRPS: 0.0141797\n",
      "[250]\tvalid_0's CRPS: 0.0141221\n",
      "[300]\tvalid_0's CRPS: 0.0140801\n",
      "[350]\tvalid_0's CRPS: 0.0140478\n",
      "[400]\tvalid_0's CRPS: 0.0140231\n",
      "[450]\tvalid_0's CRPS: 0.0140038\n",
      "[500]\tvalid_0's CRPS: 0.013991\n",
      "[550]\tvalid_0's CRPS: 0.0139799\n",
      "[600]\tvalid_0's CRPS: 0.013972\n",
      "[650]\tvalid_0's CRPS: 0.0139643\n",
      "[700]\tvalid_0's CRPS: 0.0139608\n",
      "[750]\tvalid_0's CRPS: 0.0139576\n",
      "[800]\tvalid_0's CRPS: 0.0139562\n",
      "[850]\tvalid_0's CRPS: 0.0139544\n",
      "[900]\tvalid_0's CRPS: 0.013953\n",
      "[950]\tvalid_0's CRPS: 0.0139536\n",
      "[1000]\tvalid_0's CRPS: 0.013955\n",
      "[1050]\tvalid_0's CRPS: 0.0139554\n",
      "Early stopping, best iteration is:\n",
      "[896]\tvalid_0's CRPS: 0.0139525\n",
      "0.01395251323942853\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's CRPS: 0.0142904\n",
      "[100]\tvalid_0's CRPS: 0.0141497\n",
      "[150]\tvalid_0's CRPS: 0.0140512\n",
      "[200]\tvalid_0's CRPS: 0.0139832\n",
      "[250]\tvalid_0's CRPS: 0.0139351\n",
      "[300]\tvalid_0's CRPS: 0.0139014\n",
      "[350]\tvalid_0's CRPS: 0.0138787\n",
      "[400]\tvalid_0's CRPS: 0.0138614\n",
      "[450]\tvalid_0's CRPS: 0.0138496\n",
      "[500]\tvalid_0's CRPS: 0.0138412\n",
      "[550]\tvalid_0's CRPS: 0.0138342\n",
      "[600]\tvalid_0's CRPS: 0.0138293\n",
      "[650]\tvalid_0's CRPS: 0.0138244\n",
      "[700]\tvalid_0's CRPS: 0.0138209\n",
      "[750]\tvalid_0's CRPS: 0.0138191\n",
      "[800]\tvalid_0's CRPS: 0.0138169\n",
      "[850]\tvalid_0's CRPS: 0.0138146\n",
      "[900]\tvalid_0's CRPS: 0.0138135\n",
      "[950]\tvalid_0's CRPS: 0.0138132\n",
      "[1000]\tvalid_0's CRPS: 0.0138116\n",
      "[1050]\tvalid_0's CRPS: 0.0138126\n",
      "[1100]\tvalid_0's CRPS: 0.013813\n",
      "[1150]\tvalid_0's CRPS: 0.0138142\n",
      "[1200]\tvalid_0's CRPS: 0.0138157\n",
      "Early stopping, best iteration is:\n",
      "[1004]\tvalid_0's CRPS: 0.0138113\n",
      "0.013811279974779619\n",
      "mean cprs: 0.012823385472669323\n",
      "oof cprs: 0.012823366348625522\n",
      "mean logloss 2.359852075420603\n",
      "oof logloss 2.359850796748401\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits = 5)\n",
    "impor1 = 0\n",
    "resu1_logloss = 0\n",
    "resu2_cprs = 0\n",
    "models = []\n",
    "y_train_trans = y_to_cate(y_train,bins)\n",
    "y_true_array1 = y_true_array(y_train)\n",
    "oof_predict = np.zeros((y_train.shape[0],18))\n",
    "for train_index, test_index in kf.split(X_train, y_train_trans):\n",
    "    X_train2= X_train.iloc[train_index,:]\n",
    "    y_train2= y_train_trans.iloc[train_index]\n",
    "    X_test2= X_train.iloc[test_index,:]\n",
    "    y_test2= y_train_trans.iloc[test_index]\n",
    "\n",
    "    clf = lgb.LGBMClassifier(n_estimators=10000, random_state=47,learning_rate=0.01,importance_type = 'gain',\n",
    "                     n_jobs = -1,num_leaves=20,bagging_freq=1,colsample_bytree=0.5,subsample=1,min_child_weight = 0.1,\n",
    "                             min_child_samples = 250,reg_alpha = 1.5,reg_lambda = 1,metric = 'None')\n",
    "    clf.fit(X_train2,y_train2,eval_set = [(X_test2,y_test2)],early_stopping_rounds=200,verbose=50,eval_metric = CRPS_eval)\n",
    "    models.append(clf)\n",
    "    temp_predict_prob = clf.predict_proba(X_test2)\n",
    "    oof_predict[test_index,:] = temp_predict_prob\n",
    "    crps = cal_CPRS(y_true_array1[test_index,:],raw_y_to_array2(temp_predict_prob,num_counts,bins,train_single['dist_to_end'].iloc[test_index]))\n",
    "    print(crps)\n",
    "    resu1_logloss += log_loss(y_test2,temp_predict_prob)/5\n",
    "    resu2_cprs += crps/5\n",
    "    impor1 += clf.feature_importances_/5\n",
    "    gc.collect()\n",
    "print('mean cprs:',resu2_cprs)\n",
    "print('oof cprs:',cal_CPRS(y_true_array1,raw_y_to_array2(oof_predict,num_counts,bins,train_single['dist_to_end'])))\n",
    "print('mean logloss',resu1_logloss)\n",
    "print('oof logloss',log_loss(y_train_trans,oof_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_test(train):\n",
    "    train.loc[train.VisitorTeamAbbr == \"ARI\",'VisitorTeamAbbr'] = \"ARZ\"\n",
    "    train.loc[train.HomeTeamAbbr == \"ARI\",'HomeTeamAbbr'] = \"ARZ\"\n",
    "\n",
    "    train.loc[train.VisitorTeamAbbr == \"BAL\",'VisitorTeamAbbr'] = \"BLT\"\n",
    "    train.loc[train.HomeTeamAbbr == \"BAL\",'HomeTeamAbbr'] = \"BLT\"\n",
    "\n",
    "    train.loc[train.VisitorTeamAbbr == \"CLE\",'VisitorTeamAbbr'] = \"CLV\"\n",
    "    train.loc[train.HomeTeamAbbr == \"CLE\",'HomeTeamAbbr'] = \"CLV\"\n",
    "\n",
    "    train.loc[train.VisitorTeamAbbr == \"HOU\",'VisitorTeamAbbr'] = \"HST\"\n",
    "    train.loc[train.HomeTeamAbbr == \"HOU\",'HomeTeamAbbr'] = \"HST\"    \n",
    "    train['ToLeft'] = train.PlayDirection == \"left\"\n",
    "    train['X_std'] = train.X\n",
    "    train.loc[train.ToLeft, 'X_std'] = 120 - train.loc[train.ToLeft, 'X'] \n",
    "    train['X'] = train['X_std'].copy()\n",
    "    train['Y_std'] = train.Y\n",
    "    train.loc[train.ToLeft, 'Y_std'] = 160/3 - train.loc[train.ToLeft, 'Y'] \n",
    "    train['Y'] = train['Y_std'].copy()\n",
    "    train['Orientation_std'] = np.mod(train.Orientation-90, 360)\n",
    "    train.loc[train.ToLeft, 'Orientation_std'] = np.mod(180 + train.loc[train.ToLeft, 'Orientation_std'].copy(),360)\n",
    "    train['Orientation'] = train['Orientation_std'].copy()\n",
    "    train['Dir_rad'] = np.mod(train.Dir-90, 360) * np.pi/180.0\n",
    "    train['Dir_std'] = train.Dir_rad.copy()\n",
    "    train.loc[train.ToLeft, 'Dir_std'] = np.mod(np.pi + train.loc[train.ToLeft, 'Dir_rad'], 2*np.pi)\n",
    "    train['Dir'] = train['Dir_std'].copy()\n",
    "    person_info = train[person_feature].copy()\n",
    "    person_info['player_mark'] = ['player'+ str(i) for i in range(1,12)]*int(person_info.shape[0]/11)\n",
    "    te = pd.pivot_table(person_info,columns=['Team','player_mark'],index=['PlayId'],aggfunc=lambda x:x)\n",
    "    te.columns = ['_'.join(a) for a in te.columns.values]\n",
    "    train['TeamOnOffense'] = \"home\"\n",
    "    train.loc[train.PossessionTeam != train.HomeTeamAbbr, 'TeamOnOffense'] = \"away\"\n",
    "    train['IsOnOffense'] = train.Team == train.TeamOnOffense\n",
    "    \n",
    "    train['is_run'] = train.NflId == train.NflIdRusher\n",
    "    train_single = train[train.is_run==True].copy()\n",
    "    train_single['diff_Ori_dir'] = np.abs(train_single.Orientation - train_single.Dir/np.pi*180)\n",
    "    temp1 = pd.DataFrame(train_single['diff_Ori_dir'].copy())\n",
    "    temp1['c1'] = 360 - temp1.diff_Ori_dir\n",
    "    train_single['diff_Ori_dir']= np.min(temp1,axis=1).tolist()\n",
    "    train_single['time_quarter'] = train_single.GameClock.map(lambda x:transform_time_quarter(x))\n",
    "    train_single['time_end'] = train_single.apply(lambda x:transform_time_all(x.loc['GameClock'],x.loc['Quarter']),axis=1)\n",
    "    train_single['TimeHandoff'] = train_single['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    train_single['TimeSnap'] = train_single['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n",
    "    train_single['date_game'] = train_single.GameId.map(lambda x:pd.to_datetime(str(x)[:8]))\n",
    "    train_single['runner_age'] = (train_single.date_game.map(pd.to_datetime) - train_single.PlayerBirthDate.map(pd.to_datetime)).map(lambda x:x.days)/365.25\n",
    "    train_single['runner_height'] = train_single.PlayerHeight.map(transform_height)\n",
    "    train_single['own_field'] = (train_single['FieldPosition'] == train_single['PossessionTeam']).astype(int)\n",
    "    train_single['dist_to_end'] = train_single.apply(lambda x:(100 - x.loc['YardLine']) if x.loc['own_field']==1 else x.loc['YardLine'],axis=1)\n",
    "    train_single['YardLine_x'] = train_single.apply(transform_YardLine_x,axis=1)\n",
    "    train_single['dist_to_line'] = train_single.apply(transform_dist_to_line,axis=1)\n",
    "    train['is_QB'] = train.Position=='QB'\n",
    "    qb_number = train.groupby(['PlayId'])['is_QB'].sum()\n",
    "    train_single['qb_number'] = train_single.PlayId.map(qb_number)\n",
    "    te1 = train.loc[(train.is_run==True)|(train.is_QB==1),['PlayId','X','Y','is_run','is_QB','A','S',\n",
    "                                                           'Dis','Orientation','Dir','PlayerHeight','PlayerWeight','PlayerBirthDate']]\n",
    "    te1 = te1.set_index(['PlayId'])\n",
    "    run_info = te1[te1.is_run==True].copy()\n",
    "    run_info.rename({'X':'run_x','Y':'run_y'},axis=1,inplace=True)\n",
    "    qb_info = te1[te1.is_QB==1].copy()\n",
    "    qb_info.reset_index(inplace=True)\n",
    "    \n",
    "    drop_index=[]\n",
    "    for num_index in qb_number.index[qb_number>=2]:\n",
    "        temp = qb_info.loc[qb_info.PlayId==num_index,['X','Y']]\n",
    "        dist_to_close = []\n",
    "        for num in temp.index:\n",
    "            temp_a = np.sqrt(np.sum((temp.loc[num].values - run_info.loc[run_info.index==num_index,['run_x','run_y']].values[0,])**2))\n",
    "            #print(num_index)\n",
    "            dist_to_close.append(temp_a)\n",
    "        drop_index.extend([temp.index.tolist()[i] for i in list(np.argsort(dist_to_close))[1:]])\n",
    "    qb_info.drop(drop_index,axis=0,inplace=True)\n",
    "#     drop_index=[]\n",
    "#     for num_index in qb_number.index[qb_number==2]:\n",
    "#         temp = qb_info.loc[qb_info.PlayId==num_index,['X','Y']]\n",
    "#         dist_to_close = []\n",
    "#         for num in temp.index:\n",
    "#             temp_a = np.sqrt(np.sum((temp.loc[num].values - run_info.loc[run_info.index==num_index,['run_x','run_y']].values[0,])**2))\n",
    "#             #print(num_index)\n",
    "#             dist_to_close.append(temp_a)\n",
    "#         if dist_to_close[0]>dist_to_close[1]:\n",
    "#             drop_index.append(temp.index.tolist()[0])\n",
    "#         else:\n",
    "#             drop_index.append(temp.index.tolist()[1])\n",
    "\n",
    "    train_single.rename({'X':'run_x','Y':'run_y'},axis=1,inplace=True)\n",
    "    qb_info.rename({'A':'QB_A','S':'QB_S','Dis':'QB_Dis','Orientation':'QB_Orientation',\n",
    "                    'Dir':'QB_dir','PlayerHeight':'QB_PlayerHeight',\n",
    "                    'PlayerWeight':'QB_PlayerWeight','PlayerBirthDate':'QB_PlayerBirthDate'},axis=1,inplace=True)\n",
    "    train_single = pd.merge(train_single,qb_info[['PlayId','X','Y','QB_A','QB_S','QB_Dis','QB_Orientation',\n",
    "                                                 'QB_dir','QB_PlayerHeight','QB_PlayerWeight',\n",
    "                                                 'QB_PlayerBirthDate']],on='PlayId',how='left')\n",
    "    train_single.rename({'X':'QB_x','Y':'QB_y'},axis=1,inplace=True)\n",
    "    train_single['qb_to_line'] = train_single.apply(transform_qb_to_line,axis=1)\n",
    "\n",
    "    train_single['run_dist_qb'] = train_single.apply(transform_run_dist_qb,axis=1)\n",
    "    train_single['QB_PlayerHeight'] = train_single.QB_PlayerHeight.map(transform_height)\n",
    "    train_single['QB_age'] = (train_single.date_game.map(pd.to_datetime) - train_single.QB_PlayerBirthDate.map(pd.to_datetime)).map(lambda x:x.days)/365.25\n",
    "\n",
    "    train_single['diff_Ori_dir_qb'] = np.abs(train_single.QB_Orientation - train_single.QB_dir/np.pi*180)\n",
    "    temp1 = pd.DataFrame(train_single['diff_Ori_dir_qb'].copy())\n",
    "    temp1['c1'] = 360 - temp1.diff_Ori_dir_qb\n",
    "    train_single['diff_Ori_dir_qb']= np.min(temp1,axis=1).tolist()\n",
    "\n",
    "    train_single['diff_qb_runner_dir'] = np.abs(train_single.Dir/np.pi*180 - train_single.QB_dir/np.pi*180)\n",
    "    temp1 = pd.DataFrame(train_single['diff_qb_runner_dir'].copy())\n",
    "    temp1['c1'] = 360 - temp1.diff_qb_runner_dir\n",
    "    train_single['diff_qb_runner_dir']= np.min(temp1,axis=1).tolist()\n",
    "\n",
    "    train_single['diff_qb_runner_ori'] = np.abs(train_single.Orientation - train_single.QB_Orientation)\n",
    "    temp1 = pd.DataFrame(train_single['diff_qb_runner_ori'].copy())\n",
    "    temp1['c1'] = 360 - temp1.diff_qb_runner_ori\n",
    "    train_single['diff_qb_runner_ori']= np.min(temp1,axis=1).tolist()\n",
    "\n",
    "    train_single['score_difference'] = train_single.apply(lambda x:\n",
    "                                        x.loc['HomeScoreBeforePlay'] - x.loc['VisitorScoreBeforePlay'] if x.loc['PossessionTeam'] == x.loc['HomeTeamAbbr']\n",
    "                                                          else x.loc['VisitorScoreBeforePlay'] - x.loc['HomeScoreBeforePlay'],axis=1)\n",
    "    train_single['offense_score'] = train_single.apply(lambda x:\n",
    "                                        x.loc['HomeScoreBeforePlay']  if x.loc['PossessionTeam'] == x.loc['HomeTeamAbbr']\n",
    "                                                          else x.loc['VisitorScoreBeforePlay'] ,axis=1)\n",
    "    \n",
    "    train_single = pd.merge(train_single,te,on='PlayId',how = 'left')\n",
    "\n",
    "    train_single['dist1_divide_S'] = train_single.apply(dist1_divide_S,axis=1)\n",
    "\n",
    "    train_single['dist1_divide_S_hor'] = train_single.apply(dist1_divide_S_hor,axis=1)\n",
    "\n",
    "    train_single['time1_dist_S'] = train_single.apply(time1_dist_S,axis=1)\n",
    "\n",
    "    train_single['time1_dist_S_hor'] = train_single.apply(time1_dist_S_hor,axis=1)\n",
    "\n",
    "    train_single['close_who_S_ratio']= train_single.apply(transform_close_who,axis=1)\n",
    "    \n",
    "    temp1  = train_single.apply(transform_dist_close123_offense_runner,axis=1)\n",
    "    names = ['dist_1_off','A_1_off','S_1_off','dist_2_off','A_2_off','S_2_off','dist_3_off','A_3_off','S_3_off',\n",
    "            'dist_4_off','A_4_off','S_4_off','dist_5_off','A_5_off','S_5_off']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "    temp1  = train_single.apply(transform_dist_close123_defender_runner,axis=1)\n",
    "    names = ['dist_1_def','A_1_def','S_1_def','dist_2_def','A_2_def','S_2_def','dist_3_def','A_3_def','S_3_def',\n",
    "            'dist_4_def','A_4_def','S_4_def','dist_5_def','A_5_def','S_5_def']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "    for i in [1]:\n",
    "        train_single['dist_'+str(i)+'_S_ratio'] = train_single['S_'+str(i)+'_def'] / train_single.S\n",
    "        train_single['dist_'+str(i)+'_S_ratio'] = np.where(np.isinf(train_single['dist_'+str(i)+'_S_ratio']),999,train_single['dist_'+str(i)+'_S_ratio'])\n",
    "        \n",
    "        \n",
    "    temp1  = train_single.apply(transform_dist_close123_offense_QB,axis=1)\n",
    "    names = ['dist_1_off_qb','A_1_off_qb','S_1_off_qb','dist_2_off_qb','A_2_off_qb','S_2_off_qb','dist_3_off_qb','A_3_off_qb','S_3_off_qb',\n",
    "            'dist_4_off_qb','A_4_off_qb','S_4_off_qb','dist_5_off_qb','A_5_off_qb','S_5_off_qb']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "    temp1  = train_single.apply(transform_dist_close123_defender_QB,axis=1)\n",
    "    names = ['dist_1_def_qb','A_1_def_qb','S_1_def_qb','dist_2_def_qb','A_2_def_qb','S_2_def_qb','dist_3_def_qb','A_3_def_qb','S_3_def_qb',\n",
    "            'dist_4_def_qb','A_4_def_qb','S_4_def_qb','dist_5_def_qb','A_5_def_qb','S_5_def_qb']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "        \n",
    "    temp1  = train_single.apply(transform_dist2_num_defender,axis=1)\n",
    "    names = ['num_dist5_def','S_5_def_mean','A_5_def_mean','num_dist10_def','S_10_def_mean','A_10_def_mean']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "    temp1  = train_single.apply(transform_dist2_num_offense,axis=1)\n",
    "    names = ['num_dist2_off','S_2_off_mean','A_2_off_mean','num_dist5_off','S_5_off_mean','A_5_off_mean','num_dist10_off','S_10_off_mean','A_10_off_mean']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "        \n",
    "    temp1  = train_single.apply(transform_dist2_num_defender_QB,axis=1)\n",
    "    names = ['num_dist5_def_QB','S_5_def_QB_mean','A_5_def_QB_mean','num_dist10_def_QB','S_10_def_QB_mean','A_10_def_QB_mean']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "    temp1  = train_single.apply(transform_dist2_num_offense_QB,axis=1)\n",
    "    names = ['num_dist2_off_QB','S_2_off_QB_mean','A_2_off_QB_mean','num_dist5_off_QB','S_5_off_QB_mean','A_5_off_QB_mean','num_dist10_off_QB','S_10_off_QB_mean','A_10_off_QB_mean']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "    temp1  = train_single.apply(transform_defend_X_Y_std,axis=1)\n",
    "    names = ['std_def_X','std_def_Y']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "    temp1  = train_single.apply(transform_offense_X_Y_std,axis=1)\n",
    "    names = ['std_off_X','std_off_Y']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "    temp1  = train_single.apply(transform_all_X_Y_std,axis=1)\n",
    "    names = ['std_all_X','std_all_Y']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = temp1.map(lambda x:x[i])\n",
    "\n",
    "    temp1 = train_single.OffensePersonnel.apply(lambda x: pd.Series(OffensePersonnelSplit(x)))\n",
    "    names = ['DB','DL','LB','OL','QB','RB','TE','WR']\n",
    "    for i in range(len(names)):\n",
    "        train_single['off_num_' + names[i]] = temp1.apply(lambda x:x[names[i]],axis=1)\n",
    "\n",
    "    temp1 = train_single.DefensePersonnel.apply(lambda x: pd.Series(DefensePersonnelSplit(x)))\n",
    "    names = ['DB','DL','LB','OL']\n",
    "    for i in range(len(names)):\n",
    "        train_single['Def_num_' + names[i]] = temp1.apply(lambda x:x[names[i]],axis=1)\n",
    "\n",
    "    train_single['S_horizontal'] = np.cos(train_single.Dir) * train_single.S\n",
    "    train_single['S_vertical'] = np.abs(np.sin(train_single.Dir) * train_single.S)\n",
    "    \n",
    "    def is_in_poly(polygon,array):\n",
    "        try:\n",
    "            k = 0\n",
    "            temp = Delaunay(polygon)\n",
    "            for i in range(array.shape[0]):\n",
    "                if temp.find_simplex(array[i,:]) >=0:\n",
    "                    k+=1\n",
    "            return k\n",
    "        except:\n",
    "            return 0\n",
    "\n",
    "    def calculate_voroni(row):\n",
    "        try:\n",
    "            df=train[train.PlayId==row.PlayId]\n",
    "            df_offense = df[(df.NflIdRusher != df.NflId)&(df.IsOnOffense)].copy()\n",
    "            pp = df_offense[['X_std','Y_std']].values.copy()\n",
    "            df = df[(df.NflIdRusher == df.NflId) | ~df.IsOnOffense] \n",
    "            xy = df[['X_std', 'Y_std']].values\n",
    "            n_points = xy.shape[0]\n",
    "            xy1 = xy.copy()\n",
    "            xy1[:,1] = - xy[:,1]\n",
    "            xy2 = xy.copy()\n",
    "            xy2[:,1] = 320/3 - xy[:,1]\n",
    "            xy3 = xy.copy()\n",
    "            xy3[:,0] =  - xy[:,0]\n",
    "            xy4 = xy.copy()\n",
    "            xy4[:,0] = 240 - xy[:,0]\n",
    "            xy = np.concatenate((xy, xy1, xy2, xy3, xy4), axis=0)\n",
    "            offense = df.IsOnOffense.values\n",
    "            vor = Voronoi(xy)\n",
    "            num_adj = []\n",
    "            adj_vertice = []\n",
    "            X_temp = []\n",
    "            Y_temp = []\n",
    "            S_temp = []\n",
    "            Dir_temp = []\n",
    "            for r in range(n_points):\n",
    "                if offense[r]:\n",
    "                    rusher_num = r\n",
    "                    rusher_region_points = vor.regions[vor.point_region[r]]\n",
    "            for r in range(n_points):\n",
    "                region = vor.regions[vor.point_region[r]]\n",
    "                if not -1 in region:\n",
    "                    polygon = [vor.vertices[i] for i in region]\n",
    "                    if offense[r]:\n",
    "                        temp_area = ConvexHull(polygon)\n",
    "                        voroni_area = temp_area.volume\n",
    "                        x_max = np.max(np.array(polygon)[:,0])\n",
    "                        x_min = np.min(np.array(polygon)[:,0])\n",
    "                    else:\n",
    "                        if len(set(rusher_region_points).intersection(set(region)))>=1:\n",
    "                            num_adj.append(r)\n",
    "                            adj_vertice.append(polygon)\n",
    "            X_temp = df.X_std.values.copy()[num_adj]\n",
    "            X_Y_temp = df[['X_std','Y_std']].values.copy()[num_adj,:]\n",
    "            S_temp = df.S.values.copy()[num_adj]\n",
    "            Dir_temp = df.Dir.values.copy()[num_adj]\n",
    "            num_in_adj_cell = [is_in_poly(np.array(poly),pp) for poly in adj_vertice]\n",
    "            num_0_cell = len(list(filter(lambda x:x==0,num_in_adj_cell)))\n",
    "            sum_num_adj_cell = np.sum(num_in_adj_cell)\n",
    "\n",
    "            if num_0_cell==0:\n",
    "                dist1 = np.nan\n",
    "                S_ratio = np.nan\n",
    "                time1 = np.nan\n",
    "                time1_h = np.nan\n",
    "            else:\n",
    "                #dist1 = np.min(np.sqrt(np.sum((X_Y_temp[list(np.array(num_in_adj_cell)==0),:] - np.array([row.run_x,row.run_y]))**2,axis=1)))\n",
    "                S_ratio = np.clip(np.max(S_temp[list(np.array(num_in_adj_cell)==0)]/row.S),0,300)\n",
    "                #time1 = np.clip(np.min(np.sqrt(np.sum((X_Y_temp[list(np.array(num_in_adj_cell)==0),:] - np.array([row.run_x,row.run_y]))**2,axis=1))/S_temp[list(np.array(num_in_adj_cell)==0)]),0,500)\n",
    "                time1_h = np.clip(np.min(np.abs(X_temp[list(np.array(num_in_adj_cell)==0)] - row.run_x)/np.abs(S_temp[list(np.array(num_in_adj_cell)==0)]*np.cos(Dir_temp[list(np.array(num_in_adj_cell)==0)]))),0,500)\n",
    "            return voroni_area,110- x_max,x_max-row.run_x, x_max - row.YardLine_x,len(adj_vertice),sum_num_adj_cell,num_0_cell,S_ratio,time1_h\n",
    "        except:\n",
    "            return np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan\n",
    "\n",
    "\n",
    "    te = train_single.apply(calculate_voroni,axis=1)\n",
    "    names = ['voroni_area','voroni_bc_close','voroni_bc_x_max_minus_x','voroni_max_yardline','adj_cell_num','adj_off_num','adj_def_num_no_offense','voro0_S_ratio_max','voro0_time_min_h']\n",
    "    for i in range(len(names)):\n",
    "        train_single[names[i]] = te.map(lambda x:x[i])\n",
    "    train_single['voro_diff_num'] = train_single['adj_cell_num'] - train_single['adj_off_num']\n",
    "    \n",
    "\n",
    "    \n",
    "    ### player info\n",
    "    train_single['mean_player_100'] = 0\n",
    "    train_single['std_player_100'] = 0\n",
    "    train_single['min_player_100'] = 0\n",
    "    train_single['quan25_player_100'] = 0\n",
    "    train_single['quan75_player_100'] = 0\n",
    "    for player in list(train_single.NflId.unique()):\n",
    "        temp = train_single123.loc[train_single123.NflId==player,'Yards']\n",
    "        index1 = train_single[train_single.NflId==player].index\n",
    "        if temp.shape[0] == 0:\n",
    "            train_single.loc[index1,'mean_player_100'] = np.nan\n",
    "            train_single.loc[index1,'std_player_100'] = np.nan\n",
    "            train_single.loc[index1,'min_player_100'] = np.nan\n",
    "            train_single.loc[index1,'quan25_player_100'] = np.nan\n",
    "            train_single.loc[index1,'quan75_player_100'] = np.nan\n",
    "        else:     \n",
    "            mean1 = temp.rolling(100,min_periods=20).mean().iloc[-1]\n",
    "            std1 = temp.rolling(100,min_periods=20).std().iloc[-1]\n",
    "            min1 = temp.rolling(100,min_periods=20).min().iloc[-1]\n",
    "            quan25 = temp.rolling(100,min_periods=20).quantile(0.10).iloc[-1]\n",
    "            quan75 = temp.rolling(100,min_periods=20).quantile(0.90).iloc[-1]      \n",
    "            train_single.loc[index1,'mean_player_100'] = mean1\n",
    "            train_single.loc[index1,'std_player_100'] = std1\n",
    "            train_single.loc[index1,'min_player_100'] = min1\n",
    "            train_single.loc[index1,'quan25_player_100'] = quan25\n",
    "            train_single.loc[index1,'quan75_player_100'] = quan75\n",
    "\n",
    "    train_single['DefendersInTheBox_vs_Distance'] = train_single['DefendersInTheBox'] / train_single['Distance']\n",
    "\n",
    "    train_single['WindDirection'] = train_single['WindDirection'].apply(clean_WindDirection)\n",
    "\n",
    "    train_single['WindDirection'] = train_single['WindDirection'].apply(transform_WindDirection)\n",
    "    train_single['S_horizontal_qb'] = np.cos(train_single.QB_dir) * train_single.QB_S\n",
    "    train_single['S_vertical_qb'] = np.sin(train_single.QB_dir) * train_single.QB_S\n",
    "    train_single['S_h_diff'] = np.abs(train_single['S_horizontal_qb'] - train_single.S_horizontal)\n",
    "    train_single['S_v_diff'] = np.abs(train_single['S_vertical_qb'] - np.sin(train_single.Dir) * train_single.S)\n",
    "    train_single.drop(['QB_S','QB_dir'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "    temp1 = ['run_y', 'dist_2_def', 'A_2_def', 'A_5_off_mean','A','A_1_off_qb']\n",
    "    train_single.drop(['A_2_off_QB_mean','A_5_off_QB_mean','A_5_def_QB_mean','A_10_def_QB_mean','A_10_off_QB_mean','A_5_def_qb','A_4_def_qb','A_4_off_qb','A_3_def_qb','A_3_off_qb','A_1_def_qb','A_2_def_qb','A_2_off_qb','A_5_off_qb'],axis=1,inplace=True)\n",
    "    train_single = train_single.drop(temp1,axis=1)\n",
    "    train_single.drop(drop_list222,axis=1,inplace=True)    \n",
    "\n",
    "    return train_single.drop(remove_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:25: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission file has been saved!  Once you `Commit` your Notebook and it finishes running, you can submit the file to the competition from the Notebook Viewer `Output` tab.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_start=time.time()\n",
    "\n",
    "\n",
    "for (test_df, sample_prediction_df) in env.iter_test():\n",
    "    X_test = transform_test(test_df)\n",
    "    X_test.fillna(-999,inplace=True)\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object':\n",
    "            X_test[f] = X_test[f].map(lambda x:x if x in set(X_train_123[f]) else -999)\n",
    "    for f in X_test.columns:\n",
    "        if X_test[f].dtype=='object': \n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            lbl.fit(list(X_train_123[f])+[-999])\n",
    "            X_test[f] = lbl.transform(list(X_test[f])) \n",
    "    pred_value = 0\n",
    "    for model in models:\n",
    "        pred_value += model.predict_proba(X_test)/5\n",
    "    pred_data = list(raw_y_to_array2_test(pred_value,num_counts,bins,X_test['dist_to_end']))\n",
    "    pred_data = np.array(pred_data).reshape(1,199)\n",
    "    pred_target = pd.DataFrame(index = sample_prediction_df.index, \\\n",
    "                               columns = sample_prediction_df.columns, \\\n",
    "                               #data = np.array(pred_data))\n",
    "                               data = pred_data)\n",
    "    #print(pred_target)\n",
    "    env.predict(pred_target)\n",
    "env.write_submission_file()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totally cost 3313.5569021701813\n"
     ]
    }
   ],
   "source": [
    "time_end=time.time()\n",
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kf=KFold(n_splits = 5)\n",
    "# resu1 = 0\n",
    "# impor1 = 0\n",
    "# ##y_pred = 0\n",
    "# stack_train = np.zeros([X_train.shape[0],])\n",
    "# for train_index, test_index in kf.split(X_train, y_train):\n",
    "#     X_train2= X_train.iloc[train_index,:]\n",
    "#     y_train2= y_train.iloc[train_index]\n",
    "#     X_test2= X_train.iloc[test_index,:]\n",
    "#     y_test2= y_train.iloc[test_index]\n",
    "#     clf = lgb.LGBMRegressor(n_estimators=10000, random_state=47,subsample=0.7,\n",
    "#                              colsample_bytree=0.7,learning_rate=0.03,importance_type = 'gain',\n",
    "#                      max_depth = -1, num_leaves = 256,min_child_samples=20,min_split_gain = 0.001,\n",
    "#                        bagging_freq=1,reg_alpha = 0,reg_lambda = 0,n_jobs = -1)\n",
    "#     clf.fit(X_train2,y_train2,eval_set = [(X_train2,y_train2),(X_test2,y_test2)],early_stopping_rounds=100,verbose=50)\n",
    "#     temp_predict = clf.predict(X_test2)\n",
    "#     stack_train[test_index] = temp_predict\n",
    "#     ##y_pred += clf.predict(X_test)/5\n",
    "#     mse = mean_squared_error(y_test2, temp_predict)\n",
    "#     print(mse)\n",
    "#     resu1 += mse/5\n",
    "#     impor1 += clf.feature_importances_/5\n",
    "#     gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
